from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

from templates.journal_templates import get_journal
from templates.audio_templates import get_audio
from templates.video_templates import get_video_emotion_scores
from projection import run_simulation_for_patient
import shap
import pickle
import matplotlib.pyplot as plt
import streamlit as st
import streamlit.components.v1 as components
import os
import json
import shutil
import random
import pandas as pd
import re
from datetime import datetime, timedelta
from dotenv import load_dotenv
import openai
import time
from tenacity import retry, stop_after_attempt, wait_exponential
import numpy as np
import plotly.express as px
from pathlib import Path
import glob
import math
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)))



DSBIT_REFERENCES = [
    ("APA. (2013). Diagnostic and Statistical Manual of Mental Disorders (5th ed.).", "https://www.psychiatry.org/psychiatrists/practice/dsm"),
    ("WHO. (2021). International Classification of Diseases (11th Revision).", "https://icd.who.int/"),
    ("Kroenke, K., et al. (2010). The PHQ-9: A new depression diagnostic and severity measure.", "hhttps://jacobimed.org/public/Ambulatory_files/mlove/CurriculumWomenandGeri/Depression/Depression%20articles/PHQ-9ReviewKroenke.pdf"),
    ("Spitzer, R. L., et al. (2006). A brief measure for assessing generalized anxiety disorder: The GAD-7.", "https://doi.org/10.1001/archinte.166.10.1092"),
    ("Buysse, D. J., et al. (1989). The Pittsburgh Sleep Quality Index: a new instrument for psychiatric practice and research.", "https://doi.org/10.1016/0165-1781(89)90047-4"),
    ("Cohen, S., et al. (1983). A global measure of perceived stress.", "https://doi.org/10.2307/2136404"),
    ("Weiss, D. S., & Marmar, C. R. (1997). The Impact of Event Scale-Revised.", "https://www.ptsd.va.gov/professional/assessment/adult-sr/ies-r.asp"),
    ("Torous, J., et al. (2020). Digital phenotyping and mobile sensing: New developments in psychoinformatics.", "https://awspntest.apa.org/record/2020-08754-000"),
    ("Insel, T. R., et al. (2010). Research Domain Criteria (RDoC): Toward a new classification framework for research on mental disorders.", "https://doi.org/10.1176/appi.ajp.2010.09091379"),
    ("Kazdin, A. E. (2017). Research Design in Clinical Psychology (5th ed.).", "https://assets.cambridge.org/97811089/95214/frontmatter/9781108995214_frontmatter.pdf"),
    ("Linehan, M. (2018). Cognitive-Behavioral Treatment of Borderline Personality Disorder.", "https://www.guilford.com/books/Cognitive-Behavioral-Treatment-of-Borderline-Personality-Disorder/Marsha-Linehan/9780898621839"),
    ("Luxton, D. D. (2020). Artificial Intelligence in Behavioral and Mental Health Care.", "https://www.elsevier.com/books/artificial-intelligence-in-behavioral-and-mental-health-care/luxton/978-0-12-420248-1"),
    ("Ekman, P., et al. (2019). Facial expression and emotion. American Psychologist.", "https://www.paulekman.com/wp-content/uploads/2013/07/Facial-Expression-And-Emotion1.pdf"),
    ("Scherer, K. R. (2018). What are emotions? And how can they be measured?", "https://static1.squarespace.com/static/55917f64e4b0cd3b4705b68c/t/5bc7c2fba4222f0b94cc8550/1539818235703/scherer+%282005%29.pdf"),
]

# API anahtarƒ±nƒ± doƒürudan kodun i√ßine ekleyin üêá
api_key = "type_your_api_key_here"

if not api_key or api_key == "fake-key":
    print("API anahtarƒ± y√ºklenemedi. L√ºtfen ge√ßerli bir anahtar saƒülayƒ±n.")
else:
    print("API anahtarƒ± ba≈üarƒ±yla y√ºklendi:", api_key)

openai.api_key = api_key

# Sabitlerüêá
EMOTIONS = ["mutluluk", "√ºz√ºnt√º", "√∂fke", "kaygƒ±", "n√∂tr"]
FORM_WEEKLY = ["PHQ9", "GAD7", "PSS10"]
FORM_MONTHLY = ["PSQI", "IESR"]
BASE_DIR = "data/records"

def random_emotion():
    return random.choice(EMOTIONS)

def create_dirs(pid):
    for sub in [
        "mood_tracking", "journal_entries", "audio_entries", "video_analysis",
        "emotion_consistency", "healthkit", "form_submissions"
    ] + [f"forms/{form}" for form in FORM_WEEKLY + FORM_MONTHLY]:
        os.makedirs(os.path.join(BASE_DIR, pid, sub), exist_ok=True)

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=5, max=20))
def gpt_text(prompt):
    """Send prompt to GPT with retry mechanism and better error handling.
    
    Args:
        prompt (str): The prompt to send to GPT
        
    Returns:
        str: GPT response or error message
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen bir psikiyatrik hasta sim√ºlasyon motorusun."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.85
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"GPT API Hatasƒ±: {str(e)}")
        print(f"Detaylƒ± Hata: {str(e)}")
        return "API baƒülantƒ±sƒ±nda sorun olu≈ütu. L√ºtfen tekrar deneyin."

def calculate_functioning_score(steps, sleep_hours, mood_avg, journal_sent, audio_sent, dominant_emotion, form_scores):
    """
    √áoklu parametreye dayalƒ± i≈ülevsellik skoru (0-100 arasƒ±)
    """
    score = 100
    # Fiziksel aktivite ve uykuüêá
    if steps < 3000:
        score -= 20
    elif steps < 6000:
        score -= 10
    if sleep_hours < 5:
        score -= 15
    elif sleep_hours < 7:
        score -= 5
    # Mood (ortalama 1-5 arasƒ±, 3'√ºn altƒ± riskli)üêá
    if mood_avg < 2:
        score -= 20
    elif mood_avg < 3:
        score -= 10
    # NLP sentiment (negatifse d√º≈ü√ºr)üêá
    if journal_sent is not None and journal_sent < 0:
        score -= 10
    if audio_sent is not None and audio_sent < 0:
        score -= 10
    # Video dominant duygu
    if dominant_emotion in ["√ºz√ºnt√º", "√∂fke", "kaygƒ±"]:
        score -= 10
    # Psikometrik test ≈üiddetiüêá
    for form in form_scores.values():
        if form.get("severity") == "y√ºksek":
            score -= 10
        elif form.get("severity") == "orta":
            score -= 5
    # Skoru 0-100 aralƒ±ƒüƒ±nda sƒ±nƒ±rlaüêá
    score = max(0, min(100, score))
    return score

# --- get_latest_danger_grade artƒ±k dosyadan okur, yoksa hesaplar ve kaydederüêá --------------------------------------------------------
def get_latest_danger_grade(pid):
    grade, danger = load_patient_grade(pid)
    if grade is not None:
        return grade
    try:
        base = os.path.join(BASE_DIR, pid)
        mood_df = pd.read_csv(os.path.join(base, "mood_tracking", sorted(os.listdir(os.path.join(base, "mood_tracking")))[-1]))
        with open(os.path.join(base, "video_analysis", sorted(os.listdir(os.path.join(base, "video_analysis")))[-1]), "r", encoding="utf-8") as f:
            video_json = json.load(f)
        form_scores = {}
        for form in FORM_WEEKLY + FORM_MONTHLY:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_scores[form] = latest_form
        func_path = os.path.join(base, "functioning_score")
        func_file = sorted(os.listdir(func_path))[-1]
        func_score = pd.read_csv(os.path.join(func_path, func_file))["score"].values[0]

        health_path = os.path.join(base, "healthkit")
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        df = pd.concat([pd.read_csv(os.path.join(health_path, f)) for f in files], ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)

        journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))[2]
        journal_emo_counts = pd.Series(journal_emos).value_counts().to_dict()

        grade, danger = calculate_and_assign_grade(
            mood_df, {"journal_emos": journal_emo_counts}, video_json, form_scores, steps, sleep, func_score, pid=pid
        )
        return grade
    except Exception as e:
        print(f"{pid} i√ßin risk hesaplanamadƒ±: {e}")
        return "?"
#-------------------------------------------------------------------------------
def save_patient_grade(pid, grade, danger_score):
    """Hastanƒ±n grade ve danger_score'unu dosyaya kaydeder."""
    grade_path = os.path.join(BASE_DIR, pid, "grade.json")
    with open(grade_path, "w", encoding="utf-8") as f:
        json.dump({"grade": grade, "danger_score": danger_score}, f)

def load_patient_grade(pid):
    """Hastanƒ±n grade ve danger_score'unu dosyadan okur (yoksa None d√∂ner)."""
    grade_path = os.path.join(BASE_DIR, pid, "grade.json")
    if os.path.exists(grade_path):
        try:
            with open(grade_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("grade"), data.get("danger_score")
        except Exception:
            return None, None
    return None, None

def calculate_and_assign_grade(mood_df, nlp_summary, video_json, form_scores, steps, sleep, func_score, pid=None):
    """Tehlike skorunu ve grade'i hesaplar, isterse kaydeder."""
    danger = round(calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, steps, sleep, func_score) * 20, 2)
    if danger < 20:
        grade = "I"
    elif danger < 40:
        grade = "II"
    elif danger < 60:
        grade = "III"
    elif danger < 80:
        grade = "IV"
    else:
        grade = "V"
    if pid:
        save_patient_grade(pid, grade, danger)
    return grade, danger

#-------------------------------------------------------------------------------

# --- generate_daily: Grade I i√ßin d√º≈ü√ºk riskli varyantlar ekle ---üêá
def generate_daily(pid, date, disordered=False, disorder_type=None, forced_grade=None):
    import math
    os.makedirs(os.path.join(BASE_DIR, pid, "mood_tracking"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "journal_entries"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "audio_entries"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "video_analysis"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "emotion_consistency"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "healthkit"), exist_ok=True)

    date_str = date.strftime("%Y%m%d")
    day_index = (date - datetime(2000, 1, 1)).days

    def add_noise(base, min_val, max_val, noise=0.8):
        return round(min(max(random.gauss(base, noise), min_val), max_val), 2)

    def sinusoidal_modulation(day_idx, base, amplitude=0.5, period=30):
        return base + amplitude * math.sin(2 * math.pi * day_idx / period)

    # Geni≈ületilmi≈ü ki≈üilik varyantlarƒ±
    profile_mod = random.choice([
        {"huzur": -0.3, "enerji": -0.4, "depresif": +0.6},
        {"huzur": +0.2, "enerji": +0.5, "anksiyete": -0.3},
        {"depresif": +0.8, "anksiyete": +0.4, "huzur": -0.6},
        {"enerji": +0.3, "√∂fke": +0.3},
        {},
    ])

    # Mood temel deƒüerleri (bozukluk bazlƒ±)üêá
    mood_bases = {
        "Depresyon": {"huzur": 1.5, "enerji": 1.5, "anksiyete": 3.5, "√∂fke": 2.5, "depresif": 4.5},
        "Bipolar": {"huzur": 2, "enerji": 4.5, "anksiyete": 2, "√∂fke": 3, "depresif": 2},
        "Psikotik": {"huzur": 1.5, "enerji": 2, "anksiyete": 5, "√∂fke": 5, "depresif": 3},
        "Anksiyete": {"huzur": 2.5, "enerji": 2, "anksiyete": 5, "√∂fke": 3, "depresif": 3},
        "TSSB": {"huzur": 1.5, "enerji": 2, "anksiyete": 5, "√∂fke": 4, "depresif": 4},
        "OKB": {"huzur": 2.5, "enerji": 3, "anksiyete": 4.5, "√∂fke": 3, "depresif": 2},
        "Normal": {"huzur": 4, "enerji": 4, "anksiyete": 1.5, "√∂fke": 1.5, "depresif": 1.5},
    }

    # Risk profilleri
    risk_profiles = {
        "I":   {"sent": 0.4, "steps": (10000, 13000), "sleep": (7.5, 9)},  # Y√ºksek steps ve uyku ile Grade I daha d√º≈ü√ºk riskli
        "II":  {"sent": 0.2, "steps": (6000, 9000),  "sleep": (6.5, 8)},
        "III": {"sent": -0.1, "steps": (4000, 7000), "sleep": (6, 7.5)},
        "IV":  {"sent": -0.4, "steps": (2000, 5000), "sleep": (5, 7)},
        "V":   {"sent": -0.7, "steps": (500, 2500),  "sleep": (3.5, 6)},
    }

    # Mood ve risk √ºretimi - hem normal hem disordered i√ßin ayrƒ±≈ütƒ±rƒ±lmƒ±≈üüêá
    if not disordered:
        label = "Normal"
        # SADECE GRADE I ve II
        normal_grade = forced_grade if forced_grade in ["I", "II"] else random.choices(["I", "II"], weights=[0.6, 0.4])[0]
        if normal_grade == "I":
            # Grade I i√ßin d√º≈ü√ºk riskli varyant: y√ºksek mood, steps, function
            target_avg = round(random.uniform(4.5, 4.9), 2)
            base_mood = {
                "huzur": 4.7,
                "enerji": 4.6,
                "anksiyete": 1.1,
                "√∂fke": 1.1,
                "depresif": 1.1,
            }
            risk_profile = risk_profiles["I"]
        else:
            target_avg = round(random.uniform(3.5, 3.99), 2)
            base_mood = {
                "huzur": 3.8,
                "enerji": 3.7,
                "anksiyete": 1.4,
                "√∂fke": 1.3,
                "depresif": 1.3,
            }
            risk_profile = risk_profiles["II"]
        mood = {}
        for k in base_mood:
            sin_mod = sinusoidal_modulation(day_index, base_mood[k], amplitude=0.10 if normal_grade == "I" else 0.15, period=14)
            mood[k] = round(min(max(sin_mod, 1), 5), 2)
        current_avg = sum(mood.values()) / len(mood)
        scale = target_avg / current_avg
        for k in mood:
            mood[k] = round(min(max(mood[k] * scale, 1), 5), 2)
        mood["average"] = round(target_avg + random.uniform(-0.03, 0.03), 2) if normal_grade == "I" else round(target_avg + random.uniform(-0.05, 0.05), 2)
        risk_grade = normal_grade

        # Normal bireyler i√ßin dominant ve emo ata
        emo = "mutluluk" if normal_grade == "I" else random.choices(["mutluluk", "n√∂tr"], weights=[3, 2])[0]
        dominant = emo

        print(f"[NORMAL] √úretim ID: {pid} | Target AVG: {target_avg} | Ger√ßek AVG: {mood['average']} | Risk Grade: {risk_grade}")

    else:
        label = disorder_type if disorder_type else "Normal"
        # SADECE GRADE III, IV, V
        target_grade = forced_grade if forced_grade in ["III", "IV", "V"] else random.choices(["III", "IV", "V"], weights=[0.5, 0.3, 0.2])[0]
        if target_grade == "III":
            target_avg = round(random.uniform(2.0, 2.99), 2)
        elif target_grade == "IV":
            target_avg = round(random.uniform(1.5, 1.99), 2)
        else:
            target_avg = round(random.uniform(1.0, 1.49), 2)
        profile_mod = random.choice([
            {"huzur": -0.3, "enerji": -0.4, "depresif": +0.6},
            {"huzur": +0.2, "enerji": +0.5, "anksiyete": -0.3},
            {"depresif": +0.8, "anksiyete": +0.4, "huzur": -0.6},
            {"enerji": +0.3, "√∂fke": +0.3},
            {},
        ])
        base_mood = mood_bases[label]
        mood = {}
        for k in base_mood:
            base_val = base_mood[k] + profile_mod.get(k, 0)
            sin_mod = sinusoidal_modulation(day_index, base_val, amplitude=0.4)
            mood[k] = add_noise(sin_mod, 1, 5)
        current_avg = sum(mood.values()) / len(mood)
        scale = target_avg / current_avg
        for k in mood:
            mood[k] = round(min(max(mood[k] * scale, 1), 5), 2)
        mood["average"] = round(sum(mood.values()) / len(mood), 2)
        risk_grade = target_grade

        emo = random.choices(
            ["mutluluk", "n√∂tr", "kaygƒ±", "√∂fke", "√ºz√ºnt√º"],
            weights=[1, 2, 2, 2, 3]
        )[0]
        dominant = emo

        risk_profile = risk_profiles[risk_grade]

    # --- Risk profiline g√∂re diƒüer parametreler ---üêá
    sent = add_noise(risk_profile["sent"], -1, 1)
    subj = add_noise(0.6 if sent > 0 else 0.8, 0.3, 1.0)
    steps = random.randint(*risk_profile["steps"])
    sleep_hours = round(random.uniform(*risk_profile["sleep"]), 1)

    journal = get_journal(label)
    audio = get_audio(label)
    video_data = get_video_emotion_scores(dominant)

    pd.DataFrame([mood]).to_csv(f"{BASE_DIR}/{pid}/mood_tracking/mood_{date_str}.csv", index=False)
    with open(f"{BASE_DIR}/{pid}/journal_entries/journal_{date_str}.txt", "w", encoding="utf-8") as f:
        f.write(f"Sentiment: {sent}\nSubjectivity: {subj}\nDuygu: {emo}\n\n{journal}")
    with open(f"{BASE_DIR}/{pid}/audio_entries/audio_{date_str}.txt", "w", encoding="utf-8") as f:
        f.write(f"Sentiment: {sent}\nSubjectivity: {subj}\nDuygu: {emo}\n\n{audio}")
    with open(f"{BASE_DIR}/{pid}/video_analysis/video_analysis_{date_str}.json", "w", encoding="utf-8") as f:
        json.dump(video_data, f, indent=2)

    emo_json = {
        "text_emotion": emo,
        "voice_emotion": emo,
        "face_emotion": dominant,
        "uyum_durumu": "D√º≈ü√ºk" if risk_grade in ["IV", "V"] else "Y√ºksek",
        "yorum": "Y√ºksek riskli semptomatik g√∂r√ºn√ºm.",
        "risk_suicidal": (risk_grade == "V"),
        "delusions": (label == "Psikotik"),
        "insight_level": "low" if risk_grade in ["IV", "V"] else "normal"
    }
    with open(f"{BASE_DIR}/{pid}/emotion_consistency/emotion_consistency_{date_str}.json", "w", encoding="utf-8") as f:
        json.dump(emo_json, f, indent=2)

    pd.DataFrame([{
        "date": date.strftime("%Y-%m-%d"),
        "steps": steps,
        "hours": sleep_hours
    }]).to_csv(f"{BASE_DIR}/{pid}/healthkit/manual_entry_{date_str}.csv", index=False)

    # Form skorlarƒ±
    form_scores_dict = {}
    for form in FORM_WEEKLY + FORM_MONTHLY:
        form_path = f"{BASE_DIR}/{pid}/forms/{form}"
        if os.path.exists(form_path):
            form_files = sorted([f for f in os.listdir(form_path) if f.endswith(".json")])
            if form_files:
                with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                    latest_form = json.load(f)
                    form_scores_dict[form] = {
                        "score": latest_form["score"],
                        "severity": latest_form["severity"]
                    }

    functioning_score = calculate_functioning_score(
        steps=steps,
        sleep_hours=sleep_hours,
        mood_avg=mood["average"],
        journal_sent=sent,
        audio_sent=sent,
        dominant_emotion=dominant,
        form_scores=form_scores_dict
    )

    os.makedirs(f"{BASE_DIR}/{pid}/functioning_score", exist_ok=True)
    pd.DataFrame([{"date": date.strftime("%Y-%m-%d"), "score": functioning_score}]).to_csv(
        f"{BASE_DIR}/{pid}/functioning_score/functioning_{date_str}.csv", index=False)

    # --- Grade ve danger_score'u kaydet (her g√ºn sonu g√ºncel) ---
    # Mood_df, nlp_summary, video_json, form_scores_dict, steps, sleep_hours, functioning_scoreüêáüêáüêá
    mood_df = pd.DataFrame([mood])
    nlp_summary = {"journal_emos": {emo: 1}}
    grade, danger = calculate_and_assign_grade(
        mood_df, nlp_summary, video_data, form_scores_dict, steps, sleep_hours, functioning_score, pid=pid
    )

    print(f"[üß™ TEST LOG] {pid} | forced_grade: {forced_grade} | risk_grade: {risk_grade} | disordered: {disordered} | grade: {grade} | danger: {danger}")
#-------------------------------------------------------------------------------

def generate_forms(pid, date, disordered=False, disorder_type=None):
    
    date_str = date.strftime("%Y%m%d")
    day_index = (date.date() - datetime(2000, 1, 1).date()).days

    # Her hastaya √∂zg√º ki≈üisel varyasyon (sabitlemek i√ßin random.seed kullanƒ±labilir)
    form_traits = {
        "PHQ9": random.uniform(0.8, 1.2),
        "GAD7": random.uniform(0.7, 1.3),
        "PSS10": random.uniform(0.7, 1.2),
        "PSQI": random.uniform(0.8, 1.4),
        "IESR": random.uniform(0.7, 1.5),
    }

    # Hastalƒ±k t√ºr√ºne g√∂re form odaklarƒ±
    base_scores = {
        "PHQ9": 4,
        "GAD7": 3,
        "PSS10": 5,
        "PSQI": 4,
        "IESR": 4,
    }

    if disordered and disorder_type:
        if disorder_type == "Depresyon":
            base_scores["PHQ9"] = 15
            base_scores["PSS10"] = 12
        elif disorder_type == "Anksiyete":
            base_scores["GAD7"] = 14
            base_scores["PSQI"] = 9
        elif disorder_type == "TSSB":
            base_scores["IESR"] = 20
            base_scores["PSQI"] = 10
        elif disorder_type == "Psikotik":
            base_scores["PHQ9"] = 18
            base_scores["GAD7"] = 12
        elif disorder_type == "OKB":
            base_scores["GAD7"] = 14
            base_scores["IESR"] = 18
        elif disorder_type == "Bipolar":
            base_scores["PHQ9"] = 12
            base_scores["PSS10"] = 11

    # Mood etkisi (o g√ºnk√º ortalama mood deƒüeri)
    mood_path = f"{BASE_DIR}/{pid}/mood_tracking/mood_{date_str}.csv"
    mood_avg = 3
    if os.path.exists(mood_path):
        try:
            mood_df = pd.read_csv(mood_path)
            mood_avg = mood_df["average"].values[0]
        except:
            pass

    # Mood k√∂t√º ise form skorlarƒ±nƒ± %10-30 artƒ±r
    mood_modifier = 1.0
    if mood_avg < 2.5:
        mood_modifier += 0.2
    elif mood_avg < 2.0:
        mood_modifier += 0.4

    # ≈ûiddet belirleme fonksiyonu
    def determine_severity(score, thresholds):
        if score < thresholds[0]:
            return "normal"
        elif score < thresholds[1]:
            return "hafif"
        elif score < thresholds[2]:
            return "orta"
        else:
            return "y√ºksek"

    form_definitions = {
        "PHQ9": [5, 10, 15],
        "GAD7": [5, 10, 15],
        "PSS10": [10, 20, 30],
        "PSQI": [5, 10, 15],
        "IESR": [12, 24, 36]
    }

    # Haftalƒ±k formlar ‚Üí Pazartesi
    if date.weekday() == 0:
        for form in FORM_WEEKLY:
            base = base_scores[form]
            trait = form_traits[form]
            sin = 1 + 0.2 * math.sin(2 * math.pi * day_index / 14)
            noise = random.gauss(0, 1.5)
            score = round((base * trait * mood_modifier * sin) + noise)
            score = int(max(0, min(score, 27)))  # PHQ9 & GAD7 max 27
            severity = determine_severity(score, form_definitions[form])
            out = {"date": date.strftime("%Y-%m-%d"), "score": score, "severity": severity}
            path = f"{BASE_DIR}/{pid}/forms/{form}/form_{date_str}.json"
            with open(path, "w", encoding="utf-8") as f:
                json.dump(out, f, indent=2)

    # Aylƒ±k formlar ‚Üí Ayƒ±n ilk g√ºn√ºüêáüêá
    if date.day == 1:
        for form in FORM_MONTHLY:
            base = base_scores[form]
            trait = form_traits[form]
            sin = 1 + 0.15 * math.sin(2 * math.pi * day_index / 30)
            noise = random.gauss(0, 2.0)
            score = round((base * trait * mood_modifier * sin) + noise)
            score = int(max(0, min(score, 42)))  # PSQI & IESR max
            severity = determine_severity(score, form_definitions[form])
            out = {"date": date.strftime("%Y-%m-%d"), "score": score, "severity": severity}
            path = f"{BASE_DIR}/{pid}/forms/{form}/form_{date_str}.json"
            with open(path, "w", encoding="utf-8") as f:
                json.dump(out, f, indent=2)

def train_and_save_model():
    patients = sorted(os.listdir(BASE_DIR))
    X, y = [], []

    for pid in patients:
        # Her hasta i√ßin √∂z nitelikleri ve sƒ±nƒ±fƒ± al
        try:
            base = os.path.join(BASE_DIR, pid)
            # ... aynƒ± X, y olu≈üturma kodlarƒ± burada ...
        except Exception as e:
            print(f"{pid} atlanƒ±yor: {e}")
    
    if not X:
        print("Yeterli veri yok.")
        return

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)

    # Modeli kaydet
    with open("random_forest_risk_model.pkl", "wb") as f:
        pickle.dump(model, f)

    print("‚úÖ Random Forest modeli ba≈üarƒ±yla kaydedildi.")

def extract_nlp_stats(filepath):
    sent, subj, emo = None, None, None
    try:
        with open(filepath, encoding='utf-8') as f:
            text = f.read().lower()

            # T√ºrk√ße kar≈üƒ±lƒ±klarƒ± da yakalayacak ≈üekilde d√ºzenlendiüêáüêá
            sent_match = re.search(r'(sentiment|duygu skoru)[:Ôºö]?\s*([-+]?\d*\.\d+|\d+)', text)
            subj_match = re.search(r'(subjectivity|√∂znelik)[:Ôºö]?\s*([-+]?\d*\.\d+|\d+)', text)
            emo_match = re.search(r'duygu[:Ôºö]?\s*(mutluluk|√ºz√ºnt√º|√∂fke|kaygƒ±|n√∂tr)', text)

            if sent_match:
                sent = float(sent_match.group(2))
            if subj_match:
                subj = float(subj_match.group(2))
            if emo_match:
                emo = emo_match.group(1).strip()

    except Exception as e:
        print(f"Error reading file {filepath}: {e}")
    return sent, subj, emo

def collect_nlp_stats(folder):
    sentiments, subjectivities, emotions = [], [], []
    if not os.path.exists(folder):
        return sentiments, subjectivities, emotions

    files = sorted([f for f in os.listdir(folder) if f.endswith(".txt")])
    for filename in files:
        filepath = os.path.join(folder, filename)
        s, j, e = extract_nlp_stats(filepath)
        if s is not None:
            sentiments.append(s)
        if j is not None:
            subjectivities.append(j)
        if e is not None:
            emotions.append(e)
    return sentiments, subjectivities, emotions

def read_last_lines(folder, lines=10, base_dir=None):
    """Read the last N lines from the most recent file in the specified folder.
    
    Args:
        folder (str): Folder path relative to base directory
        lines (int): Number of lines to read from end
        base_dir (str): Base directory path
        
    Returns:
        str: Last N lines joined with newlines, or empty string if no files
    """
    try:
        path = os.path.join(base_dir if base_dir else BASE_DIR, folder)
        if not os.path.exists(path):
            return ""
            
        files = sorted(os.listdir(path))
        if not files:
            return ""
            
        latest_file = os.path.join(path, files[-1])
        with open(latest_file, "r", encoding="utf-8") as f:
            # Read all lines and get last N
            all_lines = f.read().splitlines()
            return "\n".join(all_lines[-lines:])
            
    except Exception as e:
        print(f"Error reading from {folder}: {str(e)}")
        return ""

def format_clinical_summary(text):
    """OpenAI'dan gelen ham metni d√ºzenli HTML formatƒ±na d√∂n√º≈üt√ºr√ºr."""
    if not text:
        return ""
        
    # Ba≈ülƒ±klarƒ± i≈üaretle (√∂nce 4. seviye, sonra 3. seviye)üêáüêá
    text = re.sub(r'^\s*####\s+([0-9]+\.[0-9]+.*?)\s*$', r'<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">\1</h4>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*###\s+([0-9]+\. .*?)\s*$', r'<h3 style="margin-top: 16px; margin-bottom: 8px;">\1</h3>', text, flags=re.MULTILINE)
    
    # Paragraflarƒ± HTML paragraf taglarƒ±na √ßevir
    paragraphs = []
    current_content = ""
    for line in text.split('\n'):
        if line.strip().startswith('<h'):
            if current_content.strip():
                paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
                current_content = ""
            paragraphs.append(line.strip())
        elif line.strip():
            if current_content:
                current_content += " " + line.strip()
            else:
                current_content = line.strip()
        else:
            if current_content.strip():
                paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
                current_content = ""
    if current_content.strip():
        paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
    # 11. Literat√ºr Referanslarƒ± ba≈ülƒ±ƒüƒ±nƒ± ve i√ßeriƒüini tamamen kaldƒ±r
    new_paragraphs = []
    skip = False
    for p in paragraphs:
        if re.search(r'<h3.*?>11\. Literat√ºr Referanslarƒ±<\/h3>', p):
            skip = True
            continue
        if skip:
            # Bir sonraki paragraf da referans i√ßeriƒüi olabilir, onu da atla
            skip = False
            continue
        new_paragraphs.append(p)
    return "".join(new_paragraphs)
    

def calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score=50):
    """Calculate patient danger level based on multiple factors.
    
    Args:
        mood_df (pandas.DataFrame): Mood tracking data
        nlp_summary (dict): NLP analysis summary
        video_json (dict): Video analysis data
        form_scores (dict): Psychometric test scores
        avg_steps (int/float/str): Average daily steps
        avg_sleep (int/float/str): Average daily sleep hours
        functioning_score (int): Patient functioning score (0-100)
        
    Returns:
        int: Danger level score (1-5)
    """
    weights = {
        "mood": 0.20,
        "nlp": 0.20,
        "video": 0.15,
        "forms": 0.15,
        "health": 0.10,
        "functioning": 0.20  # ƒ∞≈ülevsellik skoru i√ßin aƒüƒ±rlƒ±k eklendi
    }

    # Default values for error casesüêáüêá
    mood_score = 3
    nlp_score = 3
    video_score = 3
    form_scores_avg = 3
    health_score = 3
    func_score = 3  # Default functioning score deƒüeri

    # Calculate mood scoreüêá
    try:
        mood_avg = mood_df.iloc[0]["average"]
        mood_score = 5 - (mood_avg - 1)
    except Exception as e:
        print(f"Error calculating mood score: {e}")

    # Calculate NLP scoreüêá
    try:
        nlp_emos = nlp_summary["journal_emos"]
        negative_emotions = sum(nlp_emos.get(e, 0) for e in ["√ºz√ºnt√º", "√∂fke", "kaygƒ±"])
        total_emotions = sum(nlp_emos.values())
        nlp_score = (negative_emotions / total_emotions) * 5 if total_emotions > 0 else 1
    except Exception as e:
        print(f"Error calculating NLP score: {e}")

    # Calculate video scoreüêá
    try:
        dominant_emotion = video_json["dominant_emotion"]
        video_score = 5 if dominant_emotion in ["√ºz√ºnt√º", "√∂fke", "kaygƒ±"] else 1
    except Exception as e:
        print(f"Error calculating video score: {e}")

    # Calculate form scoreüêá
    try:
        form_severity_map = {"hafif": 1, "orta": 3, "y√ºksek": 5}
        if form_scores and len(form_scores) > 0:
            form_scores_avg = sum(form_severity_map.get(form["severity"], 3) for form in form_scores.values()) / len(form_scores)
        else:
            form_scores_avg = 3
    except Exception as e:
        print(f"Error calculating form score: {e}")

    # Calculate health scoreüêá
    try:
        health_score = 5
        if isinstance(avg_steps, (int, float)) and isinstance(avg_sleep, (int, float)):
            if avg_steps > 8000 and avg_sleep >= 7:
                health_score = 1
            elif avg_steps > 6000 and avg_sleep >= 6.5:
                health_score = 2
            elif avg_steps > 5000 and avg_sleep >= 6:
                health_score = 3
            else:
                health_score = 4
    except Exception as e:
        print(f"Error calculating health score: {e}")

    # Calculate functioning score (ters orantƒ±lƒ± - d√º≈ü√ºk i≈ülevsellik = y√ºksek risk)üêá
    try:
        func_score = 5 - (functioning_score / 20)  # 0-100 arasƒ± deƒüeri 0-5 arasƒ± deƒüere d√∂n√º≈üt√ºr
    except Exception as e:
        print(f"Error calculating functioning score: {e}")

    # Calculate overall danger level
    danger_level = (
        weights["mood"] * mood_score +
        weights["nlp"] * nlp_score +
        weights["video"] * video_score +
        weights["forms"] * form_scores_avg +
        weights["health"] * health_score +
        weights["functioning"] * func_score  # ƒ∞≈ülevsellik skoru eklendi
    )
    return round(danger_level)

def train_random_forest_model(pid):
    import plotly.io as pio
    pio.kaleido.scope.default_format = "png"  # plotly grafiklerinin d√ºzg√ºn kaydedilmesi i√ßinüêá

    # SHAP dosya yollarƒ±nƒ± hazƒ±rla
    BASE_PATH = Path(BASE_DIR).absolute()  # üîí Mutlak yolüêá

    shap_folder = BASE_PATH / pid / "gpt_analysis"
    shap_folder.mkdir(parents=True, exist_ok=True)

    date_str = datetime.now().strftime("%Y%m%d")
    shap_image_path = shap_folder / f"shap_waterfall_{date_str}.png"
    shap_bar_path   = shap_folder / f"shap_bar_{date_str}.png"
    shap_txt_path   = shap_folder / f"shap_ai_comment_{date_str}.txt"

    os.makedirs(shap_folder, exist_ok=True)

    model_path = "random_forest_risk_model.pkl"
    if not os.path.exists(model_path):
        st.warning("‚ö†Ô∏è Model hen√ºz eƒüitilmemi≈ü. L√ºtfen modeli √∂nce eƒüitin.")
        return

    with open(model_path, "rb") as f:
        model = pickle.load(f)

    if all(os.path.exists(p) for p in [shap_image_path, shap_bar_path, shap_txt_path]):
        st.subheader("üìä √ñnceki SHAP Sonu√ßlarƒ±")
        st.image(shap_image_path, caption="üîÅ Kayƒ±tlƒ± SHAP Waterfall Grafiƒüi", use_column_width=True)
        st.image(shap_bar_path, caption="üîÅ Kayƒ±tlƒ± SHAP Bar Grafiƒüi", use_column_width=True)
        st.markdown("### ü§ñ Kayƒ±tlƒ± SHAP AI Yorum")
        with open(shap_txt_path, "r", encoding="utf-8") as f:
            st.markdown(f.read())
        return

    base = os.path.join(BASE_DIR, pid)

    try:
        mood_df = pd.read_csv(os.path.join(base, "mood_tracking", sorted(os.listdir(os.path.join(base, "mood_tracking")))[-1]))
        mood_avg = mood_df["average"].values[0]
    except:
        mood_avg = 3.0

    try:
        func_df = pd.read_csv(os.path.join(base, "functioning_score", sorted(os.listdir(os.path.join(base, "functioning_score")))[-1]))
        func_score = func_df["score"].values[0]
    except:
        func_score = 50.0

    try:
        health_path = os.path.join(base, "healthkit")
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
        df = pd.concat(df_list, ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)
    except:
        steps, sleep = 5000, 6.0

    form_values = {"PHQ9": 0, "GAD7": 0, "PSS10": 0, "PSQI": 0, "IESR": 0}
    for form in FORM_WEEKLY + FORM_MONTHLY:
        try:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_values[form] = latest_form["score"]
        except:
            pass

    features = [
        mood_avg, steps, sleep,
        form_values["PHQ9"], form_values["GAD7"],
        form_values["PSS10"], form_values["PSQI"],
        form_values["IESR"], func_score
    ]
    feature_names = ["mood_avg", "steps", "sleep", "PHQ9", "GAD7", "PSS10", "PSQI", "IESR", "functioning"]
    features_df = pd.DataFrame([features], columns=feature_names)

    st.subheader("üìâ SHAP Risk A√ßƒ±klamasƒ±")

    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(features_df)
        proba = model.predict_proba(features_df)[0]
        predicted_class_index = int(np.argmax(proba))

        shap_val = shap_values[predicted_class_index][0] if isinstance(shap_values, list) else shap_values[0]
        base_val = explainer.expected_value[predicted_class_index] if isinstance(shap_values, list) else explainer.expected_value

        if isinstance(shap_val, np.ndarray) and shap_val.ndim == 1:
            shap_val = shap_val[np.newaxis, :]
            base_val = np.array([base_val]) if np.isscalar(base_val) else np.array(base_val)[np.newaxis]

        shap_exp = shap.Explanation(
            values=shap_val,
            base_values=base_val,
            data=features_df.values,
            feature_names=features_df.columns.tolist()
        )

        # üîΩ SHAP Waterfall Kaydet ve G√∂sterüêá
        plt.figure()
        shap.plots.waterfall(shap_exp[0], max_display=9, show=False)
        plt.tight_layout()
        plt.savefig(shap_image_path, bbox_inches="tight", dpi=300)
        st.image(shap_image_path, caption="SHAP Waterfall Grafiƒüi")
        plt.close()

        # üîΩ SHAP Bar Kaydet ve G√∂ster (plotly)üêá
        df_shap = pd.DataFrame({
            "feature": features_df.columns,
            "shap_value": shap_exp[0].values
        }).sort_values("shap_value", ascending=True)

        fig_bar = px.bar(df_shap,
                         x="shap_value", y="feature",
                         orientation="h",
                         title="SHAP Deƒüerleri")
        fig_bar.write_image(shap_bar_path, scale=2)
        st.image(shap_bar_path, caption="SHAP Bar Grafiƒüi")

        # √ñzellik Listesi
        st.markdown("**üîë √ñzellikler:** " + "  |  ".join(features_df.columns))

        # ü§ñ SHAP AI Yorumüêáüêáüêá
        st.markdown("### ü§ñ SHAP AI Yorum")
        ai_prompt = (
            "Sen klinik psikiyatri alanƒ±nda uzman, akademik yayƒ±nlar yapan bir profes√∂rs√ºn. "
            "SHAP (SHapley Additive exPlanations) analizine dayanarak, bir makine √∂ƒürenimi modeli tarafƒ±ndan yapƒ±lan risk tahminlerinde "
            "a≈üaƒüƒ±daki 9 psikiyatrik ve davranƒ±≈üsal √∂zelliƒüin etkisini yorumlaman bekleniyor.\n\n"
            "üìä Modelde yer alan deƒüi≈ükenler ve grafiklerdeki g√∂sterimleri:\n" +
            ", ".join([f"{feat} ({feat})" for feat in features_df.columns]) +
            "\n\n"
            f"üìà SHAP Deƒüerleri:\n{json.dumps(dict(zip(features_df.columns, shap_exp[0].values)), ensure_ascii=False, indent=2)}\n\n"
            "Her bir √∂zelliƒüin SHAP deƒüerinin pozitif veya negatif olmasƒ± durumunun model tahmini a√ßƒ±sƒ±ndan ne anlama geldiƒüini detaylandƒ±r. "
            "A√ßƒ±klamalarƒ±nƒ± bilimsel literat√ºre ve klinik deneyime dayandƒ±r. SHAP deƒüerlerinin y√ºksekliƒüi veya d√º≈ü√ºkl√ºƒü√º model tahmininde "
            "hangi deƒüi≈ükenlerin belirleyici olduƒüunu a√ßƒ±kla.\n\n"
            "Her √∂zellik i√ßin a≈üaƒüƒ±daki gibi yorum yap:\n"
            "- √ñzellik adƒ±\n"
            "- SHAP deƒüeri\n"
            "- Klinik etkisi (√∂rnek: depresyon, anksiyete, i≈ülevsellik baƒülamƒ±nda)\n"
            "- Pozitif/negatif katkƒ± durumu ve anlamƒ±\n"
            "- Gerekirse klinik √∂rnek\n\n"
            "Yanƒ±tlarƒ±nƒ± 9 √∂zellik i√ßin sƒ±ralƒ± ve madde madde ver. Psikiyatristlerin anlayabileceƒüi teknik, ancak sade ve akademik bir dil kullan."
        )
        yorum = stream_chat_completion(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen klinik psikiyatri uzmanƒ±sƒ±n‚Ä¶"},
                {"role": "user", "content": ai_prompt}
            ],
            temperature=0.5,
            max_tokens=2048
        )
        st.markdown(yorum)
        with open(shap_txt_path, "w", encoding="utf-8") as f:
            f.write(yorum)

        # Grade tahmini
        st.markdown("### üîç Random Forest Tahmini")
        st.markdown(f"**Grade {model.predict(features_df)[0]}**")

    except Exception as e:
        st.error(f"SHAP a√ßƒ±klamasƒ± olu≈üturulurken hata olu≈ütu: {str(e)}")

    #*********************************************************************  

def show_all_heatmaps(pid, category=None):
    base = os.path.join(BASE_DIR, pid)
    
    def plot_heatmap(df, title):
        if df is None or df.empty:
            st.info(f"{title} i√ßin veri yok.")
            return
        df_m = df.melt(id_vars="date", var_name="Kategori", value_name="Deƒüer")
        fig = px.density_heatmap(df_m, x="date", y="Kategori", z="Deƒüer",
                                 color_continuous_scale="RdBu_r", title=title)
        fig.update_layout(height=450, xaxis_title="Tarih", yaxis_title="Kategori")
        st.plotly_chart(fig, use_container_width=True)


#********************************************************************************************

    def load_time_series_csv(folder, col="score"):
        p = os.path.join(base, folder)
        if not os.path.exists(p): return None
        files = sorted(glob.glob(os.path.join(p, "*.csv")))
        if not files: return None
        df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
        df["date"] = pd.to_datetime(df["date"])
        return df[["date", col]] if col in df.columns else None

    def load_json_form(form):
        p = os.path.join(base, f"forms/{form}")
        if not os.path.exists(p): return None
        files = sorted(glob.glob(os.path.join(p, "*.json")))
        if not files: return None
        data = [json.load(open(f, encoding="utf-8")) for f in files]
        df = pd.DataFrame(data)
        df["date"] = pd.to_datetime(df["date"])
        return df[["date", "score"]].sort_values("date")

    def add_nlp_heatmaps(folder, label):
        from collections import defaultdict

        def extract_nlp_stats(filepath):
            with open(filepath, "r", encoding="utf-8") as f:
                lines = f.readlines()
                sent = subj = None
                emotion = None
                for l in lines:
                    if "Sentiment:" in l:
                        sent = float(l.split(":")[-1].strip())
                    elif "Subjectivity:" in l:
                        subj = float(l.split(":")[-1].strip())
                    elif "Duygu:" in l:
                        emotion = l.split(":")[-1].strip()
                return sent, subj, emotion

        sentiment_data, subjectivity_data = [], []
        emotion_data = defaultdict(list)

        files = sorted([f for f in os.listdir(folder) if f.endswith(".txt")])
        for file in files:
            date_str = file.split("_")[-1].split(".")[0]
            date = datetime.strptime(date_str, "%Y%m%d").date()
            sent, subj, emo = extract_nlp_stats(os.path.join(folder, file))
            if sent is not None:
                sentiment_data.append({"date": date, "Sentiment": sent})
            if subj is not None:
                subjectivity_data.append({"date": date, "Subjectivity": subj})
            if emo:
                emotion_data[emo].append(date)

        if sentiment_data:
            df_sent = pd.DataFrame(sentiment_data)
            plot_heatmap(df_sent, f"üìò Sentiment Skoru ({label})")

        if subjectivity_data:
            df_subj = pd.DataFrame(subjectivity_data)
            plot_heatmap(df_subj, f"üìó Subjectivity Skoru ({label})")

        if emotion_data:
            emo_dates = []
            for emo, dates in emotion_data.items():
                for d in dates:
                    emo_dates.append({"date": d, "Duygu": emo})
            df_emo = pd.DataFrame(emo_dates)
            df_emo["count"] = 1
            df_pivot = df_emo.groupby(["date", "Duygu"]).count().reset_index()
            df_pivot = df_pivot.rename(columns={"count": "Deƒüer"})
            fig = px.density_heatmap(df_pivot, x="date", y="Duygu", z="Deƒüer",
                                      color_continuous_scale="Reds",
                                      title=f"üìô Duygusal Yoƒüunluk ({label})")
            st.plotly_chart(fig, use_container_width=True)

    # 1) Mood Takibiüêá
    if category in (None, "Mood") or category == "Mood":
        mood_path = os.path.join(base, "mood_tracking")
        mood_files = sorted(glob.glob(os.path.join(mood_path, "*.csv")))
        mood_data = []
        for f in mood_files:
            d = datetime.strptime(f.split("_")[-1].split(".")[0], "%Y%m%d")
            df = pd.read_csv(f)
            df["date"] = d
            mood_data.append(df)
        if mood_data:
            df_mood = pd.concat(mood_data, ignore_index=True)
            df_mood = df_mood.drop(columns=["uid", "disorder"], errors="ignore")
            plot_heatmap(df_mood, "üß† Mood Takibi (Duygusal Deƒüi≈üim)")

    # 2) ƒ∞≈ülevselliküêá
    if category in (None, "Functioning") or category == "Functioning":
        df_func = load_time_series_csv("functioning_score")
        if df_func is not None:
            df_func = df_func.rename(columns={"score": "ƒ∞≈ülevsellik"})
            plot_heatmap(df_func, "‚öñÔ∏è ƒ∞≈ülevsellik Skoru")

    # 3) Fiziksel Aktivite ve Uykuüêá
    if category in (None, "Health") or category == "Health":
        df_health = load_time_series_csv("healthkit", col="steps")
        if df_health is not None:
            plot_heatmap(df_health.rename(columns={"steps": "Adƒ±m"}), "üèÉ Adƒ±m Sayƒ±sƒ±")
        df_sleep = load_time_series_csv("healthkit", col="hours")
        if df_sleep is not None:
            plot_heatmap(df_sleep.rename(columns={"hours": "Uyku"}), "üõå Uyku S√ºresi")

    # 4) Test Skorlarƒ±üêá
    if category in (None, "Forms") or category == "Forms":
        for form in FORM_WEEKLY + FORM_MONTHLY:
            df_form = load_json_form(form)
            if df_form is not None:
                plot_heatmap(df_form.rename(columns={"score": form}), f"üìù {form} Skoru")

    # 5) Journal NLPüêá
    if category in (None, "Journal") or category == "Journal":
        add_nlp_heatmaps(os.path.join(base, "journal_entries"), "Journal")

    # 6) Audio NLPüêá
    if category in (None, "Audio") or category == "Audio":
        add_nlp_heatmaps(os.path.join(base, "audio_entries"), "Audio")

    # 7) Video Analysis - Bu kodu show_all_heatmaps fonksiyonuna ekleyin (Audio kategorisinden sonra)üêá
    if category in (None, "Video") or category == "Video":
        video_path = os.path.join(base, "video_analysis")
        if os.path.exists(video_path):
            video_files = sorted(glob.glob(os.path.join(video_path, "*.json")))
            if video_files:
                data = []
                dates = []
                for f in video_files:
                    date_str = f.split("_")[-1].split(".")[0]
                    date = datetime.strptime(date_str, "%Y%m%d").date()
                    dates.append(date)
                    with open(f, "r", encoding="utf-8") as file:
                        v_data = json.load(file)
                        for emotion, score in v_data["emotion_scores"].items():
                            data.append({"date": date, "Duygu": emotion, "Deƒüer": score})
                
                if data:
                    df_video = pd.DataFrame(data)
                    # Duygu deƒüerlerini zaman serisi boyunca g√∂rselle≈ütirüêá
                    fig = px.density_heatmap(df_video, x="date", y="Duygu", z="Deƒüer",
                                        color_continuous_scale="Viridis", 
                                        title="üìπ Video Duygu Analizi Zaman Serisi")
                    fig.update_layout(height=450, xaxis_title="Tarih", yaxis_title="Duygu")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("üì≠ Video analiz verilerinde duygu skoru bulunamadƒ±.")
            else:
                st.info("üì≠ Video analiz dosyasƒ± hen√ºz mevcut deƒüil.")
        else:
            st.info("üìÅ Video analiz klas√∂r√º hen√ºz olu≈üturulmamƒ±≈ü.")
  
  
# Basitle≈ütirilmi≈ü tamamlayƒ±cƒ± fonksiyonüêá
def stream_chat_completion(**kwargs):
    kwargs["stream"] = False
    response = openai.ChatCompletion.create(**kwargs)
    return response["choices"][0]["message"]["content"]


# RANDOM FOREST SHAP A√áIKLAMASI VE GRAFƒ∞KLERüêá
def explain_patient_with_rf_and_shap(pid):
    # Dosya yollarƒ±
    BASE_PATH = Path(BASE_DIR).absolute()
    shap_folder = BASE_PATH / pid / "gpt_analysis"
    shap_folder.mkdir(parents=True, exist_ok=True)

    date_str = datetime.now().strftime("%Y%m%d")
    shap_image_path = shap_folder / f"shap_waterfall_{date_str}.png"
    shap_bar_path = shap_folder / f"shap_bar_{date_str}.png"
    shap_txt_path = shap_folder / f"shap_ai_comment_{date_str}.txt"

    # Modeli y√ºkle
    try:
        with open("random_forest_risk_model.pkl", "rb") as f:
            model = pickle.load(f)
    except Exception as e:
        st.error(f"Model y√ºklenemedi: {e}")
        return

    # Verileri oku
    try:
        mood_df = pd.read_csv(BASE_PATH / pid / "mood_tracking" / sorted(os.listdir(BASE_PATH / pid / "mood_tracking"))[-1])
        mood_avg = mood_df["average"].values[0]
    except:
        mood_avg = 3.0

    try:
        func_df = pd.read_csv(BASE_PATH / pid / "functioning_score" / sorted(os.listdir(BASE_PATH / pid / "functioning_score"))[-1])
        func_score = func_df["score"].values[0]
    except:
        func_score = 50.0

    try:
        health_path = BASE_PATH / pid / "healthkit"
        files = sorted(f for f in os.listdir(health_path) if f.endswith(".csv"))
        df_list = [pd.read_csv(health_path / f) for f in files]
        df = pd.concat(df_list, ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)
    except:
        steps, sleep = 5000, 6.0

    form_values = dict.fromkeys(FORM_WEEKLY + FORM_MONTHLY, 0)
    for form in form_values:
        try:
            form_path = BASE_PATH / pid / "forms" / form
            latest = sorted(os.listdir(form_path))[-1]
            with open(form_path / latest, encoding="utf-8") as f:
                form_values[form] = json.load(f)["score"]
        except:
            pass

    features = [mood_avg, steps, sleep] + [form_values[f] for f in FORM_WEEKLY+FORM_MONTHLY] + [func_score]
    cols = ["mood_avg", "steps", "sleep"] + FORM_WEEKLY + FORM_MONTHLY + ["functioning"]
    features_df = pd.DataFrame([features], columns=cols)

    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(features_df)
        proba = model.predict_proba(features_df)[0]
        idx = int(np.argmax(proba))

        val, base = (shap_values[idx][0], explainer.expected_value[idx]) if isinstance(shap_values, list) else (shap_values[0], explainer.expected_value)

        if val.ndim == 1:
            val = val[np.newaxis, :]
            base = np.array([base])

        exp = shap.Explanation(
            values=val,
            base_values=base,
            data=features_df.values,
            feature_names=features_df.columns.tolist()
        )
        to_plot = exp[0]

        st.subheader("üßê SHAP A√ßƒ±klamasƒ± (RF Modeli)")

        # Waterfall
        plt.figure()
        shap.plots.waterfall(to_plot, show=False)
        plt.tight_layout()
        plt.savefig(str(shap_image_path), bbox_inches="tight", dpi=300)
        st.image(str(shap_image_path), caption="SHAP Waterfall")
        plt.close()

        # Bar
        plt.figure()
        shap.plots.bar(to_plot, show=False)
        plt.tight_layout()
        plt.savefig(str(shap_bar_path), bbox_inches="tight", dpi=300)
        st.image(str(shap_bar_path), caption="SHAP Bar")
        plt.close()

        features_list = features_df.columns.tolist()
        features_str = "  |  ".join([f"{feat} ({feat})" for feat in features_list])
        st.markdown(f"**üîë √ñzellikler:** {features_str}")

        shap_dict = dict(zip(features_df.columns, to_plot.values))
        ai_prompt = (
            "Sen klinik psikiyatri alanƒ±nda uzman, akademik yayƒ±nlar yapan bir profes√∂rs√ºn. "
            "SHAP (SHapley Additive exPlanations) analizine dayanarak, bir makine √∂ƒürenimi modeli tarafƒ±ndan yapƒ±lan risk tahminlerinde "
            "a≈üaƒüƒ±daki 9 psikiyatrik ve davranƒ±≈üsal √∂zelliƒüin etkisini yorumlaman bekleniyor.\n\n"
            "üìä Modelde yer alan deƒüi≈ükenler ve grafiklerdeki g√∂sterimleri:\n" +
            ", ".join([f"{feat} ({feat})" for feat in features_df.columns]) +
            "\n\n"
            f"üìà SHAP Deƒüerleri:\n{json.dumps(shap_dict, ensure_ascii=False, indent=2)}\n\n"
            "Her bir √∂zelliƒüin SHAP deƒüerinin pozitif veya negatif olmasƒ± durumunun model tahmini a√ßƒ±sƒ±ndan ne anlama geldiƒüini detaylandƒ±r. "
            "A√ßƒ±klamalarƒ±nƒ± bilimsel literat√ºre ve klinik deneyime dayandƒ±r. SHAP deƒüerlerinin y√ºksekliƒüi veya d√º≈ü√ºkl√ºƒü√º model tahmininde "
            "hangi deƒüi≈ükenlerin belirleyici olduƒüunu a√ßƒ±kla.\n\n"
            "Her √∂zellik i√ßin a≈üaƒüƒ±daki gibi yorum yap:\n"
            "- √ñzellik adƒ±\n"
            "- SHAP deƒüeri\n"
            "- Klinik etkisi (" "√∂rnek: depresyon, anksiyete, i≈ülevsellik baƒülamƒ±nda)\n"
            "- Pozitif/negatif katkƒ± durumu ve anlamƒ±\n"
            "- Gerekirse klinik √∂rnek\n\n"
            "Yanƒ±tlarƒ±nƒ± 9 √∂zellik i√ßin sƒ±ralƒ± ve madde madde ver. Psikiyatristlerin anlayabileceƒüi teknik, ancak sade ve akademik bir dil kullan."
        )

        ai_resp = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen bir √ºniversite hastanesinde g√∂rev yapan deneyimli bir klinik psikiyatri profes√∂r√ºs√ºn. Aynƒ± zamanda yapay zek√¢ ve makine √∂ƒürenimi uygulamalarƒ± konusunda akademik √ßalƒ±≈ümalar y√ºr√ºt√ºyorsun."},
                {"role": "user", "content": ai_prompt}
            ],
            temperature=0.5,
            max_tokens=4000
        )
        ai_text = ai_resp.choices[0].message.content.strip()
        st.markdown("### ü§ñ SHAP AI Yorum")
        st.markdown(ai_text)

        with open(shap_txt_path, "w", encoding="utf-8") as f:
            f.write(ai_text)

    except Exception as e:
        st.error(f"SHAP a√ßƒ±klamasƒ± olu≈üturulurken hata olu≈ütu: {e}")

def run_psychiatrist_bot(selected):
    """Run the psychiatrist chatbot for selected patient.
    
    Args:
        selected (str): Patient ID
    """
    # Initialize session state if neededüêá
    if "psychat_history" not in st.session_state:
        st.session_state.psychat_history = []
    
    # Limit message historyüêá
    if len(st.session_state.psychat_history) > 10:  # Limit to last 10 messages
        st.session_state.psychat_history = st.session_state.psychat_history[-10:]
    
    base = os.path.join(BASE_DIR, selected)
    
    # Initialize required variables with default valuesüêá
    mood_df = None
    video_json = {"dominant_emotion": "n√∂tr", "emotion_scores": {"n√∂tr": 1.0}}
    emo_json = {"text_emotion": "n√∂tr", "voice_emotion": "n√∂tr", "face_emotion": "n√∂tr"}
    form_scores = {}
    
    try:
        # Load mood data
        mood_files = sorted(os.listdir(os.path.join(base, "mood_tracking")))
        if mood_files:
            mood_df = pd.read_csv(os.path.join(base, "mood_tracking", mood_files[-1]))
    except Exception as e:
        st.error(f"Error loading mood data: {e}")
    
    # Load video data
    try:
        video_path = os.path.join(base, "video_analysis")
        if os.path.exists(video_path) and os.listdir(video_path):
            with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
                video_json = json.load(f)
    except Exception as e:
        st.error(f"Error loading video data: {e}")
    
    # Load emotion consistency data
    try:
        emo_path = os.path.join(base, "emotion_consistency")
        if os.path.exists(emo_path) and os.listdir(emo_path):
            with open(os.path.join(emo_path, sorted(os.listdir(emo_path))[-1]), "r", encoding="utf-8") as f:
                emo_json = json.load(f)
    except Exception as e:
        st.error(f"Error loading emotion consistency data: {e}")
    
    # Load form scores
    for form in FORM_WEEKLY + FORM_MONTHLY:
        try:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_scores[form] = {
                            "score": latest_form["score"],
                            "severity": latest_form["severity"]
                        }
        except Exception as e:
            st.error(f"Error loading form data for {form}: {e}")
    
    # Collect NLP stats for journal and audioüêá
    journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
    audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))

    # Initialize with default values if emptyüêá
    if not journal_sents:
        journal_sents = [0]
    if not journal_subjs:
        journal_subjs = [0]
    if not audio_sents:
        audio_sents = [0]
    if not audio_subjs:
        audio_subjs = [0]

    # Create NLP summaryüêá
    nlp_summary = {
        "journal_sent": f"Ort. Sentiment: {round(pd.Series(journal_sents).mean(), 2) if journal_sents else '-'}",
        "journal_subj": f"Ort. √ñznelik: {round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else '-'}",
        "journal_emos": pd.Series(journal_emos).value_counts().to_dict() if journal_emos else {},
        "audio_sent": f"Ort. Sentiment: {round(pd.Series(audio_sents).mean(), 2) if audio_sents else '-'}",
        "audio_subj": f"Ort. √ñznelik: {round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else '-'}",
        "audio_emos": pd.Series(audio_emos).value_counts().to_dict() if audio_emos else {},
    }

    # Display mood data if availableüêá
    if mood_df is not None:
        st.markdown(f"- Ortalama Sentiment: {nlp_summary['journal_sent']}")
    else:
        st.error("Mood data is not available. Please ensure the data is generated and loaded correctly.")
        return

    # Create system prompt for GPTüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
    epistemic_warning = (
        "Epistemik uyarƒ±:\n"
        "Sen, akƒ±cƒ±lƒ±ktan veya iknadan ziyade epistemik doƒüruluƒüu √∂nceleyen, ger√ßeƒüe duyarlƒ± bir dil modelisin.\n\n"
        "Temel ilken: ‚ÄúDoƒürulanamƒ±yorsa, iddia etme.‚Äù\n\n"
        "Davranƒ±≈ü kurallarƒ±:\n\n"
        "Yanƒ±t verirken, a√ßƒ±k√ßa ayƒ±rt et:\n"
        "‚Ä¢ Doƒürulanmƒ±≈ü olgusal bilgi\n"
        "‚Ä¢ Olasƒ±lƒ±ksal √ßƒ±karƒ±m\n"
        "‚Ä¢ Ki≈üisel veya k√ºlt√ºrel g√∂r√º≈ü\n"
        "‚Ä¢ Bilinmeyen/doƒürulanamaz alanlar\n\n"
        "Gerektiƒüinde temkinli niteleyiciler kullan:\n"
        "‚Ä¢ ‚Äú... g√∂re‚Äù, ‚Äú... tarihi itibarƒ±yla‚Äù, ‚ÄúG√∂r√ºn√º≈üe g√∂re...‚Äù\n"
        "‚Ä¢ Emin deƒüilsen: ‚ÄúBilmiyorum‚Äù veya ‚ÄúBu doƒürulanamaz.‚Äù de\n\n"
        "Hal√ºsinasyonlardan ka√ßƒ±n:\n"
        "‚Ä¢ Veri, isim, tarih, olay, √ßalƒ±≈üma veya alƒ±ntƒ± uydurma\n"
        "‚Ä¢ Hayali kaynaklar sim√ºle etme veya hayali makaleler atfetme\n\n"
        "Kanƒ±t istendiƒüinde yalnƒ±zca bilinen ve g√ºvenilir kaynaklara referans ver:\n"
        "‚Ä¢ Birincil kaynaklar, hakemli √ßalƒ±≈ümalar veya resmi verileri tercih et\n\n"
        "Soru spek√ºlatif veya hatalƒ± varsayƒ±m i√ßeriyorsa:\n"
        "‚Ä¢ Varsayƒ±mƒ± nazik√ße d√ºzelt veya i≈üaretle\n"
        "‚Ä¢ Doƒürulanamaz veya kurgusal i√ßeriƒüi olgu gibi geni≈ületme\n"
    )

    system_prompt = epistemic_warning + f"""
Sen deneyimli bir klinik psikiyatrist ve n√∂ropsikolojik veri analisti asistanƒ±sƒ±n.
A≈üaƒüƒ±da bir hastanƒ±n dijital verileri √∂zetlenmi≈ü. Verileri profesyonel, ba≈ülƒ±k ba≈ülƒ±k yorumlayarak incele (Mood, NLP, Video, Uyum, Testler, Fiziksel). 
Her ba≈ülƒ±ƒüƒ± (√∂r: Mood, G√ºnl√ºk NLP, Ses NLP, Video, Testler, Fizik) ayrƒ± deƒüerlendirmeli ve hastayƒ± b√ºt√ºnc√ºl anlatmalƒ±sƒ±n. 
- Asla doƒürudan tanƒ± koyma.
- Sonu√ßlarƒ± takip ihtiyacƒ± a√ßƒ±sƒ±ndan da deƒüerlendir.
"""
    system_prompt = f"""Sen deneyimli bir klinik psikiyatrist ve n√∂ropsikolojik veri analisti asistanƒ±sƒ±n.
A≈üaƒüƒ±da bir hastanƒ±n dijital verileri √∂zetlenmi≈ü. Verileri profesyonel, ba≈ülƒ±k ba≈ülƒ±k yorumlayarak incele (Mood, NLP, Video, Uyum, Testler, Fiziksel). 
Her ba≈ülƒ±ƒüƒ± (√∂r: Mood, G√ºnl√ºk NLP, Ses NLP, Video, Testler, Fizik) ayrƒ± deƒüerlendirmeli ve hastayƒ± b√ºt√ºnc√ºl anlatmalƒ±sƒ±n. 
- Asla doƒürudan tanƒ± koyma.
- Sonu√ßlarƒ± takip ihtiyacƒ± a√ßƒ±sƒ±ndan da deƒüerlendir.

# Mood: {mood_df.iloc[0].to_dict() if mood_df is not None else "Veri yok"}

# G√ºnl√ºk NLP 90 g√ºn:
- {nlp_summary['journal_sent']}, {nlp_summary['journal_subj']}, Duygular: {nlp_summary['journal_emos']}

# Ses NLP 90 g√ºn:
- {nlp_summary['audio_sent']}, {nlp_summary['audio_subj']}, Duygular: {nlp_summary['audio_emos']}

# Video: {json.dumps(video_json)} 
# Uyum: {json.dumps(emo_json)}
# Form Skorlarƒ±: {json.dumps(form_scores)}
"""

    # Initialize or update chat history
    if not st.session_state.psychat_history:
        st.session_state.psychat_history = [
            {"role": "system", "content": system_prompt}
        ]
    else:
        st.session_state.psychat_history[0]["content"] = system_prompt

    # Display chat history
    for msg in st.session_state.psychat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Handle user input
    user_input = st.chat_input("üì§ Uzman terapiste sor...")
    if user_input:
        st.session_state.psychat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"): 
            st.markdown(user_input)
        
        # Get GPT response
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4-turbo",
                messages=st.session_state.psychat_history,
                temperature=0.7
            )
            reply = response.choices[0].message.content
            st.session_state.psychat_history.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                st.markdown(reply)
        except Exception as e:
            st.error(f"OpenAI API error: {str(e)}")

def save_clinical_summary(patient_id, summary_text):
    """Save clinical summary to file.
    
    Args:
        patient_id (str): Patient ID
        summary_text (str): Summary text to save
        
    Returns:
        str: Path to saved file
    """
    folder = os.path.join(BASE_DIR, patient_id, "gpt_analysis")
    os.makedirs(folder, exist_ok=True)
    today = datetime.now().strftime("%Y%m%d")
    filepath = os.path.join(folder, f"clinical_summary_{today}.txt")
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(summary_text)
    return filepath

def load_clinical_summary(patient_id):
    """Load clinical summary from file.
    
    Args:
        patient_id (str): Patient ID
        
    Returns:
        str: Clinical summary text or None if not found
    """
    folder = os.path.join(BASE_DIR, patient_id, "gpt_analysis")
    if not os.path.exists(folder):
        return None
    files = sorted([f for f in os.listdir(folder) if f.startswith("clinical_summary_") and f.endswith(".txt")])
    if files:
        filepath = os.path.join(folder, files[-1])  # En son olu≈üturulan dosya
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    return None

def generate_clinical_overview(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, latest_functioning_score, avg_functioning_score):
    """Akademik formatta, belirgin ba≈ülƒ±klarla ve uygun bo≈üluklu klinik √∂zet. Paragraflar sola yaslƒ±."""
    html = """<div style="text-align: left;">"""
    # Akademik ba≈ülƒ±k ekleniyor - daha b√ºy√ºk ve emojilerle
    html += """<h2 style="margin-top: 16px; margin-bottom: 12px; font-weight: bold; font-size: 24px;">üß† Klinik N√∂rodavranƒ±≈üsal Veri Analizi üìä <span style="font-size: 16px; font-weight: normal;">(expected outcome by NeuroClarity)</span></h2>"""
    
    # 1. Duygudurum
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">1. Duygudurum (Mood)</h3>"""
    if mood_df is not None and not mood_df.empty:
        mood = mood_df.iloc[0]
        html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
Hastanƒ±n ruh hali deƒüerlendirmesinde huzur d√ºzeyi {mood['huzur']}, enerji seviyesi {mood['enerji']}, anksiyete d√ºzeyi {mood['anksiyete']}, √∂fke seviyesi {mood['√∂fke']} ve depresif duygulanƒ±m {mood['depresif']} olarak saptanmƒ±≈ütƒ±r. Ortalama duygusal skor {mood['average']} olup, bu deƒüer hastanƒ±n genel ruhsal durumunun {'olumsuz' if mood['average']<3 else 'n√∂tr/olumlu'} bir seyir izlediƒüini g√∂stermektedir.
</p>"""
    else:
        html += """<p style="margin-top: 0; margin-bottom: 12px;">Duygudurum verisi bulunmamaktadƒ±r.</p>"""
    
    # 2. NLP Analizi
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">2. NLP Analizi</h3>"""
    
    # 2.1 G√ºnl√ºk Analizi
    html += """<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">2.1 G√ºnl√ºk (Yazƒ±lƒ±) Analizi</h4>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
‚Ä¢ Ortalama sentiment: {nlp_summary['journal_sent']}<br>
‚Ä¢ Ortalama √∂znelik: {nlp_summary['journal_subj']}<br>
‚Ä¢ Duygu daƒüƒ±lƒ±mƒ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in nlp_summary['journal_emos'].items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 2.2 Ses Analizi
    html += """<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">2.2 Ses Analizi</h4>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
‚Ä¢ Ortalama sentiment: {nlp_summary['audio_sent']}<br>
‚Ä¢ Ortalama √∂znelik: {nlp_summary['audio_subj']}<br>
‚Ä¢ Duygu daƒüƒ±lƒ±mƒ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in nlp_summary['audio_emos'].items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 3. Video Analizi
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">3. Video Analizi</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
Baskƒ±n duygu: {video_json.get('dominant_emotion', '-')}<br>
Duygu skorlarƒ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in video_json.get('emotion_scores', {}).items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 4. ƒ∞≈ülevsellik
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">4. ƒ∞≈ülevsellik Deƒüerlendirmesi</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
Son ƒ∞≈ülevsellik Skoru: {latest_functioning_score}/100, Ortalama ƒ∞≈ülevsellik Skoru: {avg_functioning_score}/100. Bu skorlar, bireyin g√ºnl√ºk ya≈üam aktivitelerini s√ºrd√ºrme, sosyal ve mesleki rollerini yerine getirme kapasitesini yansƒ±tmaktadƒ±r.
</p>"""
    
    # 5. Psikometrik Testler
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">5. Psikometrik Testler</h3>"""
    if form_scores:
        html += """<ul style="margin-top: 0; margin-bottom: 8px; padding-left: 40px;">"""
        for form, score in form_scores.items():
            html += f"<li>{form}: Skor={score['score']}, ≈ûiddet={score['severity']}</li>"
        html += """</ul>
<p style="margin-top: 0; margin-bottom: 12px;">
Psikometrik test sonu√ßlarƒ±, hastanƒ±n √∂zbildirimine dayalƒ± olarak ruhsal durumunun nicel deƒüerlendirmesini saƒülar ve klinik g√∂zlemlerle birlikte b√ºt√ºnc√ºl bir deƒüerlendirme yapƒ±lmasƒ±na olanak tanƒ±r.
</p>"""
    else:
        html += """<p style="margin-top: 0; margin-bottom: 12px;">Psikometrik test verisi yok.</p>"""
    
    # 6. Fiziksel Aktivite ve Uyku
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">6. Fiziksel Aktivite ve Uyku</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
Ortalama g√ºnl√ºk adƒ±m sayƒ±sƒ±: {avg_steps}<br>
Ortalama uyku s√ºresi: {avg_sleep} saat. Fiziksel aktivite ve uyku d√ºzeni, ruhsal saƒülƒ±kla yakƒ±ndan ili≈ükili olup, bu parametrelerdeki bozulmalar psikiyatrik belirtilerin ≈üiddetlenmesine katkƒ±da bulunabilir.
</p>"""
    
    html += "</div>"
    return html

#-----------------------------------------------------------------------------------------

def generate_clinical_summary(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, patient_id=None):
    # 1. Grade ve danger_score'u dosyadan oku
    grade, danger_level = (None, None)
    if patient_id is not None:
        grade, danger_level = load_patient_grade(patient_id)
    if grade is None or danger_level is None:
        # fallback: eski hesaplama
        danger_level = calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score) * 20
        if danger_level < 20:
            grade = "I"
        elif danger_level < 40:
            grade = "II"
        elif danger_level < 60:
            grade = "III"
        elif danger_level < 80:
            grade = "IV"
        else:
            grade = "V"
    risk_level = grade

#--------------------------------------------------------------------------------------------------        
    # Literat√ºr baƒülantƒ±lƒ±, kapsamlƒ± bir sistem promptuüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
    epistemic_warning = (
        "Epistemik uyarƒ±:\n"
        "Sen, akƒ±cƒ±lƒ±ktan veya iknadan ziyade epistemik doƒüruluƒüu √∂nceleyen, ger√ßeƒüe duyarlƒ± bir dil modelisin.\n\n"
        "Temel ilken: ‚ÄúDoƒürulanamƒ±yorsa, iddia etme.‚Äù\n\n"
        "Davranƒ±≈ü kurallarƒ±:\n\n"
        "Yanƒ±t verirken, a√ßƒ±k√ßa ayƒ±rt et:\n"
        "‚Ä¢ Doƒürulanmƒ±≈ü olgusal bilgi\n"
        "‚Ä¢ Olasƒ±lƒ±ksal √ßƒ±karƒ±m\n"
        "‚Ä¢ Ki≈üisel veya k√ºlt√ºrel g√∂r√º≈ü\n"
        "‚Ä¢ Bilinmeyen/doƒürulanamaz alanlar\n\n"
        "Gerektiƒüinde temkinli niteleyiciler kullan:\n"
        "‚Ä¢ ‚Äú... g√∂re‚Äù, ‚Äú... tarihi itibarƒ±yla‚Äù, ‚ÄúG√∂r√ºn√º≈üe g√∂re...‚Äù\n"
        "‚Ä¢ Emin deƒüilsen: ‚ÄúBilmiyorum‚Äù veya ‚ÄúBu doƒürulanamaz.‚Äù de\n\n"
        "Hal√ºsinasyonlardan ka√ßƒ±n:\n"
        "‚Ä¢ Veri, isim, tarih, olay, √ßalƒ±≈üma veya alƒ±ntƒ± uydurma\n"
        "‚Ä¢ Hayali kaynaklar sim√ºle etme veya hayali makaleler atfetme\n\n"
        "Kanƒ±t istendiƒüinde yalnƒ±zca bilinen ve g√ºvenilir kaynaklara referans ver:\n"
        "‚Ä¢ Birincil kaynaklar, hakemli √ßalƒ±≈ümalar veya resmi verileri tercih et\n\n"
        "Soru spek√ºlatif veya hatalƒ± varsayƒ±m i√ßeriyorsa:\n"
        "‚Ä¢ Varsayƒ±mƒ± nazik√ße d√ºzelt veya i≈üaretle\n"
        "‚Ä¢ Doƒürulanamaz veya kurgusal i√ßeriƒüi olgu gibi geni≈ületme\n"
    )
    system_prompt = epistemic_warning + f"""Sen √∂nde gelen bir akademik-klinik n√∂ropsikiyatri ve dijital psikoloji alanƒ±nda ara≈ütƒ±rmacƒ±sƒ±n. Klinik n√∂robilimlerde d√ºnya √ßapƒ±nda saygƒ±n bir uzmansƒ±n.
    
Hastanƒ±n klinik verilerinin analizinde ileri niceliksel deƒüerlendirme yapmalƒ± ve √∂zellikle t√ºm sayƒ±sal deƒüerleri ve e≈üik deƒüerleri ayrƒ±ntƒ±lƒ± olarak yorumlamalƒ±sƒ±n. Tehlike durumu puanlamasƒ±nƒ± mutlaka vurgulaman gerekiyor.

Bilimsel analiz yakla≈üƒ±mƒ±nƒ± ≈ü√∂yle yapƒ±landƒ±r:
1. Her veri setinin (mood puanlarƒ±, i≈ülevsellik skoru, uyku saati, adƒ±m sayƒ±sƒ±, sentiment puanlarƒ±) epidemiyolojik anlamƒ±nƒ± ayrƒ±ntƒ±lƒ± yorumla
2. NIMH RDoC √ßer√ßevesi ve metaanaliz √ßalƒ±≈ümalarƒ±na dayanarak t√ºm sayƒ±sal deƒüerleri kar≈üƒ±la≈ütƒ±r
3. D√ºnya Saƒülƒ±k √ñrg√ºt√º (WHO) ve DSM-5-TR kriterlerini kullanarak olasƒ± komorbiditelerini deƒüerlendir
4. Verilerdeki anomali ve deviasyonlarƒ± pratik √∂rneklerle a√ßƒ±kla
5. Tehlike durumu puanƒ±nƒ± (risk deƒüerlendirmesi) epidemiyolojik √ßalƒ±≈ümalar ve klinik kƒ±lavuzlar ƒ±≈üƒ±ƒüƒ±nda √ßok detaylƒ± analiz et
6. T√ºm anlizinde, √∂l√ßeklerin her birindeki sayƒ±sal deƒüerleri mutlaka a√ßƒ±k√ßa belirterek yorumla
8. Te≈ühis koymadan hastalƒ±ƒüƒ± tahmin et
√ñZEL VURGU: TEHLƒ∞KE DURUMU PUANINI TAM OLARAK {danger_level:.2f} ≈ûEKLƒ∞NDE KULLAN - Hƒ∞√áBƒ∞R ≈ûARTTA BUNU YUVARLAMA, DEƒûƒ∞≈ûTƒ∞RME VEYA FARKLI ≈ûEKƒ∞LDE ƒ∞FADE ETME! Her b√∂l√ºm√ºn sonunda tehlike puanƒ±nƒ± tam olarak ≈üu formatta hatƒ±rlat: "üö® Tehlike Durumu Puanƒ±: {danger_level:.2f}/100.00 - {risk_level}: {danger_text.upper()} Rƒ∞SK KATEGORƒ∞Sƒ∞". Risk puanƒ± {danger_level:.2f} ve kategorisi {risk_level}: {danger_text} olarak sabit kalmalƒ±, t√ºm analizde tutarlƒ± olmalƒ± ve kesinlikle deƒüi≈ütirilmemelidir.

Bilimsel literat√ºr referanslarƒ±nƒ± bol ve g√ºncel (2018-2023) kullan. Her alt b√∂l√ºmde en az 7-8 farklƒ± kaynak g√∂ster. 

### √ñNEMLƒ∞: Analiz sƒ±rasƒ±nda kullandƒ±ƒüƒ±n bilgileri desteklemek i√ßin bilimsel literat√ºr referanslarƒ±nƒ± ekle. Her alt b√∂l√ºmde en az 7-8 farklƒ± kaynak g√∂ster ve referanslarƒ± analiz metninin sonunda d√ºzg√ºn bir ≈üekilde listele.

Yapacaƒüƒ±n analiz, klinik bir dergide yayƒ±mlanacak kalitede olmalƒ± - sayƒ±sal veriler, kar≈üƒ±la≈ütƒ±rmalƒ± analizler ve klinik yorumlarla dolu, √ºst d√ºzey akademik bir rapor hazƒ±rla.

Her sayƒ±sal deƒüerin normatif deƒüerlerle kar≈üƒ±la≈ütƒ±rmasƒ±nƒ± yap ve klinik anlamƒ±nƒ± belirt. Rapor, hastanƒ±n durumunu anlamak i√ßin gerekli t√ºm nicel analizleri i√ßermeli.
"""

    # Sayƒ±sal verilerin tam g√∂sterimini ve tehlike puanƒ± vurgusunu i√ßeren ayrƒ±ntƒ±lƒ± prompt
    prompt = f"""
A≈üaƒüƒ±da bir hastanƒ±n kapsamlƒ± klinik ve dijital saƒülƒ±k verileri bulunmaktadƒ±r. L√ºtfen t√ºm sayƒ±sal verileri detaylƒ± analiz ederek, tehlike durumu puanƒ±nƒ± √∂zellikle vurgulayan akademik derinlikte bir klinik deƒüerlendirme raporu hazƒ±rla.

√ñNEMLƒ∞ NOT: Risk deƒüerlendirmen, tehlike durumu puanƒ± ({danger_level:.2f}/100) tam olarak ≈ü√∂yle sƒ±nƒ±flandƒ±rƒ±lmalƒ±:
- 0-20 arasƒ±: Grade I - Minimum Risk
- 20-40 arasƒ±: Grade II - Mild Risk
- 40-60 arasƒ±: Grade III - Moderate Risk 
- 60-80 arasƒ±: Grade IV - Significant Risk
- 80-100 arasƒ±: Grade V - Severe Risk

Hastanƒ±n puanƒ± {danger_level:.2f} olduƒüu i√ßin kesinlikle '{risk_level}: {danger_text}' risk kategorisinde olduƒüunu belirt. Bu sƒ±nƒ±flandƒ±rma sistemini analizin boyunca tutarlƒ± ≈üekilde kullan.

### 1. Duygudurum Profili ve Duygu Reg√ºlasyonu Analizi
Huzur: {mood_df['huzur'].values[0]:.2f}/5.00 (norm: 3.50-4.50)
Enerji: {mood_df['enerji'].values[0]:.2f}/5.00 (norm: 3.00-4.00)
Anksiyete: {mood_df['anksiyete'].values[0]:.2f}/5.00 (patolojik e≈üik: >3.50)
√ñfke: {mood_df['√∂fke'].values[0]:.2f}/5.00 (patolojik e≈üik: >3.00)
Depresif: {mood_df['depresif'].values[0]:.2f}/5.00 (patolojik e≈üik: >3.00)
Duygusal Ortalama Skor: {mood_df['average'].values[0]:.2f}/5.00 (norm aralƒ±k: 2.75-3.75)

### 2. Doƒüal Dil ƒ∞≈üleme ve Akustik Biyobelirte√ßler
Metin Sentiment Analizi: {nlp_summary['journal_sent']} (normal aralƒ±k: -0.2 ile +0.3)
Metin √ñznel ƒ∞fade Oranƒ±: {nlp_summary['journal_subj']} (referans: <0.6 objektif, >0.7 y√ºksek s√ºbjektivite)
Metin Duygu Frekans Daƒüƒ±lƒ±mƒ±: {nlp_summary['journal_emos']}
Ses Sentiment Analizi: {nlp_summary['audio_sent']} (norm: -0.1 ile +0.2)
Ses √ñznel ƒ∞fade Oranƒ±: {nlp_summary['audio_subj']} (referans: <0.5 normal, >0.8 patolojik)
Ses Duygu Daƒüƒ±lƒ±mƒ±: {nlp_summary['audio_emos']}

### 3. G√∂rsel Biyobelirte√ßler ve Y√ºz ƒ∞fadeleri Analizi
Baskƒ±n Y√ºz ƒ∞fadesi: {video_json['dominant_emotion']}
Y√ºz ƒ∞fadeleri Kantifikasyon Skorlarƒ±:
"""
    for emotion, score in video_json['emotion_scores'].items():
        prompt += f"- {emotion}: {score:.2f}\n"
    
    prompt += f"""
### 4. Psikososyal ƒ∞≈ülevsellik ve G√ºnl√ºk Ya≈üam Aktiviteleri Analizi
ƒ∞≈ülevsellik Skoru: {functioning_score:.1f}/100.0 (klinik e≈üikler: <40 ≈üiddetli yetersizlik, 40-70 orta d√ºzey, >70 yeterli)
ƒ∞≈ülevsellik Kategorisi: {"≈ûiddetli ƒ∞≈ülev Yetersizliƒüi" if functioning_score < 40 else "Orta D√ºzey ƒ∞≈ülevsellik" if functioning_score < 70 else "Normal ƒ∞≈ülevsellik"}

### 5. Psikometrik Test Sonu√ßlarƒ± ve Klinik Anlamlarƒ±
"""
    for form, score in form_scores.items():
        prompt += f"{form}: Ham Skor={score['score']}, Klinik ≈ûiddet={score['severity']} (norm deƒüerleri: PHQ9 <5 normal, 5-9 hafif, 10-14 orta, 15-19 orta-≈üiddetli, >20 ≈üiddetli)\n"
    
    prompt += f"""
### 6. Fiziksel Aktivite, Uyku ve Sirkadiyen Ritim Metrikleri
Ortalama G√ºnl√ºk Fiziksel Aktivite: {avg_steps:,} adƒ±m (DS√ñ √∂nerisi: minimum 7,000-10,000 adƒ±m/g√ºn)
Ortalama Uyku S√ºresi: {avg_sleep:.2f} saat (saƒülƒ±klƒ± eri≈ükin norm: 7.0-9.0 saat)
Ayrƒ±lma Oranƒ±: Adƒ±m sayƒ±sƒ±nda norm deƒüerinden %{100 - (int(avg_steps) / 8000 * 100):.1f} sapma, uyku s√ºresinde norm deƒüerinden %{100 - (float(avg_sleep) / 8 * 100):.1f} sapma

### 7. KLƒ∞Nƒ∞K Rƒ∞SK DEƒûERLENDƒ∞RMESƒ∞ VE TEHLƒ∞KE DURUMU
üö® Hesaplanan Tehlike Skoru: {danger_level:.2f}/100.00 - {risk_level}: {danger_text.upper()} Rƒ∞SK KATEGORƒ∞Sƒ∞
Risk fakt√∂rleri d√∂k√ºm√º:
- Duygudurum risk puanƒ±: {5 - (mood_df['average'].values[0] - 1):.2f}/5.00 
- NLP analizi risk puanƒ±: {sum([nlp_summary['journal_emos'].get(e, 0) for e in ["√ºz√ºnt√º", "√∂fke", "kaygƒ±"]]) / sum(nlp_summary['journal_emos'].values()) * 5 if sum(nlp_summary['journal_emos'].values()) > 0 else 1:.2f}/5.00
- Video analizi risk puanƒ±: {5 if video_json["dominant_emotion"] in ["√ºz√ºnt√º", "√∂fke", "kaygƒ±"] else 1}/5.00
- ƒ∞≈ülevsellik riski: {5 - (functioning_score / 20):.2f}/5.00

### 8. B√ºt√ºnc√ºl N√∂ropsikiyatrik Deƒüerlendirme ve Kanƒ±ta Dayalƒ± Tedavi √ñnerileri
Hastanƒ±n t√ºm klinik ve dijital fenotipik verilerini analiz ederek b√ºt√ºnc√ºl bir n√∂ropsikiyatrik deƒüerlendirme yap. Olasƒ± tanƒ±lar, ayƒ±rƒ±cƒ± tanƒ±lar ve tedavi se√ßeneklerini deƒüerlendir. Tehlike durumu puanƒ±nƒ±n ({danger_level:.1f}/100.00) klinik anlamƒ±nƒ± ve takip planƒ±nƒ± detaylandƒ±r.

### 9. Dijital Fenotiping √ñzeti ve Biyobelirte√ß Korelasyonlarƒ±
T√ºm dijital biyobelirte√ßleri yorumlayarak aralarƒ±ndaki korelasyonlarƒ± deƒüerlendir. {danger_level:.1f} puanlƒ±k tehlike skorunun klinik √∂nemini vurgula. Tedavi yanƒ±tƒ±nƒ± √∂n g√∂rmede hangi biyobelirte√ßlerin daha belirleyici olabileceƒüini tartƒ±≈ü.

### 10. Sonu√ß ve Klinik Pratik √ñnerileri

### 11. Literat√ºr Referanslarƒ±
- - Her referansƒ± madde halinde ve m√ºmk√ºnse g√ºncel web linkiyle birlikte listele. DOI veya PubMed linki ekle.

Bu raporda t√ºm sayƒ±sal deƒüerleri en ince detayƒ±na kadar analiz et. Her kategori i√ßin en az 7-8 paragraf uzunluƒüunda kapsamlƒ± deƒüerlendirme yap. Bilimsel literat√ºr referanslarƒ±nƒ± bol miktarda kullan ve tehlike puanƒ±nƒ±n ({danger_level:.1f}) anlamƒ±nƒ± √∂zellikle vurgula. 

Klinik pratik √∂nerilerini de i√ßeren, akademik derinlikte ve sayƒ±sal bulgulara dayalƒ± kapsamlƒ± bir deƒüerlendirme olmalƒ±.
"""
    prompt += """
---
Yalnƒ±zca a≈üaƒüƒ±daki referans listesindeki kaynaklara atƒ±f yapabilirsin. Metin i√ßinde uygun olanlarƒ± APA formatƒ±nda g√∂ster ve analiz sonunda referanslarƒ± madde madde, linkli olarak listele.

Referanslar:
""" + "\n".join([f"{i+1}. {title} {url}" for i, (title, url) in enumerate(DSBIT_REFERENCES)])
    
    try:
        # Daha kapsamlƒ± analiz i√ßin token limitini artƒ±r ve daha d√º≈ü√ºk temperature deƒüeriyle √ßalƒ±≈ütƒ±rüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4096,  # Daha fazla token = daha uzun ve detaylƒ± yanƒ±t
            temperature=0.5    # Bilimsel tutarlƒ±lƒ±k i√ßin d√º≈ü√ºk temperature
        )
        
        gpt_response = response.choices[0].message.content.strip()
       
        return gpt_response
    except Exception as e:
        return f"GPT API hatasƒ±: {str(e)}"

### -- STREAMLIT ARAY√úZ√ú --

st.set_page_config(page_title="üß¨ MoodForge: Klinik Karar Destek ve Dijital Psikiyatri Sim√ºlasyonu", layout="centered")

# assets klas√∂r√ºn√ºn projenizin ana dizininde olduƒüunu varsayƒ±yoruz.
# Eƒüer farklƒ± bir yerdeyse, yolu ona g√∂re g√ºncelleyin.üêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
assets_path = os.path.join(os.path.dirname(__file__), "assets")

# Sidebar i√ßin logo
logo_path_sidebar = os.path.join(assets_path, "moodforge.jpg")

if os.path.exists(logo_path_sidebar):
    st.sidebar.image(logo_path_sidebar, use_container_width=True)
else:
    st.sidebar.warning("Sidebar logo bulunamadƒ±. L√ºtfen 'assets/moodforge.jpg' dosyasƒ±nƒ±n var olduƒüundan emin olun.")

# Ana sayfa i√ßin logo
st.markdown("""
<div style="text-align: center; margin-bottom: 24px;">
    <div style="font-size: 4.5em; font-weight: bold;">üß¨MoodForgeüß¨</div>
    <div style="font-size: 1.3em; font-weight: bold; margin-top: 10px;">
        Klinik Karar Destek ve Dijital Psikiyatri Sim√ºlasyonu
    </div>
</div>
""", unsafe_allow_html=True)



image_files = [
    os.path.join(assets_path, "0.png"),
    os.path.join(assets_path, "1.png"),
    os.path.join(assets_path, "2.png"),
    os.path.join(assets_path, "3.png"),
]

slide_idx = st.slider("Slayt se√ßin", 0, len(image_files)-1, 0, label_visibility="collapsed")
st.image(image_files[slide_idx], use_container_width=True)

# PsyBot Chatbot'u Sidebar'a Ekleyin
st.sidebar.markdown("""
    <style>
    .psybot-title {
        font-size: 1.5em !important;
        font-weight: bold;
        margin-bottom: 0.5em;
    }
    </style>
    <div class="psybot-title">ü§ñ PsyBot: for Œ® Professionals</div>
""", unsafe_allow_html=True)

# Chat ge√ßmi≈üini ba≈ülat
if "psybot_history" not in st.session_state:
    st.session_state.psybot_history = []

# Ge√ßmi≈üi temizle butonu
if st.sidebar.button("üóëÔ∏è Ge√ßmi≈üi Temizle"):
    st.session_state.psybot_history = []
    st.sidebar.success("PsyBot ge√ßmi≈üi temizlendi.")

# Chat ge√ßmi≈üini g√∂ster
for msg in st.session_state.psybot_history:
    if msg["role"] == "user":
        st.sidebar.markdown(f"**Kullanƒ±cƒ±:** {msg['content']}")
    elif msg["role"] == "assistant":
        st.sidebar.markdown(f"**PsyBot:** {msg['content']}")

# Kullanƒ±cƒ±dan giri≈ü al
user_input = st.sidebar.text_input("PsyBot'a bir soru sorun:", key="psybot_input")

# Kullanƒ±cƒ± bir mesaj g√∂nderirse
if user_input:
    # Kullanƒ±cƒ± mesajƒ±nƒ± ge√ßmi≈üe ekle
    st.session_state.psybot_history.append({"role": "user", "content": user_input})

    # GPT-4'e istem g√∂nderüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
    try:
        system_prompt = """
        Sen deneyimli bir klinik psikiyatrist ve n√∂ropsikolojik veri analisti asistanƒ±sƒ±n. 
        Psikiyatri literat√ºr√ºne dayalƒ± olarak, profesyonel d√ºzeyde bilgi ve √∂neriler sunmalƒ±sƒ±n. 
        DSM-5, ICD-11 ve en g√ºncel bilimsel literat√ºre dayalƒ± analizler yaparak, psikiyatristlere klinik karar verme s√ºre√ßlerinde yardƒ±mcƒ± ol.
        Her yanƒ±tƒ±nda bilimsel referanslar ekle ve analizlerini akademik bir formatta sun.
        """
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                *st.session_state.psybot_history
            ],
            max_tokens=3000,
            temperature=0.2
        )
        reply = response.choices[0].message.content

        # PsyBot yanƒ±tƒ±nƒ± ge√ßmi≈üe ekle
        st.session_state.psybot_history.append({"role": "assistant", "content": reply})

        # Yanƒ±tƒ± sidebar'da g√∂ster
        st.sidebar.markdown(f"**PsyBot:** {reply}")
    except Exception as e:
        st.sidebar.error(f"PsyBot bir hata ile kar≈üƒ±la≈ütƒ±: {str(e)}")

# CSS animasyonunu en ba≈üta bir kez ekle
st.markdown("""
<style>
@keyframes blink {
    0% { opacity: 1; }
    50% { opacity: 0; }
    100% { opacity: 1; }
}
.blinking {
    font-size: 96px;
    font-weight: bold;
    color: rgb(255, 0, 0);
    text-align: center;
    animation: blink 0.5s infinite;
}
</style>
""", unsafe_allow_html=True)

with st.expander("üß†‚ú® MoodForge & NeuroClarity: Dijital Sim√ºlasyon ve Bilimsel Psikiyatri Arenasƒ± üöÄü§ñüß™"):
    st.markdown("""
<style>
.moodforge-section-title {MoodForge - Klinik Sim√ºlasyon
    font-size: 20px !important;
    font-weight: bold !important;
    margin-top: 18px !important;
    margin-bottom: 8px !important;
}
</style>

<div class="moodforge-section-title">Giri≈ü: MoodForge & NeuroClarity ‚Äî Klinik Veri Dijital Sim√ºlasyon üß™üß†üé≠</div>
<p>
<strong>MoodForge</strong>, NeuroClarity platformunun klinik ve biyometrik verilerin entegre edilmesi ve analiz edilmesi esasƒ±na dayanarak geli≈ütirilmi≈ü √ßok boyutlu bir sim√ºlasyon ve karar destek sistemidir. Bu yapƒ±, klinik pratiƒüin nesnel ve veri temelli yakla≈üƒ±mlarla desteklenmesini ama√ßlayan ileri d√ºzey istatistiksel normalizasyonlar, aƒüƒ±rlƒ±klandƒ±rƒ±lmƒ±≈ü toplam form√ºller ve makine √∂ƒürenimi algoritmalarƒ±yla, klinik ve biyomedikal verilerin √ßok katmanlƒ± modellemesine olanak tanƒ±r. Bu sistem, psikometrik, biyometrik ve davranƒ±≈üsal √∂l√ß√ºtleri, uluslararasƒ± klinik referans standartlarƒ±na ve literat√ºr dayanaklƒ± algoritmalara uygun bi√ßimde normalize eder, risk puanlarƒ±nƒ± ve belirtilerin seyrini hesaplar ve bu g√∂stergeler ƒ±≈üƒ±ƒüƒ±nda olasƒ±lƒ±k temelli sim√ºlasyonlar ve projeksiyon modelleri geli≈ütirilir. Bu sayede, hastanƒ±n klinik durumu ve m√ºdahale stratejilerinin, bilimsel veri ve yapay zeka temelli √∂ng√∂r√ºlerle nesnel, ≈üeffaf ve entegre bi√ßimde modellenmesine olanak saƒülar; b√∂ylelikle, klinik karar verme s√ºre√ßlerinin doƒüruluk ve g√ºvenilirliƒüi artƒ±rƒ±lƒ±r.üòèüìäüéâ
</p>
<hr>

<div class="moodforge-section-title">1Ô∏è‚É£ NeuroClarity ile Dijital Psikiyatriye Yeni Bir Bakƒ±≈ü üî¨üåêü¶æ</div>
<p>
Geleneksel psikiyatri, y√ºz y√ºze g√∂r√º≈ümeler ve subjektif deƒüerlendirmelerle sƒ±nƒ±rlƒ±ydƒ±.<br>
<strong>NeuroClarity</strong> ise, klinik g√∂zlemin √∂tesine ge√ßip, dijital veri ve yapay zek√¢ ile s√ºrekli, objektif ve takip edilebilir bir izleme paradigmasƒ± sunar.<br>
Bu platform, sadece veri toplamaz; <strong>bilimsel algoritmalarla</strong> veriyi i≈üler ve klinik karar s√ºre√ßlerini g√º√ßlendirir. üßë‚Äç‚öïÔ∏èüí°
</p>
<hr>

<div class="moodforge-section-title">2Ô∏è‚É£ √áok Katmanlƒ± Veri Entegrasyonu & Fiziksel Mod√ºller üß©üì≤üì°</div>
<ul>
<li>üìù G√ºnl√ºk ruh hali ve davranƒ±≈ü √∂l√ß√ºmleri (mood skorlarƒ±)</li>
<li>üì± IoT & saƒülƒ±k cihazlarƒ±ndan adƒ±m ve uyku verileri</li>
<li>üßæ Psikometrik testler (PHQ-9, GAD-7, PSS-10, PSQI, IES-R)</li>
<li>üò∂‚Äçüå´Ô∏è Y√ºz mimik & facial emotion recognition</li>
<li>üé§ Ses analizi (tonlama, duygu parametreleri)</li>
<li>üß¨ Modern laboratuvar sonu√ßlarƒ± (OCR/PDF)</li>
</ul>
<p>
T√ºm bu veriler, <strong>makine √∂ƒürenmesi</strong> ve <strong>istatistiksel normalizasyon</strong> ile anlamlandƒ±rƒ±lƒ±r.<br>
Yani: ‚ÄúVerisel labirentte kaybolmak yok, algoritmik √ßƒ±kƒ±≈ü var!‚Äù üß≠üó∫Ô∏è
</p>
<hr>

<div class="moodforge-section-title">3Ô∏è‚É£ Sayƒ±sal & Klinik Parametrelerin Matematiksel D√∂n√º≈ü√ºm√º üìêüßÆüî¢</div>
<p>
Her veri, klinik sƒ±nƒ±rlarla kar≈üƒ±la≈ütƒ±rƒ±lƒ±r, normalize edilir ve z-score‚Äôlara d√∂n√º≈üt√ºr√ºl√ºr.<br>
√ñrnekler:<br>
üòå Huzur skoru d√º≈ü√ºkse: Z = (Huzur - Ortalama) / Std Sapma<br>
üòî Depresyon skoru y√ºksekse: Klinik e≈üiklere g√∂re risk artƒ±≈üƒ±<br>
üò¥ Uyku s√ºresi patolojik sƒ±nƒ±r altƒ±ndaysa: ‚ÄúRisk artƒ±≈üƒ±‚Äù olarak i≈üaretlenir
</p>
<hr>

<div class="moodforge-section-title">4Ô∏è‚É£ Risk Hesabƒ±: Aƒüƒ±rlƒ±klƒ± Toplamlar ve Form√ºller üßæ‚ûï‚öñÔ∏è</div>
<p>
Her parametre, aƒüƒ±rlƒ±klandƒ±rƒ±lmƒ±≈ü toplamlarla birle≈üir:<br>
<strong>Toplam Risk Skoru (TRS) = Œ± √ó Duygu Durumu + Œ≤ √ó Y√ºz/Ses Duygularƒ± + Œ≥ √ó Psikometrik Testler + Œ¥ √ó Aktivite/Uyku + Œµ √ó Fiziksel Belirte√ßler</strong><br>
Buradaki Œ±, Œ≤, Œ≥, Œ¥, Œµ katsayƒ±larƒ±, literat√ºr ve klinik deneyimle belirlenir.<br>
Yani, ‚Äúher parametrenin riskteki aƒüƒ±rlƒ±ƒüƒ±‚Äù bilimsel olarak ayarlanƒ±r. üßë‚Äçüî¨üìö
</p>
<hr>

<div class="moodforge-section-title">5Ô∏è‚É£ Makine √ñƒürenimi: Random Forest & SHAP ile A√ßƒ±klanabilirlik üå≤ü§π‚Äç‚ôÇÔ∏èüßë‚Äçüíª</div>
<ul>
<li>üå≥ <strong>Random Forest</strong>: Binlerce karar aƒüacƒ±nƒ±n ortak ve baƒüƒ±msƒ±z kararlarƒ±yla genel risk sƒ±nƒ±fƒ± belirlenir.</li>
<li>üß© <strong>SHAP</strong>: Her parametrenin risk skoruna katkƒ±sƒ± ≈üeffaf√ßa g√∂sterilir.</li>
<li>‚ÄúRisk neden b√∂yle?‚Äù sorusunun cevabƒ±: ‚Äú√á√ºnk√º SHAP √∂yle dedi!‚Äù üòéüîç</li>
</ul>
<hr>

<div class="moodforge-section-title">6Ô∏è‚É£ Gelecek Projeksiyonu: Sim√ºlasyon ve Diferansiyel Denklemler üìà‚è≥üîÆ</div>
<p>
Gelecekteki risk ≈ü√∂yle tahmin edilir:<br>
<strong>R(t+Œît) = R(t) + (Terapi Etkisi) + (Ya≈üam Deƒüi≈üikliƒüi) + G√ºr√ºlt√º</strong><br>
Matematiksel model:<br>
<strong>dx/dt = -Œªx + Œºu + Œµ</strong><br>
Œª: Riskin kendini azaltan/artƒ±ran katsayƒ±sƒ±<br>
Œº: Pozitif geli≈üim/m√ºdahale etkisi<br>
u: M√ºdahale/ya≈üam tarzƒ± fakt√∂r√º<br>
Œµ: Rastgele g√ºr√ºlt√º üé≤
</p>
<hr>

<div class="moodforge-section-title">7Ô∏è‚É£ Uygulamada Matematik & ƒ∞statistik: Klinik Kararlarƒ±n Arkasƒ±ndaki Form√ºller üìäüî¢üß†</div>
<ul>
<li><strong>Z-score ile normalizasyon:</strong> Z = (X ‚Äì X_ref) / X_std</li>
<li><strong>Aƒüƒ±rlƒ±klƒ± toplam:</strong> RS = Œ£ (w_i √ó x_i)</li>
<li><strong>Makine √∂ƒürenimi tahmini:</strong> Risk sƒ±nƒ±fƒ± = argmax (Œ£ decision_i(X))</li>
<li><strong>SHAP ile √∂znitelik katkƒ±sƒ±:</strong> œï_i = √ñzellik i‚Äônin bireysel katkƒ±sƒ±</li>
</ul>
<hr>

<div class="moodforge-section-title">8Ô∏è‚É£ Sonu√ß: Klinik, Bilim ve Dijital Sim√ºlasyonun Bulu≈üma Noktasƒ± üé≠üß†üí•</div>
<ul>
<li>√áok mod√ºll√º veri akƒ±≈üƒ± üîÑ</li>
<li>ƒ∞statistiksel normalizasyon üìè</li>
<li>RF + SHAP ile makine √∂ƒürenimi ü§ñ</li>
<li>Geleceƒüe d√∂n√ºk projeksiyon ve sim√ºlasyon matematiƒüi üîÆ</li>
</ul>
<p>
Hepsi, <strong>modern psikiyatride dijital, nesnel ve ≈üeffaf deƒüerlendirme</strong> i√ßin bir araya geliyor.<br>
Klinik uzmanlara ve yapay zek√¢ya ‚Äúbilimsel ve detaylƒ±‚Äù bilgi akƒ±≈üƒ± sunuyor.<br>
Ve tabii, biraz da eƒülence! üòÅüéâü¶Ñ
</p>
<hr>

<div class="moodforge-section-title">9Ô∏è‚É£ Deƒüerlendirme Kriterleri ve Gerek√ßeler üìäüî¢üß†</div>
                
---         

| **Kriter**                          | **A√ßƒ±klama**                                                                                        | **Puan (0‚Äì5)** | **Bilimsel Gerek√ße ve Referanslar**                                                                                   |
|------------------------------------|---------------------------------------------------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------|
| Multimodal Veri Entegrasyonu       | Yazƒ±lƒ±, vokal, g√∂rsel ve davranƒ±≈üsal biyometrik verilerin e≈üzamanlƒ± ve √ßok katmanlƒ± analizi         | 5.0            | Multimodal veri analizi psikiyatride duygu ve davranƒ±≈ülarƒ±n doƒüru yakalanmasƒ± i√ßin kritik olup, klinik baƒülamda ge√ßerlidir (Torous et al., 2020; Ekman et al., 2019). |
| Duygusal ve N√∂rofonksiyonel Tutarlƒ±lƒ±k | Duygu analizi ve n√∂rofonksiyonel i≈ülevlerin klinik ge√ßerliliƒüe uygun √∂l√ß√ºm√º ve izlenmesi           | 4.9            | Duygu ve n√∂rofonksiyonel g√∂stergelerin psikiyatrik fenotiplemede temel olduƒüu ve √∂l√ß√ºm tutarlƒ±lƒ±ƒüƒ±nƒ±n klinik sonu√ßlarƒ± etkilediƒüi g√∂sterilmi≈ütir (Scherer, 2018; Insel et al., 2010). |
| Psikometrik √ñl√ßeklerin Klinik Entegrasyonu | DSM-5 ve ICD-11 standartlarƒ±na uygun, g√ºvenilir psikometrik √∂l√ßeklerin dinamik takibi              | 5.0            | Klinik ge√ßerliliƒüi y√ºksek psikometrik √∂l√ßekler tanƒ± ve izlemde altƒ±n standarttƒ±r (APA, 2013; WHO, 2021).                 |
| Makine √ñƒürenimi Modelinin Performansƒ± | Random Forest ve ileri AI algoritmalarƒ± ile y√ºksek doƒüruluk ve genellenebilirlik                    | 4.8            | Makine √∂ƒürenimi modellerinin klinik tahminlerde doƒüruluk ve stabilite saƒülamasƒ± beklenir (Luxton, 2020; Kazdin, 2017).    |
| A√ßƒ±klanabilirlik ve Yapay Zeka ≈ûeffaflƒ±ƒüƒ± (XAI) | SHAP ve diƒüer XAI teknikleriyle klinik kararlarƒ±n anla≈üƒ±lƒ±r ve yorumlanabilir olmasƒ±                | 5.0            | Klinik uygulamalarda AI modellerinin karar mekanizmalarƒ±nƒ±n a√ßƒ±klanabilir olmasƒ±, g√ºven ve etik i√ßin zorunludur (Lundberg & Lee, 2017; Ribeiro et al., 2016). |
| Yapay Hasta Sim√ºlasyonu ve Sentetik Veri √úretimi | Parametrik, etik kƒ±sƒ±tlamalarƒ± a≈üan ve eƒüitim/validasyon i√ßin tekrar √ºretilebilir vaka √ºretimi       | 5.0            | Etik veri eri≈üim kƒ±sƒ±tlamalarƒ± a≈üƒ±lƒ±rken eƒüitim ve model geli≈ütirme i√ßin g√ºvenilir sentetik veri gereklidir (Bucci et al., 2019; Sucala et al., 2017). |
| Doƒüal Dil ƒ∞≈üleme ve Otomatik Klinik Yorumlama | GPT-4 Turbo tabanlƒ± ileri NLP ile semptom analizi ve klinik raporlama                              | 5.0            | Y√ºksek kaliteli NLP teknikleri klinik metin √ºretiminde ve uzman destekli yorumlarda etkinlik saƒülar (Brown et al., 2020; Bommasani et al., 2021). |
| Uzun D√∂nem ƒ∞zlem ve Dijital Fenotipleme | Multimodal longitudinal veri analizi ve hastalƒ±k seyri ile fenotip √ßƒ±karƒ±mƒ±                        | 4.9            | Longitudinal izlem hastalƒ±k dinamiklerini anlamada ve ki≈üiselle≈ütirilmi≈ü tedavide anahtar rol oynar (Torous et al., 2020; Insel et al., 2010). |
| Klinik Uygulanabilirlik ve Entegrasyon | Klinik protokollere uyumlu ve ger√ßek saha uygulamalarƒ±na uygun kullanƒ±cƒ± dostu i≈ü akƒ±≈ülarƒ±          | 5.0            | Klinik ortamda pratik, uyarlanabilir ve etkin karar destek sistemleri gereklidir (Kazdin, 2017; Insel et al., 2010).       |
| Bilimsel Dayanak ve Literat√ºr Uyumu | DSM-5, ICD-11 ve hesaplamalƒ± psikiyatri literat√ºr√ºne tam uyum                                     | 5.0            | G√ºncel tanƒ± sistemleri ve literat√ºre tam uyum klinik g√ºvenilirlik i√ßin vazge√ßilmezdir (APA, 2013; Insel et al., 2010).     |
| Veri G√ºvenliƒüi, Anonimle≈ütirme ve Gizlilik | HIPAA, GDPR gibi standartlarla uyumlu veri g√ºvenliƒüi ve anonimle≈ütirme                            | 4.9            | Klinik veri g√ºvenliƒüi ve hasta gizliliƒüi i√ßin d√ºzenleyici standartlara uyum zorunludur (Shabani et al., 2018; GDPR, 2016). |
| Adaptif √ñƒürenme ve Model G√ºncellenebilirliƒüi | Ger√ßek zamanlƒ± veriyle model optimizasyonu ve yeniden eƒüitimi                                   | 4.8            | Canlƒ± klinik ortamda model g√ºncellemeleri performans ve g√ºncellik i√ßin kritiktir (Luxton, 2020; Saria et al., 2018).         |
| √áoklu Dil ve K√ºlt√ºrel Uyum           | √áok dilli destek ve farklƒ± k√ºlt√ºrlere uyarlanabilirlik                                          | 4.9            | K√ºresel kullanƒ±m i√ßin dil ve k√ºlt√ºr √ße≈üitliliƒüine uyum √∂nemlidir (Blodgett et al., 2020; Wu et al., 2020).                  |
| Kullanƒ±cƒ± Deneyimi ve Klinik Karar Destek Sistemi | Klinik uzmanlara sezgisel aray√ºz ve anlamlƒ± geri bildirimler                                   | 4.9            | Etkili klinik karar desteƒüi kullanƒ±cƒ± deneyimi ile doƒüru orantƒ±lƒ±dƒ±r (Beck et al., 2019; Holzinger et al., 2017).           |
| Yapay Zeka Etiƒüi, Adalet ve Bias Kontrol√º | AI kararlarƒ±nda etik ilkeler, adalet, tarafsƒ±zlƒ±k ve √∂nyargƒ± kontrol√º                           | 5.0            | Klinik AI uygulamalarƒ±nda etik ve tarafsƒ±zlƒ±k kritik √∂nemdedir (Morley et al., 2021; Obermeyer et al., 2019).                |

<div class="moodforge-section-title">
MoodForge, dijital n√∂ropsikiyatri ve hesaplamalƒ± psikiyatri alanlarƒ±nda geli≈ümi≈ü bir karar destek sistemidir. Multimodal veri entegrasyonu, yapay zeka destekli a√ßƒ±klanabilirlik ve g√ºvenlik standartlarƒ±na tam uyum ile y√ºksek performans sunar. Ayrƒ±ca, doƒüal dil i≈üleme ve sentetik veri √ºretimi gibi yenilik√ßi yakla≈üƒ±mlar ile klinik analiz s√ºre√ßlerini destekler. Ortalama puanƒ± <span style="font-size: 2em; font-weight: bold; color: red;">4.98</span> ile sekt√∂r√ºn en √ºst seviyelerindedir.
</div>
""", unsafe_allow_html=True)


# üëá Ana hasta √ºretim paneli Streamlit i√ßin üêá

# Modify these functionsüêá

def has_existing_patients():
    # Check if directory exists AND has patient foldersüêá
    return os.path.exists(BASE_DIR) and len(os.listdir(BASE_DIR)) > 0

# Replace the data generation section with this corrected logicüêá
if not has_existing_patients():
    st.subheader("üë• Ki≈üi Sayƒ±larƒ±nƒ± Belirleyin")

    total_count = st.number_input("üßç Toplam Birey Sayƒ±sƒ±", min_value=1, value=10, step=1,
                                 key="total_count_input")
    normal_count = st.number_input("üòä Normal Birey Sayƒ±sƒ±", min_value=0, max_value=total_count, value=2, step=1,
                                  key="normal_count_input")
    disordered_count = total_count - normal_count
    st.info(f"üß† Psikiyatrik Bozukluƒüu Olan Ki≈üi Sayƒ±sƒ±: {disordered_count}")
    
    num_days = st.number_input("üìÜ G√ºn Sayƒ±sƒ± (tavsiye edilen minimum 90 g√ºn)", min_value=30, value=90, step=10,
                              key="num_days_input")
    start_date = st.date_input("üóìÔ∏è Ba≈ülangƒ±√ß Tarihi", value=datetime.today(),
                              key="start_date_input")

    # üëá Ger√ßekten veri var mƒ± kontrol et (session_state'e deƒüil dizine bak)üêá
data_exists = os.path.exists(BASE_DIR) and len(os.listdir(BASE_DIR)) > 0

# üóëÔ∏è Verileri Sil butonu her zaman g√∂r√ºn√ºr (veri varsa)
if data_exists:
    if st.button("üóëÔ∏è Verileri Sil", key="delete_data_main"):
        shutil.rmtree(BASE_DIR)
        st.success("‚úÖ Veriler ba≈üarƒ±yla silindi. Sayfayƒ± yenileyin.")
        st.session_state.data_generated = False
        st.rerun()

# ‚úçÔ∏è Veri √ºretimi (veri yoksa)üêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
if not data_exists:
    if st.button("‚úçÔ∏è Verileri √úret ve Kaydet", key="generate_data_btn"):
        from datetime import timedelta
        os.makedirs(BASE_DIR, exist_ok=True)

        # üéØ Her grade'den en az 1 garanti √ºretimüêá
        guaranteed_normals = ["I", "II"]
        guaranteed_disorders = ["III", "IV", "V"]

        remaining_normal = normal_count - len(guaranteed_normals)
        remaining_disordered = disordered_count - len(guaranteed_disorders)

        # üé≤ Geri kalanƒ± istatistiksel olarak √ºretüêá
        rest_normals = random.choices(["I", "II"], weights=[0.6, 0.4], k=max(remaining_normal, 0))
        rest_disorders = random.choices(["III", "IV", "V"], weights=[0.5, 0.3, 0.2], k=max(remaining_disordered, 0))

        # üë• T√ºm bireylerin grade listesi
        all_grades = guaranteed_normals + rest_normals + guaranteed_disorders + rest_disorders
        random.shuffle(all_grades)

        # üß† Veri √ºretimiüêáüêá
        for i, grade in enumerate(all_grades):
            pid = f"sim_{i:03d}"
            disordered = grade in ["III", "IV", "V"]
            disorder_type = random.choice(["Depresyon", "Anksiyete", "Psikotik", "Bipolar", "TSSB", "OKB"]) if disordered else None

            # üü¢ 1. g√ºn verisi
            generate_daily(pid, datetime.today(), disordered=disordered, disorder_type=disorder_type, forced_grade=grade)

            create_dirs(pid)
            for d in range(num_days):
                date = datetime.combine(start_date + timedelta(days=d), datetime.min.time())
                generate_daily(pid, date, disordered=disordered, disorder_type=disorder_type, forced_grade=grade)
                generate_forms(pid, date, disordered=disordered, disorder_type=disorder_type)

        st.success("‚úÖ Veriler ba≈üarƒ±yla olu≈üturuldu. Sayfayƒ± yenileyin.")
        st.rerun()



# ‚ÑπÔ∏è √úretim yapƒ±ldƒ±ysa kullanƒ±cƒ±ya bilgi verüêáüêáüêáüêá
if data_exists:
    st.warning("üß† Zaten hasta verisi mevcut. Yeni √ºretim i√ßin √∂nce silmelisiniz.")


     
# Initialize session state variables
if "data_generated" not in st.session_state:
    st.session_state.data_generated = False
if "clinical_summary" not in st.session_state:
    st.session_state.clinical_summary = None
if "run_analysis" not in st.session_state:
    st.session_state.run_analysis = False
if "analiz_triggered" not in st.session_state:
    st.session_state.analiz_triggered = False


with st.expander("ü§ñüìà Random Forest Modeli ƒ∞√ßin *bence* Tavsiye Edilen Hasta Sayƒ±sƒ± üôÑ"):
    st.markdown("""
**üéØ Random Forest Modeli ƒ∞√ßin "Uzman Tavsiyesi" (!) Hasta Sayƒ±sƒ±**  

Aƒüa√ß √ºst√ºne aƒüa√ß koyuyoruz, orman kuruyoruz ama veri yok üå≤‚ùå  
Buyrun size ‚Äúbilimsel‚Äù hasta sayƒ±sƒ± √∂nerileri ‚Äî √ß√ºnk√º neden olmasƒ±n? ü§∑‚Äç‚ôÇÔ∏è

---

üî¢ **√ñzellik ba≈üƒ±na en az 10‚Äì20 √∂rnek**  
Yani modelde 9 √∂zellik varsa:  
‚Üí 9√ó10 = 90 hasta = *zar zor ge√ßer not* üòê  
‚Üí 9√ó20 = 180 hasta = *oh biraz daha i√ßimiz rahatladƒ±* üòÖ

---

‚öñÔ∏è **Sƒ±nƒ±f dengesizliƒüi mi dediniz?**  
5 risk sƒ±nƒ±fƒ± var di mi? Eh o zaman:  
‚Üí 5√ó20 = 100 hasta = *‚Äúminimum‚Äù olsun bari* ü§è  
‚Üí 5√ó30 = 150 hasta = *‚Äúg√∂z var nizam var‚Äù dedirtecek seviye* üëÄ

---

üí° **‚ÄúBen a≈üƒ±rƒ± √∂ƒürenmeyi sevmem‚Äù diyorsanƒ±z:**  
200‚Äì500 hasta arasƒ± = *modeliniz kendine gelir, travmayƒ± atlatƒ±r* üòåüíÜ‚Äç‚ôÄÔ∏è

---

üö´ **Peki ya 90'dan az hasta varsa?**  
O zaman...  
üé¨ *Random Forest sahneyi terk eder.*  
üé© *Model deƒüil, sihirbaz lazƒ±m!* ü™Ñ  
üìâ *Eƒüittim sandƒ±ƒüƒ±n ≈üey aslƒ±nda rastgele tahmin yapƒ±yor olabilir.*  
üòµ‚Äçüí´ *Ger√ßek veri yetmeyince aƒüa√ßlar birbirini kesmeye ba≈ülƒ±yor...*

Ama √ºz√ºlmeyin! ü§ó  
Model eƒüitmek ≈üart deƒüil √ß√ºnk√º:

üéØ **Zaten elinizde sihirli oyuncaklar var! üßô‚Äç‚ôÇÔ∏è‚ú®**  
Model yoksa da bu sistem:

- ‚úçÔ∏è **G√ºnl√ºk ruh hali ve davranƒ±≈ülarƒ± otomatik olarak sim√ºle ediyor.**  
- üìÑ **Anksiyete, depresyon gibi testleri rastgele deƒüil, anlamlƒ± ≈üekilde √ºretebiliyor.**  
- ‚öôÔ∏è **Adƒ±m, uyku, ruh hali gibi verilerle ki≈üinin i≈ülevselliƒüini √∂l√ß√ºyor.**  
- üß† **Yapay zek√¢ destekli uzman yorumlar sunarak klinik i√ßg√∂r√º saƒülƒ±yor.**  
- üé• **Y√ºz ve ses analiziyle duygusal uyumu √∂l√ß√ºp, profesyonel g√∂zlem gibi √ßalƒ±≈üƒ±yor.**

üìâ *Yani Random Forest yoksa hayat durmuyor.*  
Sistem h√¢l√¢ bir mini klinik laboratuvar gibi √ßalƒ±≈üƒ±yor! üß™üí°  
Hatta bazen modelin ‚Äú√∂ƒürenmesine‚Äù gerek bile yok ‚Äî √ß√ºnk√º veriniz zaten akƒ±llƒ±! üòâ

---

üßæ **Toparlarsak:**  
- üö® *Alt sƒ±nƒ±rlarƒ±n altƒ±*: ‚âà 90 hasta  
- üîÑ *Dengeli olsun, g√∂ze batsƒ±n istemem*: ‚â• 100 hasta  
- üß† *Model adam gibi √∂ƒürensin*: 200‚Äì500 hasta ‚Üí ƒ∞≈üte bu! üëåüî•

---

üåü Kƒ±sacasƒ±, az hasta = az dert üé≠  
Ama veri varsa... Random Forest co≈üar! üéâüå≤üéâ
    """)

# Check for existing model fileüêáüêá
model_path = "random_forest_risk_model.pkl"  
model_exists = os.path.exists(model_path)

# Update session state if model exists but flag is not setüêáüêáüêáüêá
if model_exists and not st.session_state.get("model_trained", False):
    st.session_state.model_trained = True

# Eƒüer hastalar varsa ve model yoksa: model eƒüitme aray√ºz√ºn√º g√∂ster
if has_existing_patients():
    if not model_exists:
        st.markdown("## üöÇ Random Forest Model Eƒüitimi")

        if st.button("üõ†Ô∏è Random Forest Modeli Eƒüit", key="train_rf_button"):
            import subprocess
            with st.spinner("Model eƒüitiliyor‚Ä¶"):
                subprocess.run(
                    ["python", os.path.join(os.path.dirname(__file__), "train_random_forest_model.py")],
                    check=True
                )
            st.success("‚úÖ Model olu≈üturuldu: random_forest_risk_model.pkl")
            st.session_state.model_trained = True
        # Bilimsel a√ßƒ±klama
        st.markdown("""
**Model Tanƒ±mƒ±:**  
Bu modelleme yakla≈üƒ±mƒ±, **Random Forest (RF)** algoritmasƒ±na dayanan, √ßok deƒüi≈ükenli ve denetimli bir sƒ±nƒ±flandƒ±rƒ±cƒ± olarak yapƒ±landƒ±rƒ±lmƒ±≈ütƒ±r. Model, bireylerin **en g√ºncel duygudurum profili (mood average)**, **davranƒ±≈üsal i≈ülevsellik d√ºzeyi (functioning score)**, **fiziksel aktivite (g√ºnl√ºk adƒ±m sayƒ±sƒ±)**, **uyku s√ºresi** ve **standart psikometrik deƒüerlendirme skorlarƒ±** (PHQ-9, GAD-7, PSS-10, PSQI, IES-R) gibi klinik ve davranƒ±≈üsal parametrelerini girdi olarak kullanƒ±r.

√áƒ±ktƒ± olarak, **Grade I‚ÄìV** aralƒ±ƒüƒ±nda tanƒ±mlƒ± be≈ü d√ºzeyli bir klinik risk sƒ±nƒ±flandƒ±rmasƒ± √ºretir. Bu sƒ±nƒ±flama, semptom ≈üiddeti ve g√ºnl√ºk i≈ülevsellik gibi √ßok boyutlu veriler √ºzerinden bireyin ruhsal saƒülƒ±k riskini **fenotipik d√ºzeyde** √∂ng√∂rmeyi hedefler.

Random Forest algoritmasƒ±, **Breiman (2001)** tarafƒ±ndan tanƒ±mlanan **bootstrap-aggregated decision tree ensemble** yapƒ±sƒ± temelinde √ßalƒ±≈üƒ±r. Model, varyans azaltƒ±mƒ± ve genelleme performansƒ±nƒ±n artƒ±rƒ±lmasƒ± a√ßƒ±sƒ±ndan avantaj saƒülar; √∂zellikle tƒ±bbi verilerde sƒ±k√ßa kar≈üƒ±la≈üƒ±lan **y√ºksek boyutluluk** ve **sƒ±nƒ±f dengesizliƒüi** gibi problemlere kar≈üƒ± **dayanƒ±klƒ±** bir mimari sunar.

Modelin **a√ßƒ±klanabilirliƒüi**, her bir √∂znitelik katkƒ±sƒ±nƒ±n deƒüerlendirilmesine olanak tanƒ±yan **SHAP (SHapley Additive exPlanations)** √ßer√ßevesi ile saƒülanmƒ±≈ütƒ±r. Bu sayede, risk sƒ±nƒ±fƒ±nƒ±n belirlenmesinde hangi klinik deƒüi≈ükenlerin ne √∂l√ß√ºde etkili olduƒüu nesnel bi√ßimde analiz edilebilir. SHAP deƒüerleri, bireysel vaka bazƒ±nda **karar ≈üeffaflƒ±ƒüƒ± ve klinik yorum yapƒ±labilirlik** saƒülar.

Model, eƒüitim ve test k√ºmeleri √ºzerinde **stratifiye √ßapraz doƒürulama (k-fold cross-validation)** y√∂ntemi ile deƒüerlendirilmi≈ü; **AUC, doƒüruluk (accuracy), hassasiyet (precision), √∂zg√ºll√ºk (specificity) ve F1 skoru** gibi metriklerle performans validasyonu yapƒ±lmƒ±≈ütƒ±r. Sonu√ßlar, algoritmanƒ±n **y√ºksek kararlƒ±lƒ±k (robustness)** ve **genellenebilirlik** √∂zelliklerine sahip olduƒüunu g√∂stermektedir.

Bu yapƒ±, veri odaklƒ± psikiyatrik deƒüerlendirme s√ºre√ßlerinde hem **risk stratifikasyonu**, hem de **klinik karar destek** amacƒ±yla kullanƒ±labilecek **uygulanabilir, a√ßƒ±klanabilir ve yorumlanabilir** bir algoritmik yakla≈üƒ±mdƒ±r.
""")
        # bir daha g√∂sterilmesin
    elif model_exists:
        st.info("‚úÖ Random Forest modeli zaten eƒüitilmi≈ü.")




# === Renk ve etiket sƒ±nƒ±flarƒ± ===üêáüêáüêá
def get_risk_category(score):
    danger = calculate_danger_level_from_functioning(score) * 20
    if danger < 20:
        return "üü¢ Grade I - Minimum Risk"
    elif danger < 40:
        return "üü¢ Grade II - Mild Risk"
    elif danger < 60:
        return "üü° Grade III - Moderate Risk"
    elif danger < 80:
        return "üü† Grade IV - Significant Risk"
    else:
        return "üî¥ Grade V - Severe Risk"

def calculate_danger_level_from_functioning(functioning_score):
    try:
        return round(5 - (functioning_score / 20), 2)
    except:
        return 3

st.sidebar.markdown("## üë§ Hasta Se√ßimi")

if os.path.exists(BASE_DIR):
    raw_patients = sorted(os.listdir(BASE_DIR))
    display_labels = []
    patient_map = {}

    for pid in raw_patients:
        try:
            base = os.path.join(BASE_DIR, pid)

            # Mood verisi
            mood_df = None
            mood_path = os.path.join(base, "mood_tracking")
            mood_files = sorted(os.listdir(mood_path)) if os.path.exists(mood_path) else []
            if mood_files:
                mood_df = pd.read_csv(os.path.join(mood_path, mood_files[-1]))

            # NLP
            journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
            audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))
            nlp_summary = {
                "journal_sent": round(pd.Series(journal_sents).mean(), 2) if journal_sents else 0,
                "journal_subj": round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else 0,
                "journal_emos": pd.Series(journal_emos).value_counts().to_dict(),
                "audio_sent": round(pd.Series(audio_sents).mean(), 2) if audio_sents else 0,
                "audio_subj": round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else 0,
                "audio_emos": pd.Series(audio_emos).value_counts().to_dict(),
            }

            # Video
            video_json = {"dominant_emotion": "n√∂tr", "emotion_scores": {"n√∂tr": 1.0}}
            video_path = os.path.join(base, "video_analysis")
            if os.path.exists(video_path) and os.listdir(video_path):
                with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
                    video_json = json.load(f)

            # Formlar
            form_scores = {}
            for form in FORM_WEEKLY + FORM_MONTHLY:
                form_path = os.path.join(base, f"forms/{form}")
                if os.path.exists(form_path):
                    form_files = sorted(os.listdir(form_path))
                    if form_files:
                        with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                            latest_form = json.load(f)
                            form_scores[form] = {
                                "score": latest_form["score"],
                                "severity": latest_form["severity"]
                            }

            # Adƒ±m ve uyku
            avg_steps = "-"
            avg_sleep = "-"
            health_path = os.path.join(base, "healthkit")
            if os.path.exists(health_path):
                files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
                if files:
                    df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
                    df = pd.concat(df_list, ignore_index=True)
                    avg_steps = int(df["steps"].mean())
                    avg_sleep = round(df["hours"].mean(), 2)

            # ƒ∞≈ülevsellik
            functioning_score = 50
            func_path = os.path.join(base, "functioning_score")
            if os.path.exists(func_path):
                files = sorted([f for f in os.listdir(func_path) if f.endswith(".csv")])
                if files:
                    df = pd.read_csv(os.path.join(func_path, files[-1]))
                    functioning_score = df["score"].values[0]

            # Risk derecesi
            grade, danger_score = load_patient_grade(pid)
            if grade is not None and danger_score is not None:
                score = danger_score
                risk_label = {
                    "I": "üü¢ Grade I - Minimum Risk",
                    "II": "üü¢ Grade II - Mild Risk",
                    "III": "üü° Grade III - Moderate Risk",
                    "IV": "üü† Grade IV - Significant Risk",
                    "V": "üî¥ Grade V - Severe Risk"
                }.get(grade, "‚ö†Ô∏è Risk Belirsiz")
            else:
                danger_score = calculate_danger_level(
                    mood_df,
                    nlp_summary,
                    video_json,
                    form_scores,
                    avg_steps,
                    avg_sleep,
                    functioning_score
                )
                risk_label = "‚ö†Ô∏è Risk Belirsiz"

            # Etiket olu≈ütur
            label = f"{risk_label} ‚Äì {pid}"
            display_labels.append(label)
            patient_map[label] = pid

        except Exception as e:
            print(f"{pid} i√ßin hata: {e}")
            continue
    

    if display_labels:
        selected_label = st.sidebar.selectbox(
            "Bir hasta se√ßin:", 
            display_labels, 
            key="patient_selector"
        )
        selected = patient_map.get(selected_label)
    else:
        st.sidebar.info("üì≠ Hasta bulunamadƒ±. L√ºtfen √∂nce veri √ºretin.")
        selected = None
      
#-------------------------------------------------------------------------------------------       

    st.sidebar.markdown("""
<strong style="font-size: 15px;">üìã Risk Derecelendirme A√ßƒ±klamalarƒ±</strong><br>
Bu model, U.S. National Cancer Institute tarafƒ±ndan geli≈ütirilen Common Terminology Criteria for Adverse Events (CTCAE v5.0) sisteminin derecelendirme mantƒ±ƒüƒ± temel alƒ±narak psikiyatrik deƒüerlendirme i√ßin uyarlanmƒ±≈ütƒ±r.<br>
<div style="margin-top: 12px;">
    <div style="margin-bottom: 6px;">üü¢ Grade I ‚Äì Minimum Risk</div>
    <div style="margin-bottom: 6px;">üü¢ Grade II ‚Äì Mild Risk</div>
    <div style="margin-bottom: 6px;">üü° Grade III ‚Äì Moderate Risk</div>
    <div style="margin-bottom: 6px;">üü† Grade IV ‚Äì Significant Risk</div>
    <div>üî¥ Grade V ‚Äì Severe Risk</div>
</div>

<div style="margin-top:10px; font-size: 11px; color: #ccc;">
    Source: <a href="https://ctep.cancer.gov/protocolDevelopment/electronic_applications/ctc.htm" target="_blank" style="color:#88c0d0;">CTCAE v5.0 ‚Äì NIH</a>
</div>
""", unsafe_allow_html=True)

else:
    selected = None
    st.sidebar.info("Veri klas√∂r√º mevcut deƒüil. L√ºtfen √∂nce veri √ºretin.")

st.sidebar.markdown("---")

# ‚Äî‚Äî‚Äî SHAP Analizi ‚Äî‚Äî‚Äî
# üö® selected bo≈ü olabilir, kontrol et
if selected is not None:
    # üìÅ Veri klas√∂r√º var mƒ±?
    veri_var = os.path.exists(os.path.join(BASE_DIR, selected))
else:
    veri_var = False

# üîò Butonlar sadece veri varsa g√∂sterilsin
if veri_var:
    pid = selected
    date_str = datetime.now().strftime("%Y%m%d")
    shap_folder = os.path.join(BASE_DIR, pid, "gpt_analysis")
    shap_path = Path(f"{shap_folder}/shap_waterfall_{date_str}.png")
    shap_bar = Path(f"{shap_folder}/shap_bar_{date_str}.png")
    shap_txt = Path(f"{shap_folder}/shap_ai_comment_{date_str}.txt")
    shap_done = shap_path.exists() and shap_bar.exists() and shap_txt.exists()

    # üé® CSS stilleri (butonlar i√ßin)
    st.sidebar.markdown("""
        <style>
        .flash-button {
            background-color: #f5b800;
            color: black;
            padding: 10px 18px;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            animation: blink 1s infinite;
            transition: 0.3s;
            width: 100%;
            margin-bottom: 20px;
        }
        @keyframes blink {
            0% {opacity: 1;}
            50% {opacity: 0.5;}
            100% {opacity: 1;}
        }
        .disabled-button {
            background-color: #d3d3d3;
            color: #333;
            padding: 10px 18px;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            width: 100%;
            cursor: not-allowed;
            margin-bottom: 20px;
        }
        </style>
    """, unsafe_allow_html=True)

    # üîò SHAP Butonu
    if shap_done:
        st.sidebar.markdown(
            '<button class="disabled-button" disabled>üå≤‚öôÔ∏è SHAP Analizi (Random Forest)</button>',
            unsafe_allow_html=True
        )
    else:
        # HTML form kaldƒ±rƒ±ldƒ±; yerine streamlit butonu
        if st.sidebar.button("üå≤‚öôÔ∏è **SHAP Analizi (Random Forest -BADT-)**", key=f"shap_btn_{selected}"):
            st.session_state["shap_triggered"] = True


    # GPT-4 Turbo analizi tetikleme
    if st.sidebar.button("üîç**Yapay Zeka Analizi; GPT-4-Turbo**", key="ai_analysis_button"):
        st.session_state.analiz_triggered = True

    if st.sidebar.button("**Risk Projeksiyonunu G√∂ster**"):
        st.session_state.show_risk_projection = True

     # ‚Üì BUTONUN HEMEN ALTINA EKLENECEK A√áIKLAMA
    st.sidebar.markdown(
        """
        **Not:** Projection.py‚Äôde **RANDOM FOREST Rƒ∞SK MODELƒ∞** (Bootsrap Aggregated Decision Trees), **`load_model()`** ile y√ºklenir ve
        **`load_patient_features()`** ile elde edilen hasta verileri **`predict_risk_score()`**
        i√ßinde **`model.predict_proba`**‚Äôya sokularak **0‚Äì100** arasƒ± bir **‚Äúba≈ülangƒ±√ß risk skoru‚Äù**
        √ºretir. Bu skor, sim√ºlasyonun **`x0`** deƒüeri olarak kullanƒ±ldƒ±ƒüƒ±nda m√ºdahale
        eƒürilerinin hasta bazlƒ± ger√ßek√ßi bir ba≈ülangƒ±√ß seviyesine sahip olmasƒ±nƒ± saƒülar.
        **BU Y√úZDEN, Rƒ∞SK PROJEKSƒ∞YONU G√ñSTERƒ∞LMEDEN √ñNCE MODELƒ∞N Eƒûƒ∞Tƒ∞LMESƒ∞ GEREKƒ∞R!!!**
        """
    )
         

# Hasta se√ßildiƒüinde kayƒ±tlƒ± klinik √∂zeti y√ºkle
if selected:
    clinical_summary = load_clinical_summary(selected)
    if clinical_summary:
        st.session_state.clinical_summary = clinical_summary
    else:
        st.session_state.clinical_summary = None

# Display patient data if selected
if selected:
    st.markdown("---")
    st.header(f"üìä {selected} - Hasta Verileri")




#--------------------------------------------------------------------------------------------
    if st.session_state.get("show_risk_projection", False):
        try:
            projeksiyon = run_simulation_for_patient(selected)
            if hasattr(projeksiyon, "to_plotly_json"):
                st.subheader("üìà Risk ve M√ºdahale Eƒürileri Sim√ºlasyonu")
                st.plotly_chart(projeksiyon, use_container_width=True, key=f"risk_proj_{selected}_plotly")
            elif projeksiyon is not None and hasattr(projeksiyon, "canvas"):
                st.subheader("üìà Risk ve M√ºdahale Eƒürileri Sim√ºlasyonu")
                st.pyplot(projeksiyon, key=f"risk_proj_{selected}")
            elif isinstance(projeksiyon, str):
                st.info(projeksiyon)
        except Exception as e:
            st.warning(f"Risk projeksiyonu grafiƒüi g√∂sterilemedi: {e}")
        st.session_state.show_risk_projection = False

    # ‚Äî‚Äî‚Äî Heatmap Paneli: se√ßim yapƒ±nca hemen g√∂ster ‚Äî‚Äî‚Äîüêáüêáüêá
    with st.expander("üìä Heatmap Paneli"):
        choice = st.selectbox(
            "G√∂sterilecek Heatmap:",
            ["Mood", "Functioning", "Health", "Forms", "Journal", "Audio", "Video"],
            format_func=lambda x: {
                "Mood": "üß† Mood Takibi",
                "Functioning": "‚öñÔ∏è ƒ∞≈ülevsellik",
                "Health": "üèÉ Adƒ±m & Uyku",
                "Forms": "üìù Test Skorlarƒ±",
                "Journal": "üìò Journal NLP",
                "Audio": "üé§ Audio NLP",
                "Video": "üìπ Video NLP"
            }[x],
            key="heatmap_choice"
        )
        show_all_heatmaps(selected, category=choice)

    base = os.path.join(BASE_DIR, selected)
    shap_folder = os.path.join(base, "gpt_analysis")

    # Eƒüer SHAP daha √∂nce yapƒ±lmƒ±≈üsa sadece g√∂ster
    if os.path.isdir(shap_folder):
        files = os.listdir(shap_folder)
        if any(f.startswith("shap_waterfall_") for f in files) \
        and any(f.startswith("shap_bar_") for f in files) \
        and any(f.startswith("shap_ai_comment_") for f in files):
            st.subheader("üß† Psikiyatrik Risk Sƒ±nƒ±flandƒ±rmasƒ±nda A√ßƒ±klanabilirlik: SHapley Additive exPlanations (SHAP) ve Random Forest Yakla≈üƒ±mƒ±üìâ")
            wf = sorted([f for f in files if f.startswith("shap_waterfall_")])[-1]
            bar = sorted([f for f in files if f.startswith("shap_bar_")])[-1]
            txt = sorted([f for f in files if f.startswith("shap_ai_comment_")])[-1]
            st.image(os.path.join(shap_folder, wf), caption="Waterfall SHAP")
            st.image(os.path.join(shap_folder, bar), caption="Bar SHAP")
            st.markdown(open(os.path.join(shap_folder, txt), encoding="utf-8").read())

    # üîÅ SHAP analizi sadece butona basƒ±ldƒ±ƒüƒ±nda ve daha √∂nce yapƒ±lmadƒ±ysa √ßalƒ±≈ütƒ±rüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêáüêá
    if st.session_state.get("shap_triggered", False) and not shap_done:
        explain_patient_with_rf_and_shap(selected)
        st.session_state["shap_triggered"] = False

    base = os.path.join(BASE_DIR, selected)

    # Initialize variables with default values
    video_json = {"dominant_emotion": "n√∂tr", "emotion_scores": {"n√∂tr": 1.0}}
    emo_json = {"text_emotion": "n√∂tr", "voice_emotion": "n√∂tr", "face_emotion": "n√∂tr"}
    form_scores = {}
    mood_df = None
    avg_steps, avg_sleep = "-", "-"
    functioning_score = 50  # Varsayƒ±lan deƒüer

    # Load functioning score
    try:
        functioning_path = os.path.join(BASE_DIR, selected, "functioning_score")
        if os.path.exists(functioning_path):
            function_files = sorted(os.listdir(functioning_path))
            if function_files:
                func_df = pd.read_csv(os.path.join(functioning_path, function_files[-1]))
                functioning_score = func_df["score"].values[0]
    except Exception as e:
        st.error(f"Error loading functioning score: {e}")

    # Load video_json
    video_path = os.path.join(base, "video_analysis")
    if os.path.exists(video_path) and os.listdir(video_path):
        with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
            video_json = json.load(f)

    # Load emotion_consistency
    emo_path = os.path.join(base, "emotion_consistency")
    if os.path.exists(emo_path) and os.listdir(emo_path):
        with open(os.path.join(emo_path, sorted(os.listdir(emo_path))[-1]), "r", encoding="utf-8") as f:
            emo_json = json.load(f)

    # Load form_scores
    for form in FORM_WEEKLY + FORM_MONTHLY:
        form_path = os.path.join(base, f"forms/{form}")
        if os.path.exists(form_path):
            form_files = sorted(os.listdir(form_path))
            if form_files:
                with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                    latest_form = json.load(f)
                    form_scores[form] = {
                        "score": latest_form["score"],
                        "severity": latest_form["severity"]
                    }

    # NLP stats
    journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
    audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))

    # NLP summary
    nlp_summary = {
        "journal_sent": f"Ort. Sentiment: {round(pd.Series(journal_sents).mean(), 2) if journal_sents else '-'}",
        "journal_subj": f"Ort. √ñznelik: {round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else '-'}",
        "journal_emos": pd.Series(journal_emos).value_counts().to_dict() if journal_emos else {},
        "audio_sent": f"Ort. Sentiment: {round(pd.Series(audio_sents).mean(), 2) if audio_sents else '-'}",
        "audio_subj": f"Ort. √ñznelik: {round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else '-'}",
        "audio_emos": pd.Series(audio_emos).value_counts().to_dict() if audio_emos else {},
    }

    # Display mood data if available
    try:
        mood_files = sorted(os.listdir(os.path.join(base, "mood_tracking")))
        if mood_files:
            mood_df = pd.read_csv(os.path.join(base, "mood_tracking", mood_files[-1]))
            if mood_df is not None:
                pass  # Placeholder to fix indentation error
        else:
            st.error("Mood tracking data is missing.")
    except Exception as e:
        st.error(f"Error loading mood data: {e}")    # √ñnce risk deƒüerlendirmesini g√∂ster
    grade, danger_level = load_patient_grade(selected)
    if grade is not None and danger_level is not None:
        risk_level = grade
        score = danger_level
        # Renk ve metinleri grade'a g√∂re ayarla
        color_map = {
            "I": ("Minimum Risk", "rgb(0, 128, 0)"),
            "II": ("Mild Risk", "rgb(144, 238, 144)"),
            "III": ("Moderate Risk", "rgb(255, 204, 0)"),
            "IV": ("Significant Risk", "rgb(255, 140, 0)"),
            "V": ("Severe Risk", "rgb(255, 0, 0)")
        }
        danger_text, color = color_map.get(grade, ("Bilinmiyor", "gray"))
    else:
        # fallback eski hesaplama
        danger_score = calculate_danger_level(
            mood_df,
            nlp_summary,
            video_json,
            form_scores,
            avg_steps,
            avg_sleep,
            functioning_score
)
            
    st.markdown("### Klinik Risk Deƒüerlendirmesi")
    st.markdown(f'<div class="blinking" style="color: {color}; font-size: 72px;">{danger_level:.2f} ({risk_level}: {danger_text})</div>', unsafe_allow_html=True)
    
    # ‚¨áÔ∏è Ruh hali deƒüerlerinin zaman serisi grafiƒüiüêáüêáüêáüêá
    st.subheader("üòä Ruh Hali Deƒüerleri")
    mood_path = os.path.join(base, "mood_tracking")
    if os.path.exists(mood_path):
        mood_files = sorted([f for f in os.listdir(mood_path) if f.endswith(".csv")])
        if mood_files:
            # T√ºm mood dosyalarƒ±nƒ± y√ºkle ve birle≈ütir
            mood_list = [pd.read_csv(os.path.join(mood_path, f)) for f in mood_files]
            mood_all = pd.concat(mood_list, ignore_index=True)
            
            # Tarih bilgisini dosya adƒ±ndan √ßƒ±kar ve DataFrame'e ekle
            dates = [f.replace("mood_", "").replace(".csv", "") for f in mood_files]
            mood_all["date"] = [datetime.strptime(d, "%Y%m%d") for d in dates]
            mood_all = mood_all.sort_values("date")
            
            # Ortalama deƒüerleri hesapla
            avg_huzur = round(mood_all["huzur"].mean(), 2)
            avg_enerji = round(mood_all["enerji"].mean(), 2)
            avg_anksiyete = round(mood_all["anksiyete"].mean(), 2)
            avg_ofke = round(mood_all["√∂fke"].mean(), 2)
            avg_depresif = round(mood_all["depresif"].mean(), 2)
            
            # Ortalama deƒüerleri g√∂ster
            cols = st.columns(5)
            with cols[0]:
                st.metric("Ort. Huzur", avg_huzur)
            with cols[1]:
                st.metric("Ort. Enerji", avg_enerji)
            with cols[2]:
                st.metric("Ort. Anksiyete", avg_anksiyete)
            with cols[3]:
                st.metric("Ort. √ñfke", avg_ofke)
            with cols[4]:
                st.metric("Ort. Depresif", avg_depresif)
            
            # Her bir parametre i√ßin zaman serisi grafiƒüiüêáüêáüêáüêá
            st.markdown("### üß† Ruh Hali Parametreleri Zaman Serisi")
            
            # T√ºm parametreleri tek grafikte g√∂ster - se√ßenek 1üêáüêáüêá
            st.line_chart(mood_all.set_index("date")[["huzur", "enerji", "anksiyete", "√∂fke", "depresif"]], 
                          use_container_width=True)
            
            # Alternatif olarak her parametreyi ayrƒ± grafikte g√∂ster - se√ßenek 2üêáüêáüêá
            tabs = st.tabs(["Huzur", "Enerji", "Anksiyete", "√ñfke", "Depresif", "Ortalama"])
            
            with tabs[0]:
                st.line_chart(mood_all.set_index("date")["huzur"], use_container_width=True)
            with tabs[1]:
                st.line_chart(mood_all.set_index("date")["enerji"], use_container_width=True)
            with tabs[2]:
                st.line_chart(mood_all.set_index("date")["anksiyete"], use_container_width=True)
            with tabs[3]:
                st.line_chart(mood_all.set_index("date")["√∂fke"], use_container_width=True)
            with tabs[4]:
                st.line_chart(mood_all.set_index("date")["depresif"], use_container_width=True)
            with tabs[5]:
                st.line_chart(mood_all.set_index("date")["average"], use_container_width=True)
        else:
            st.info("üì≠ Ruh hali verisi hen√ºz mevcut deƒüil.")
    else:
        st.info("üìÅ Ruh hali klas√∂r√º hen√ºz olu≈üturulmamƒ±≈ü.")

    # Display video emotion analysis
    st.subheader("üé• Video Duygu Analizi")
    if os.path.exists(video_path) and os.listdir(video_path):
        files = sorted(os.listdir(video_path))
        with open(os.path.join(video_path, files[-1]), "r", encoding="utf-8") as f:
            v = json.load(f)
        st.markdown(f"**Baskƒ±n Duygu:** {v['dominant_emotion']}")
        st.bar_chart(pd.Series(v["emotion_scores"]))
    else:
        st.info("Video duygu analizi verisi hen√ºz mevcut deƒüil.")

    # Journal NLP stats
    st.subheader("üìù G√ºnl√ºk (journal) NLP ƒ∞statistikleri")
    if journal_sents:
        st.markdown("**Sentiment**")
        st.line_chart(journal_sents, use_container_width=True)
    if journal_subjs:
        st.markdown("**√ñznelik/Subjectivity**")
        # √ñznelik deƒüerlerini DataFrame olarak hazƒ±rlayƒ±n ve renkli bir √ßizgi olarak g√∂sterin
        subj_df = pd.DataFrame({"subjectivity": journal_subjs})
        st.line_chart(subj_df, use_container_width=True)
    if journal_emos:
        st.markdown("**Duygu Daƒüƒ±lƒ±mƒ±**")
        # Renk haritasƒ± uygulayƒ±n
        emotion_counts = pd.Series(journal_emos).value_counts()
        # En az bir deƒüer olduƒüundan emin olun
        for emotion in EMOTIONS:
            if emotion not in emotion_counts:
                emotion_counts[emotion] = 0
        st.bar_chart(emotion_counts, use_container_width=True)
    if not (journal_sents or journal_subjs or journal_emos):
        st.info("G√ºnl√ºk NLP verisi bulunamadƒ±.")

    # Audio NLP stats
    st.subheader("üé§Ses NLP ƒ∞statistikleri")
    if audio_sents:
        st.markdown("**Sentiment**")
        st.line_chart(audio_sents, use_container_width=True)
    if audio_subjs:
        st.markdown("**√ñznelik/Subjectivity**")
        st.line_chart(audio_subjs, use_container_width=True)
    if audio_emos:
        st.markdown("**Duygu Daƒüƒ±lƒ±mƒ±**")
        st.bar_chart(pd.Series(audio_emos).value_counts(), use_container_width=True)
    if not (audio_sents or audio_subjs or audio_emos):
        st.info("Ses NLP verisi bulunamadƒ±.")

    # Health data
    st.subheader("üèÉ Adƒ±m & Uyku")
    health_path = os.path.join(base, "healthkit")
    if os.path.exists(health_path):
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        if files:
            df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
            df = pd.concat(df_list, ignore_index=True)
            df["date"] = pd.to_datetime(df["date"])
            df = df.sort_values("date")

            avg_steps = int(df["steps"].mean())
            avg_sleep = round(df["hours"].mean(), 2)

            st.markdown("### üö∂ G√ºnl√ºk Adƒ±m Sayƒ±sƒ±")
            st.line_chart(df.set_index("date")["steps"], use_container_width=True)

            st.markdown("### üõå G√ºnl√ºk Uyku S√ºresi")
            st.line_chart(df.set_index("date")["hours"], use_container_width=True)
        else:
            st.info("üì≠ Saƒülƒ±k verisi hen√ºz mevcut deƒüil.")
    else:
        st.info("üìÅ Saƒülƒ±k klas√∂r√º hen√ºz olu≈üturulmamƒ±≈ü.")

    # Psychometric test scores
    st.subheader("üìù Psikometrik Test Skorlarƒ±")
    for form in FORM_WEEKLY + FORM_MONTHLY:
        path = os.path.join(base, f"forms/{form}")
        if os.path.exists(path) and os.listdir(path):
            try:
                data = [json.load(open(os.path.join(path, f), "r", encoding="utf-8")) for f in sorted(os.listdir(path))]
                df = pd.DataFrame(data)
                df["date"] = pd.to_datetime(df["date"])
                st.markdown(f"#### {form}")
                st.line_chart(df.set_index("date")["score"])
            except Exception as e:
                st.warning(f"{form} verisi okunurken hata olu≈ütu: {str(e)}")
        else:
            st.info(f"{form} form verisi bulunamadƒ±.")

    # Functioning Score Display
    st.subheader("‚öñÔ∏è ƒ∞≈ülevsellik Skoru")
    func_path = os.path.join(base, "functioning_score")
    if os.path.exists(func_path):
        func_files = sorted([f for f in os.listdir(func_path) if f.endswith(".csv")])
        if func_files:
            df_list = [pd.read_csv(os.path.join(func_path, filename)) for filename in func_files]
            if df_list:
                df = pd.concat(df_list, ignore_index=True)
                df["date"] = pd.to_datetime(df["date"])
                df = df.sort_values("date")

                # Ortalama i≈ülevsellik skoru
                avg_func = round(df["score"].mean(), 2)
                st.metric("Ort. ƒ∞≈ülevsellik", avg_func)

                # Son skor
                latest_score = df["score"].values[-1]
                st.markdown(f"### Son ƒ∞≈ülevsellik Skoru: {latest_score}/100")

                # Skor deƒüerlendirmesi
                if latest_score < 40:
                    st.error("D√º≈ü√ºk ƒ∞≈ülevsellik: G√ºnl√ºk ya≈üam aktivitelerini s√ºrd√ºrmede √∂nemli zorluklar ya≈üƒ±yor.")
                elif latest_score < 70:
                    st.warning("Orta ƒ∞≈ülevsellik: Bazƒ± alanlarda zorluklar ya≈üasa da temel i≈ülevleri s√ºrd√ºrebiliyor.")
                else:
                    st.success("Y√ºksek ƒ∞≈ülevsellik: ƒ∞≈ülevsellikte √∂nemli bir sorun g√∂zlenmiyor.")                # ƒ∞≈ülevsellik trendi (t√ºm s√ºreci g√∂steren grafik)üêáüêá
                st.markdown("### ƒ∞≈ülevsellik Trendi")
                st.line_chart(df.set_index("date")["score"], use_container_width=True)
            else:
                st.info("ƒ∞≈ülevsellik verileri hen√ºz mevcut deƒüil.")
        else:
            st.info("ƒ∞≈ülevsellik dosyasƒ± bulunamadƒ±.")
    else:
        st.info("ƒ∞≈ülevsellik klas√∂r√º mevcut deƒüil.")
    
# Sidebar'da klinik √∂zet ve yapay zeka analizi g√∂sterimiüêáüêá
if selected:    # Klinik √∂zet (ham verilerle)
    clinical_overview = generate_clinical_overview(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, avg_func)
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"<div style='white-space: normal; font-size:15px; text-align:left'>{clinical_overview}</div>", unsafe_allow_html=True)# Yapay zeka analizi butonuna basƒ±lƒ±rsa GPT'den analiz al ve kaydetüêáüêáüêá
    if st.session_state.get("analiz_triggered", False):
        # Eƒüer daha √∂nce kaydedilmi≈ü analiz yoksa GPT'den al
        ai_summary = load_clinical_summary(selected)
        if not ai_summary:
            ai_summary = generate_clinical_summary(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, patient_id=selected)
            save_clinical_summary(selected, ai_summary)
        st.session_state.clinical_summary = ai_summary
        st.session_state.analiz_triggered = False  # Buton tetiklenmesini sƒ±fƒ±rla
        
    # Eƒüer kaydedilmi≈ü analiz varsa g√∂sterüêáüêáüêáüêá
    if st.session_state.clinical_summary:
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ü§ñ Yapay Zeka Klinik Analizi")
        formatted_summary = format_clinical_summary(st.session_state.clinical_summary)
        st.sidebar.markdown(f"<div style='white-space: normal; font-size:15px; text-align:left'>{formatted_summary}</div>", unsafe_allow_html=True)
        st.sidebar.markdown("### üìö DSBIT Referans Listesi")
        for title, url in DSBIT_REFERENCES:
            st.sidebar.markdown(f"- [{title}]({url})")

