from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

from templates.journal_templates import get_journal
from templates.audio_templates import get_audio
from templates.video_templates import get_video_emotion_scores
from projection import run_simulation_for_patient
import shap
import pickle
import matplotlib.pyplot as plt
import streamlit as st
import streamlit.components.v1 as components
import os
import json
import shutil
import random
import pandas as pd
import re
from datetime import datetime, timedelta
from dotenv import load_dotenv
import openai
import time
from tenacity import retry, stop_after_attempt, wait_exponential
import numpy as np
import plotly.express as px
from pathlib import Path
import glob
import math
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)))



DSBIT_REFERENCES = [
    ("APA. (2013). Diagnostic and Statistical Manual of Mental Disorders (5th ed.).", "https://www.psychiatry.org/psychiatrists/practice/dsm"),
    ("WHO. (2021). International Classification of Diseases (11th Revision).", "https://icd.who.int/"),
    ("Kroenke, K., et al. (2010). The PHQ-9: A new depression diagnostic and severity measure.", "hhttps://jacobimed.org/public/Ambulatory_files/mlove/CurriculumWomenandGeri/Depression/Depression%20articles/PHQ-9ReviewKroenke.pdf"),
    ("Spitzer, R. L., et al. (2006). A brief measure for assessing generalized anxiety disorder: The GAD-7.", "https://doi.org/10.1001/archinte.166.10.1092"),
    ("Buysse, D. J., et al. (1989). The Pittsburgh Sleep Quality Index: a new instrument for psychiatric practice and research.", "https://doi.org/10.1016/0165-1781(89)90047-4"),
    ("Cohen, S., et al. (1983). A global measure of perceived stress.", "https://doi.org/10.2307/2136404"),
    ("Weiss, D. S., & Marmar, C. R. (1997). The Impact of Event Scale-Revised.", "https://www.ptsd.va.gov/professional/assessment/adult-sr/ies-r.asp"),
    ("Torous, J., et al. (2020). Digital phenotyping and mobile sensing: New developments in psychoinformatics.", "https://awspntest.apa.org/record/2020-08754-000"),
    ("Insel, T. R., et al. (2010). Research Domain Criteria (RDoC): Toward a new classification framework for research on mental disorders.", "https://doi.org/10.1176/appi.ajp.2010.09091379"),
    ("Kazdin, A. E. (2017). Research Design in Clinical Psychology (5th ed.).", "https://assets.cambridge.org/97811089/95214/frontmatter/9781108995214_frontmatter.pdf"),
    ("Linehan, M. (2018). Cognitive-Behavioral Treatment of Borderline Personality Disorder.", "https://www.guilford.com/books/Cognitive-Behavioral-Treatment-of-Borderline-Personality-Disorder/Marsha-Linehan/9780898621839"),
    ("Luxton, D. D. (2020). Artificial Intelligence in Behavioral and Mental Health Care.", "https://www.elsevier.com/books/artificial-intelligence-in-behavioral-and-mental-health-care/luxton/978-0-12-420248-1"),
    ("Ekman, P., et al. (2019). Facial expression and emotion. American Psychologist.", "https://www.paulekman.com/wp-content/uploads/2013/07/Facial-Expression-And-Emotion1.pdf"),
    ("Scherer, K. R. (2018). What are emotions? And how can they be measured?", "https://static1.squarespace.com/static/55917f64e4b0cd3b4705b68c/t/5bc7c2fba4222f0b94cc8550/1539818235703/scherer+%282005%29.pdf"),
]

# API anahtarÄ±nÄ± doÄŸrudan kodun iÃ§ine ekleyin ğŸ‡
api_key = "type_your_api_key_here"

if not api_key or api_key == "fake-key":
    print("API anahtarÄ± yÃ¼klenemedi. LÃ¼tfen geÃ§erli bir anahtar saÄŸlayÄ±n.")
else:
    print("API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi:", api_key)

openai.api_key = api_key

# SabitlerğŸ‡
EMOTIONS = ["mutluluk", "Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±", "nÃ¶tr"]
FORM_WEEKLY = ["PHQ9", "GAD7", "PSS10"]
FORM_MONTHLY = ["PSQI", "IESR"]
BASE_DIR = "data/records"

def random_emotion():
    return random.choice(EMOTIONS)

def create_dirs(pid):
    for sub in [
        "mood_tracking", "journal_entries", "audio_entries", "video_analysis",
        "emotion_consistency", "healthkit", "form_submissions"
    ] + [f"forms/{form}" for form in FORM_WEEKLY + FORM_MONTHLY]:
        os.makedirs(os.path.join(BASE_DIR, pid, sub), exist_ok=True)

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=5, max=20))
def gpt_text(prompt):
    """Send prompt to GPT with retry mechanism and better error handling.
    
    Args:
        prompt (str): The prompt to send to GPT
        
    Returns:
        str: GPT response or error message
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen bir psikiyatrik hasta simÃ¼lasyon motorusun."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.85
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"GPT API HatasÄ±: {str(e)}")
        print(f"DetaylÄ± Hata: {str(e)}")
        return "API baÄŸlantÄ±sÄ±nda sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."

def calculate_functioning_score(steps, sleep_hours, mood_avg, journal_sent, audio_sent, dominant_emotion, form_scores):
    """
    Ã‡oklu parametreye dayalÄ± iÅŸlevsellik skoru (0-100 arasÄ±)
    """
    score = 100
    # Fiziksel aktivite ve uykuğŸ‡
    if steps < 3000:
        score -= 20
    elif steps < 6000:
        score -= 10
    if sleep_hours < 5:
        score -= 15
    elif sleep_hours < 7:
        score -= 5
    # Mood (ortalama 1-5 arasÄ±, 3'Ã¼n altÄ± riskli)ğŸ‡
    if mood_avg < 2:
        score -= 20
    elif mood_avg < 3:
        score -= 10
    # NLP sentiment (negatifse dÃ¼ÅŸÃ¼r)ğŸ‡
    if journal_sent is not None and journal_sent < 0:
        score -= 10
    if audio_sent is not None and audio_sent < 0:
        score -= 10
    # Video dominant duygu
    if dominant_emotion in ["Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±"]:
        score -= 10
    # Psikometrik test ÅŸiddetiğŸ‡
    for form in form_scores.values():
        if form.get("severity") == "yÃ¼ksek":
            score -= 10
        elif form.get("severity") == "orta":
            score -= 5
    # Skoru 0-100 aralÄ±ÄŸÄ±nda sÄ±nÄ±rlağŸ‡
    score = max(0, min(100, score))
    return score

# --- get_latest_danger_grade artÄ±k dosyadan okur, yoksa hesaplar ve kaydederğŸ‡ --------------------------------------------------------
def get_latest_danger_grade(pid):
    grade, danger = load_patient_grade(pid)
    if grade is not None:
        return grade
    try:
        base = os.path.join(BASE_DIR, pid)
        mood_df = pd.read_csv(os.path.join(base, "mood_tracking", sorted(os.listdir(os.path.join(base, "mood_tracking")))[-1]))
        with open(os.path.join(base, "video_analysis", sorted(os.listdir(os.path.join(base, "video_analysis")))[-1]), "r", encoding="utf-8") as f:
            video_json = json.load(f)
        form_scores = {}
        for form in FORM_WEEKLY + FORM_MONTHLY:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_scores[form] = latest_form
        func_path = os.path.join(base, "functioning_score")
        func_file = sorted(os.listdir(func_path))[-1]
        func_score = pd.read_csv(os.path.join(func_path, func_file))["score"].values[0]

        health_path = os.path.join(base, "healthkit")
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        df = pd.concat([pd.read_csv(os.path.join(health_path, f)) for f in files], ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)

        journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))[2]
        journal_emo_counts = pd.Series(journal_emos).value_counts().to_dict()

        grade, danger = calculate_and_assign_grade(
            mood_df, {"journal_emos": journal_emo_counts}, video_json, form_scores, steps, sleep, func_score, pid=pid
        )
        return grade
    except Exception as e:
        print(f"{pid} iÃ§in risk hesaplanamadÄ±: {e}")
        return "?"
#-------------------------------------------------------------------------------
def save_patient_grade(pid, grade, danger_score):
    """HastanÄ±n grade ve danger_score'unu dosyaya kaydeder."""
    grade_path = os.path.join(BASE_DIR, pid, "grade.json")
    with open(grade_path, "w", encoding="utf-8") as f:
        json.dump({"grade": grade, "danger_score": danger_score}, f)

def load_patient_grade(pid):
    """HastanÄ±n grade ve danger_score'unu dosyadan okur (yoksa None dÃ¶ner)."""
    grade_path = os.path.join(BASE_DIR, pid, "grade.json")
    if os.path.exists(grade_path):
        try:
            with open(grade_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("grade"), data.get("danger_score")
        except Exception:
            return None, None
    return None, None

def calculate_and_assign_grade(mood_df, nlp_summary, video_json, form_scores, steps, sleep, func_score, pid=None):
    """Tehlike skorunu ve grade'i hesaplar, isterse kaydeder."""
    danger = round(calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, steps, sleep, func_score) * 20, 2)
    if danger < 20:
        grade = "I"
    elif danger < 40:
        grade = "II"
    elif danger < 60:
        grade = "III"
    elif danger < 80:
        grade = "IV"
    else:
        grade = "V"
    if pid:
        save_patient_grade(pid, grade, danger)
    return grade, danger

#-------------------------------------------------------------------------------

# --- generate_daily: Grade I iÃ§in dÃ¼ÅŸÃ¼k riskli varyantlar ekle ---ğŸ‡
def generate_daily(pid, date, disordered=False, disorder_type=None, forced_grade=None):
    import math
    os.makedirs(os.path.join(BASE_DIR, pid, "mood_tracking"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "journal_entries"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "audio_entries"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "video_analysis"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "emotion_consistency"), exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, pid, "healthkit"), exist_ok=True)

    date_str = date.strftime("%Y%m%d")
    day_index = (date - datetime(2000, 1, 1)).days

    def add_noise(base, min_val, max_val, noise=0.8):
        return round(min(max(random.gauss(base, noise), min_val), max_val), 2)

    def sinusoidal_modulation(day_idx, base, amplitude=0.5, period=30):
        return base + amplitude * math.sin(2 * math.pi * day_idx / period)

    # GeniÅŸletilmiÅŸ kiÅŸilik varyantlarÄ±
    profile_mod = random.choice([
        {"huzur": -0.3, "enerji": -0.4, "depresif": +0.6},
        {"huzur": +0.2, "enerji": +0.5, "anksiyete": -0.3},
        {"depresif": +0.8, "anksiyete": +0.4, "huzur": -0.6},
        {"enerji": +0.3, "Ã¶fke": +0.3},
        {},
    ])

    # Mood temel deÄŸerleri (bozukluk bazlÄ±)ğŸ‡
    mood_bases = {
        "Depresyon": {"huzur": 1.5, "enerji": 1.5, "anksiyete": 3.5, "Ã¶fke": 2.5, "depresif": 4.5},
        "Bipolar": {"huzur": 2, "enerji": 4.5, "anksiyete": 2, "Ã¶fke": 3, "depresif": 2},
        "Psikotik": {"huzur": 1.5, "enerji": 2, "anksiyete": 5, "Ã¶fke": 5, "depresif": 3},
        "Anksiyete": {"huzur": 2.5, "enerji": 2, "anksiyete": 5, "Ã¶fke": 3, "depresif": 3},
        "TSSB": {"huzur": 1.5, "enerji": 2, "anksiyete": 5, "Ã¶fke": 4, "depresif": 4},
        "OKB": {"huzur": 2.5, "enerji": 3, "anksiyete": 4.5, "Ã¶fke": 3, "depresif": 2},
        "Normal": {"huzur": 4, "enerji": 4, "anksiyete": 1.5, "Ã¶fke": 1.5, "depresif": 1.5},
    }

    # Risk profilleri
    risk_profiles = {
        "I":   {"sent": 0.4, "steps": (10000, 13000), "sleep": (7.5, 9)},  # YÃ¼ksek steps ve uyku ile Grade I daha dÃ¼ÅŸÃ¼k riskli
        "II":  {"sent": 0.2, "steps": (6000, 9000),  "sleep": (6.5, 8)},
        "III": {"sent": -0.1, "steps": (4000, 7000), "sleep": (6, 7.5)},
        "IV":  {"sent": -0.4, "steps": (2000, 5000), "sleep": (5, 7)},
        "V":   {"sent": -0.7, "steps": (500, 2500),  "sleep": (3.5, 6)},
    }

    # Mood ve risk Ã¼retimi - hem normal hem disordered iÃ§in ayrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸğŸ‡
    if not disordered:
        label = "Normal"
        # SADECE GRADE I ve II
        normal_grade = forced_grade if forced_grade in ["I", "II"] else random.choices(["I", "II"], weights=[0.6, 0.4])[0]
        if normal_grade == "I":
            # Grade I iÃ§in dÃ¼ÅŸÃ¼k riskli varyant: yÃ¼ksek mood, steps, function
            target_avg = round(random.uniform(4.5, 4.9), 2)
            base_mood = {
                "huzur": 4.7,
                "enerji": 4.6,
                "anksiyete": 1.1,
                "Ã¶fke": 1.1,
                "depresif": 1.1,
            }
            risk_profile = risk_profiles["I"]
        else:
            target_avg = round(random.uniform(3.5, 3.99), 2)
            base_mood = {
                "huzur": 3.8,
                "enerji": 3.7,
                "anksiyete": 1.4,
                "Ã¶fke": 1.3,
                "depresif": 1.3,
            }
            risk_profile = risk_profiles["II"]
        mood = {}
        for k in base_mood:
            sin_mod = sinusoidal_modulation(day_index, base_mood[k], amplitude=0.10 if normal_grade == "I" else 0.15, period=14)
            mood[k] = round(min(max(sin_mod, 1), 5), 2)
        current_avg = sum(mood.values()) / len(mood)
        scale = target_avg / current_avg
        for k in mood:
            mood[k] = round(min(max(mood[k] * scale, 1), 5), 2)
        mood["average"] = round(target_avg + random.uniform(-0.03, 0.03), 2) if normal_grade == "I" else round(target_avg + random.uniform(-0.05, 0.05), 2)
        risk_grade = normal_grade

        # Normal bireyler iÃ§in dominant ve emo ata
        emo = "mutluluk" if normal_grade == "I" else random.choices(["mutluluk", "nÃ¶tr"], weights=[3, 2])[0]
        dominant = emo

        print(f"[NORMAL] Ãœretim ID: {pid} | Target AVG: {target_avg} | GerÃ§ek AVG: {mood['average']} | Risk Grade: {risk_grade}")

    else:
        label = disorder_type if disorder_type else "Normal"
        # SADECE GRADE III, IV, V
        target_grade = forced_grade if forced_grade in ["III", "IV", "V"] else random.choices(["III", "IV", "V"], weights=[0.5, 0.3, 0.2])[0]
        if target_grade == "III":
            target_avg = round(random.uniform(2.0, 2.99), 2)
        elif target_grade == "IV":
            target_avg = round(random.uniform(1.5, 1.99), 2)
        else:
            target_avg = round(random.uniform(1.0, 1.49), 2)
        profile_mod = random.choice([
            {"huzur": -0.3, "enerji": -0.4, "depresif": +0.6},
            {"huzur": +0.2, "enerji": +0.5, "anksiyete": -0.3},
            {"depresif": +0.8, "anksiyete": +0.4, "huzur": -0.6},
            {"enerji": +0.3, "Ã¶fke": +0.3},
            {},
        ])
        base_mood = mood_bases[label]
        mood = {}
        for k in base_mood:
            base_val = base_mood[k] + profile_mod.get(k, 0)
            sin_mod = sinusoidal_modulation(day_index, base_val, amplitude=0.4)
            mood[k] = add_noise(sin_mod, 1, 5)
        current_avg = sum(mood.values()) / len(mood)
        scale = target_avg / current_avg
        for k in mood:
            mood[k] = round(min(max(mood[k] * scale, 1), 5), 2)
        mood["average"] = round(sum(mood.values()) / len(mood), 2)
        risk_grade = target_grade

        emo = random.choices(
            ["mutluluk", "nÃ¶tr", "kaygÄ±", "Ã¶fke", "Ã¼zÃ¼ntÃ¼"],
            weights=[1, 2, 2, 2, 3]
        )[0]
        dominant = emo

        risk_profile = risk_profiles[risk_grade]

    # --- Risk profiline gÃ¶re diÄŸer parametreler ---ğŸ‡
    sent = add_noise(risk_profile["sent"], -1, 1)
    subj = add_noise(0.6 if sent > 0 else 0.8, 0.3, 1.0)
    steps = random.randint(*risk_profile["steps"])
    sleep_hours = round(random.uniform(*risk_profile["sleep"]), 1)

    journal = get_journal(label)
    audio = get_audio(label)
    video_data = get_video_emotion_scores(dominant)

    pd.DataFrame([mood]).to_csv(f"{BASE_DIR}/{pid}/mood_tracking/mood_{date_str}.csv", index=False)
    with open(f"{BASE_DIR}/{pid}/journal_entries/journal_{date_str}.txt", "w", encoding="utf-8") as f:
        f.write(f"Sentiment: {sent}\nSubjectivity: {subj}\nDuygu: {emo}\n\n{journal}")
    with open(f"{BASE_DIR}/{pid}/audio_entries/audio_{date_str}.txt", "w", encoding="utf-8") as f:
        f.write(f"Sentiment: {sent}\nSubjectivity: {subj}\nDuygu: {emo}\n\n{audio}")
    with open(f"{BASE_DIR}/{pid}/video_analysis/video_analysis_{date_str}.json", "w", encoding="utf-8") as f:
        json.dump(video_data, f, indent=2)

    emo_json = {
        "text_emotion": emo,
        "voice_emotion": emo,
        "face_emotion": dominant,
        "uyum_durumu": "DÃ¼ÅŸÃ¼k" if risk_grade in ["IV", "V"] else "YÃ¼ksek",
        "yorum": "YÃ¼ksek riskli semptomatik gÃ¶rÃ¼nÃ¼m.",
        "risk_suicidal": (risk_grade == "V"),
        "delusions": (label == "Psikotik"),
        "insight_level": "low" if risk_grade in ["IV", "V"] else "normal"
    }
    with open(f"{BASE_DIR}/{pid}/emotion_consistency/emotion_consistency_{date_str}.json", "w", encoding="utf-8") as f:
        json.dump(emo_json, f, indent=2)

    pd.DataFrame([{
        "date": date.strftime("%Y-%m-%d"),
        "steps": steps,
        "hours": sleep_hours
    }]).to_csv(f"{BASE_DIR}/{pid}/healthkit/manual_entry_{date_str}.csv", index=False)

    # Form skorlarÄ±
    form_scores_dict = {}
    for form in FORM_WEEKLY + FORM_MONTHLY:
        form_path = f"{BASE_DIR}/{pid}/forms/{form}"
        if os.path.exists(form_path):
            form_files = sorted([f for f in os.listdir(form_path) if f.endswith(".json")])
            if form_files:
                with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                    latest_form = json.load(f)
                    form_scores_dict[form] = {
                        "score": latest_form["score"],
                        "severity": latest_form["severity"]
                    }

    functioning_score = calculate_functioning_score(
        steps=steps,
        sleep_hours=sleep_hours,
        mood_avg=mood["average"],
        journal_sent=sent,
        audio_sent=sent,
        dominant_emotion=dominant,
        form_scores=form_scores_dict
    )

    os.makedirs(f"{BASE_DIR}/{pid}/functioning_score", exist_ok=True)
    pd.DataFrame([{"date": date.strftime("%Y-%m-%d"), "score": functioning_score}]).to_csv(
        f"{BASE_DIR}/{pid}/functioning_score/functioning_{date_str}.csv", index=False)

    # --- Grade ve danger_score'u kaydet (her gÃ¼n sonu gÃ¼ncel) ---
    # Mood_df, nlp_summary, video_json, form_scores_dict, steps, sleep_hours, functioning_scoreğŸ‡ğŸ‡ğŸ‡
    mood_df = pd.DataFrame([mood])
    nlp_summary = {"journal_emos": {emo: 1}}
    grade, danger = calculate_and_assign_grade(
        mood_df, nlp_summary, video_data, form_scores_dict, steps, sleep_hours, functioning_score, pid=pid
    )

    print(f"[ğŸ§ª TEST LOG] {pid} | forced_grade: {forced_grade} | risk_grade: {risk_grade} | disordered: {disordered} | grade: {grade} | danger: {danger}")
#-------------------------------------------------------------------------------

def generate_forms(pid, date, disordered=False, disorder_type=None):
    
    date_str = date.strftime("%Y%m%d")
    day_index = (date.date() - datetime(2000, 1, 1).date()).days

    # Her hastaya Ã¶zgÃ¼ kiÅŸisel varyasyon (sabitlemek iÃ§in random.seed kullanÄ±labilir)
    form_traits = {
        "PHQ9": random.uniform(0.8, 1.2),
        "GAD7": random.uniform(0.7, 1.3),
        "PSS10": random.uniform(0.7, 1.2),
        "PSQI": random.uniform(0.8, 1.4),
        "IESR": random.uniform(0.7, 1.5),
    }

    # HastalÄ±k tÃ¼rÃ¼ne gÃ¶re form odaklarÄ±
    base_scores = {
        "PHQ9": 4,
        "GAD7": 3,
        "PSS10": 5,
        "PSQI": 4,
        "IESR": 4,
    }

    if disordered and disorder_type:
        if disorder_type == "Depresyon":
            base_scores["PHQ9"] = 15
            base_scores["PSS10"] = 12
        elif disorder_type == "Anksiyete":
            base_scores["GAD7"] = 14
            base_scores["PSQI"] = 9
        elif disorder_type == "TSSB":
            base_scores["IESR"] = 20
            base_scores["PSQI"] = 10
        elif disorder_type == "Psikotik":
            base_scores["PHQ9"] = 18
            base_scores["GAD7"] = 12
        elif disorder_type == "OKB":
            base_scores["GAD7"] = 14
            base_scores["IESR"] = 18
        elif disorder_type == "Bipolar":
            base_scores["PHQ9"] = 12
            base_scores["PSS10"] = 11

    # Mood etkisi (o gÃ¼nkÃ¼ ortalama mood deÄŸeri)
    mood_path = f"{BASE_DIR}/{pid}/mood_tracking/mood_{date_str}.csv"
    mood_avg = 3
    if os.path.exists(mood_path):
        try:
            mood_df = pd.read_csv(mood_path)
            mood_avg = mood_df["average"].values[0]
        except:
            pass

    # Mood kÃ¶tÃ¼ ise form skorlarÄ±nÄ± %10-30 artÄ±r
    mood_modifier = 1.0
    if mood_avg < 2.5:
        mood_modifier += 0.2
    elif mood_avg < 2.0:
        mood_modifier += 0.4

    # Åiddet belirleme fonksiyonu
    def determine_severity(score, thresholds):
        if score < thresholds[0]:
            return "normal"
        elif score < thresholds[1]:
            return "hafif"
        elif score < thresholds[2]:
            return "orta"
        else:
            return "yÃ¼ksek"

    form_definitions = {
        "PHQ9": [5, 10, 15],
        "GAD7": [5, 10, 15],
        "PSS10": [10, 20, 30],
        "PSQI": [5, 10, 15],
        "IESR": [12, 24, 36]
    }

    # HaftalÄ±k formlar â†’ Pazartesi
    if date.weekday() == 0:
        for form in FORM_WEEKLY:
            base = base_scores[form]
            trait = form_traits[form]
            sin = 1 + 0.2 * math.sin(2 * math.pi * day_index / 14)
            noise = random.gauss(0, 1.5)
            score = round((base * trait * mood_modifier * sin) + noise)
            score = int(max(0, min(score, 27)))  # PHQ9 & GAD7 max 27
            severity = determine_severity(score, form_definitions[form])
            out = {"date": date.strftime("%Y-%m-%d"), "score": score, "severity": severity}
            path = f"{BASE_DIR}/{pid}/forms/{form}/form_{date_str}.json"
            with open(path, "w", encoding="utf-8") as f:
                json.dump(out, f, indent=2)

    # AylÄ±k formlar â†’ AyÄ±n ilk gÃ¼nÃ¼ğŸ‡ğŸ‡
    if date.day == 1:
        for form in FORM_MONTHLY:
            base = base_scores[form]
            trait = form_traits[form]
            sin = 1 + 0.15 * math.sin(2 * math.pi * day_index / 30)
            noise = random.gauss(0, 2.0)
            score = round((base * trait * mood_modifier * sin) + noise)
            score = int(max(0, min(score, 42)))  # PSQI & IESR max
            severity = determine_severity(score, form_definitions[form])
            out = {"date": date.strftime("%Y-%m-%d"), "score": score, "severity": severity}
            path = f"{BASE_DIR}/{pid}/forms/{form}/form_{date_str}.json"
            with open(path, "w", encoding="utf-8") as f:
                json.dump(out, f, indent=2)

def train_and_save_model():
    patients = sorted(os.listdir(BASE_DIR))
    X, y = [], []

    for pid in patients:
        # Her hasta iÃ§in Ã¶z nitelikleri ve sÄ±nÄ±fÄ± al
        try:
            base = os.path.join(BASE_DIR, pid)
            # ... aynÄ± X, y oluÅŸturma kodlarÄ± burada ...
        except Exception as e:
            print(f"{pid} atlanÄ±yor: {e}")
    
    if not X:
        print("Yeterli veri yok.")
        return

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)

    # Modeli kaydet
    with open("random_forest_risk_model.pkl", "wb") as f:
        pickle.dump(model, f)

    print("âœ… Random Forest modeli baÅŸarÄ±yla kaydedildi.")

def extract_nlp_stats(filepath):
    sent, subj, emo = None, None, None
    try:
        with open(filepath, encoding='utf-8') as f:
            text = f.read().lower()

            # TÃ¼rkÃ§e karÅŸÄ±lÄ±klarÄ± da yakalayacak ÅŸekilde dÃ¼zenlendiğŸ‡ğŸ‡
            sent_match = re.search(r'(sentiment|duygu skoru)[:ï¼š]?\s*([-+]?\d*\.\d+|\d+)', text)
            subj_match = re.search(r'(subjectivity|Ã¶znelik)[:ï¼š]?\s*([-+]?\d*\.\d+|\d+)', text)
            emo_match = re.search(r'duygu[:ï¼š]?\s*(mutluluk|Ã¼zÃ¼ntÃ¼|Ã¶fke|kaygÄ±|nÃ¶tr)', text)

            if sent_match:
                sent = float(sent_match.group(2))
            if subj_match:
                subj = float(subj_match.group(2))
            if emo_match:
                emo = emo_match.group(1).strip()

    except Exception as e:
        print(f"Error reading file {filepath}: {e}")
    return sent, subj, emo

def collect_nlp_stats(folder):
    sentiments, subjectivities, emotions = [], [], []
    if not os.path.exists(folder):
        return sentiments, subjectivities, emotions

    files = sorted([f for f in os.listdir(folder) if f.endswith(".txt")])
    for filename in files:
        filepath = os.path.join(folder, filename)
        s, j, e = extract_nlp_stats(filepath)
        if s is not None:
            sentiments.append(s)
        if j is not None:
            subjectivities.append(j)
        if e is not None:
            emotions.append(e)
    return sentiments, subjectivities, emotions

def read_last_lines(folder, lines=10, base_dir=None):
    """Read the last N lines from the most recent file in the specified folder.
    
    Args:
        folder (str): Folder path relative to base directory
        lines (int): Number of lines to read from end
        base_dir (str): Base directory path
        
    Returns:
        str: Last N lines joined with newlines, or empty string if no files
    """
    try:
        path = os.path.join(base_dir if base_dir else BASE_DIR, folder)
        if not os.path.exists(path):
            return ""
            
        files = sorted(os.listdir(path))
        if not files:
            return ""
            
        latest_file = os.path.join(path, files[-1])
        with open(latest_file, "r", encoding="utf-8") as f:
            # Read all lines and get last N
            all_lines = f.read().splitlines()
            return "\n".join(all_lines[-lines:])
            
    except Exception as e:
        print(f"Error reading from {folder}: {str(e)}")
        return ""

def format_clinical_summary(text):
    """OpenAI'dan gelen ham metni dÃ¼zenli HTML formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    if not text:
        return ""
        
    # BaÅŸlÄ±klarÄ± iÅŸaretle (Ã¶nce 4. seviye, sonra 3. seviye)ğŸ‡ğŸ‡
    text = re.sub(r'^\s*####\s+([0-9]+\.[0-9]+.*?)\s*$', r'<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">\1</h4>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*###\s+([0-9]+\. .*?)\s*$', r'<h3 style="margin-top: 16px; margin-bottom: 8px;">\1</h3>', text, flags=re.MULTILINE)
    
    # ParagraflarÄ± HTML paragraf taglarÄ±na Ã§evir
    paragraphs = []
    current_content = ""
    for line in text.split('\n'):
        if line.strip().startswith('<h'):
            if current_content.strip():
                paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
                current_content = ""
            paragraphs.append(line.strip())
        elif line.strip():
            if current_content:
                current_content += " " + line.strip()
            else:
                current_content = line.strip()
        else:
            if current_content.strip():
                paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
                current_content = ""
    if current_content.strip():
        paragraphs.append(f'<p style="margin-top: 0; margin-bottom: 12px;">{current_content.strip()}</p>')
    # 11. LiteratÃ¼r ReferanslarÄ± baÅŸlÄ±ÄŸÄ±nÄ± ve iÃ§eriÄŸini tamamen kaldÄ±r
    new_paragraphs = []
    skip = False
    for p in paragraphs:
        if re.search(r'<h3.*?>11\. LiteratÃ¼r ReferanslarÄ±<\/h3>', p):
            skip = True
            continue
        if skip:
            # Bir sonraki paragraf da referans iÃ§eriÄŸi olabilir, onu da atla
            skip = False
            continue
        new_paragraphs.append(p)
    return "".join(new_paragraphs)
    

def calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score=50):
    """Calculate patient danger level based on multiple factors.
    
    Args:
        mood_df (pandas.DataFrame): Mood tracking data
        nlp_summary (dict): NLP analysis summary
        video_json (dict): Video analysis data
        form_scores (dict): Psychometric test scores
        avg_steps (int/float/str): Average daily steps
        avg_sleep (int/float/str): Average daily sleep hours
        functioning_score (int): Patient functioning score (0-100)
        
    Returns:
        int: Danger level score (1-5)
    """
    weights = {
        "mood": 0.20,
        "nlp": 0.20,
        "video": 0.15,
        "forms": 0.15,
        "health": 0.10,
        "functioning": 0.20  # Ä°ÅŸlevsellik skoru iÃ§in aÄŸÄ±rlÄ±k eklendi
    }

    # Default values for error casesğŸ‡ğŸ‡
    mood_score = 3
    nlp_score = 3
    video_score = 3
    form_scores_avg = 3
    health_score = 3
    func_score = 3  # Default functioning score deÄŸeri

    # Calculate mood scoreğŸ‡
    try:
        mood_avg = mood_df.iloc[0]["average"]
        mood_score = 5 - (mood_avg - 1)
    except Exception as e:
        print(f"Error calculating mood score: {e}")

    # Calculate NLP scoreğŸ‡
    try:
        nlp_emos = nlp_summary["journal_emos"]
        negative_emotions = sum(nlp_emos.get(e, 0) for e in ["Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±"])
        total_emotions = sum(nlp_emos.values())
        nlp_score = (negative_emotions / total_emotions) * 5 if total_emotions > 0 else 1
    except Exception as e:
        print(f"Error calculating NLP score: {e}")

    # Calculate video scoreğŸ‡
    try:
        dominant_emotion = video_json["dominant_emotion"]
        video_score = 5 if dominant_emotion in ["Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±"] else 1
    except Exception as e:
        print(f"Error calculating video score: {e}")

    # Calculate form scoreğŸ‡
    try:
        form_severity_map = {"hafif": 1, "orta": 3, "yÃ¼ksek": 5}
        if form_scores and len(form_scores) > 0:
            form_scores_avg = sum(form_severity_map.get(form["severity"], 3) for form in form_scores.values()) / len(form_scores)
        else:
            form_scores_avg = 3
    except Exception as e:
        print(f"Error calculating form score: {e}")

    # Calculate health scoreğŸ‡
    try:
        health_score = 5
        if isinstance(avg_steps, (int, float)) and isinstance(avg_sleep, (int, float)):
            if avg_steps > 8000 and avg_sleep >= 7:
                health_score = 1
            elif avg_steps > 6000 and avg_sleep >= 6.5:
                health_score = 2
            elif avg_steps > 5000 and avg_sleep >= 6:
                health_score = 3
            else:
                health_score = 4
    except Exception as e:
        print(f"Error calculating health score: {e}")

    # Calculate functioning score (ters orantÄ±lÄ± - dÃ¼ÅŸÃ¼k iÅŸlevsellik = yÃ¼ksek risk)ğŸ‡
    try:
        func_score = 5 - (functioning_score / 20)  # 0-100 arasÄ± deÄŸeri 0-5 arasÄ± deÄŸere dÃ¶nÃ¼ÅŸtÃ¼r
    except Exception as e:
        print(f"Error calculating functioning score: {e}")

    # Calculate overall danger level
    danger_level = (
        weights["mood"] * mood_score +
        weights["nlp"] * nlp_score +
        weights["video"] * video_score +
        weights["forms"] * form_scores_avg +
        weights["health"] * health_score +
        weights["functioning"] * func_score  # Ä°ÅŸlevsellik skoru eklendi
    )
    return round(danger_level)

def train_random_forest_model(pid):
    import plotly.io as pio
    pio.kaleido.scope.default_format = "png"  # plotly grafiklerinin dÃ¼zgÃ¼n kaydedilmesi iÃ§inğŸ‡

    # SHAP dosya yollarÄ±nÄ± hazÄ±rla
    BASE_PATH = Path(BASE_DIR).absolute()  # ğŸ”’ Mutlak yolğŸ‡

    shap_folder = BASE_PATH / pid / "gpt_analysis"
    shap_folder.mkdir(parents=True, exist_ok=True)

    date_str = datetime.now().strftime("%Y%m%d")
    shap_image_path = shap_folder / f"shap_waterfall_{date_str}.png"
    shap_bar_path   = shap_folder / f"shap_bar_{date_str}.png"
    shap_txt_path   = shap_folder / f"shap_ai_comment_{date_str}.txt"

    os.makedirs(shap_folder, exist_ok=True)

    model_path = "random_forest_risk_model.pkl"
    if not os.path.exists(model_path):
        st.warning("âš ï¸ Model henÃ¼z eÄŸitilmemiÅŸ. LÃ¼tfen modeli Ã¶nce eÄŸitin.")
        return

    with open(model_path, "rb") as f:
        model = pickle.load(f)

    if all(os.path.exists(p) for p in [shap_image_path, shap_bar_path, shap_txt_path]):
        st.subheader("ğŸ“Š Ã–nceki SHAP SonuÃ§larÄ±")
        st.image(shap_image_path, caption="ğŸ” KayÄ±tlÄ± SHAP Waterfall GrafiÄŸi", use_column_width=True)
        st.image(shap_bar_path, caption="ğŸ” KayÄ±tlÄ± SHAP Bar GrafiÄŸi", use_column_width=True)
        st.markdown("### ğŸ¤– KayÄ±tlÄ± SHAP AI Yorum")
        with open(shap_txt_path, "r", encoding="utf-8") as f:
            st.markdown(f.read())
        return

    base = os.path.join(BASE_DIR, pid)

    try:
        mood_df = pd.read_csv(os.path.join(base, "mood_tracking", sorted(os.listdir(os.path.join(base, "mood_tracking")))[-1]))
        mood_avg = mood_df["average"].values[0]
    except:
        mood_avg = 3.0

    try:
        func_df = pd.read_csv(os.path.join(base, "functioning_score", sorted(os.listdir(os.path.join(base, "functioning_score")))[-1]))
        func_score = func_df["score"].values[0]
    except:
        func_score = 50.0

    try:
        health_path = os.path.join(base, "healthkit")
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
        df = pd.concat(df_list, ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)
    except:
        steps, sleep = 5000, 6.0

    form_values = {"PHQ9": 0, "GAD7": 0, "PSS10": 0, "PSQI": 0, "IESR": 0}
    for form in FORM_WEEKLY + FORM_MONTHLY:
        try:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_values[form] = latest_form["score"]
        except:
            pass

    features = [
        mood_avg, steps, sleep,
        form_values["PHQ9"], form_values["GAD7"],
        form_values["PSS10"], form_values["PSQI"],
        form_values["IESR"], func_score
    ]
    feature_names = ["mood_avg", "steps", "sleep", "PHQ9", "GAD7", "PSS10", "PSQI", "IESR", "functioning"]
    features_df = pd.DataFrame([features], columns=feature_names)

    st.subheader("ğŸ“‰ SHAP Risk AÃ§Ä±klamasÄ±")

    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(features_df)
        proba = model.predict_proba(features_df)[0]
        predicted_class_index = int(np.argmax(proba))

        shap_val = shap_values[predicted_class_index][0] if isinstance(shap_values, list) else shap_values[0]
        base_val = explainer.expected_value[predicted_class_index] if isinstance(shap_values, list) else explainer.expected_value

        if isinstance(shap_val, np.ndarray) and shap_val.ndim == 1:
            shap_val = shap_val[np.newaxis, :]
            base_val = np.array([base_val]) if np.isscalar(base_val) else np.array(base_val)[np.newaxis]

        shap_exp = shap.Explanation(
            values=shap_val,
            base_values=base_val,
            data=features_df.values,
            feature_names=features_df.columns.tolist()
        )

        # ğŸ”½ SHAP Waterfall Kaydet ve GÃ¶sterğŸ‡
        plt.figure()
        shap.plots.waterfall(shap_exp[0], max_display=9, show=False)
        plt.tight_layout()
        plt.savefig(shap_image_path, bbox_inches="tight", dpi=300)
        st.image(shap_image_path, caption="SHAP Waterfall GrafiÄŸi")
        plt.close()

        # ğŸ”½ SHAP Bar Kaydet ve GÃ¶ster (plotly)ğŸ‡
        df_shap = pd.DataFrame({
            "feature": features_df.columns,
            "shap_value": shap_exp[0].values
        }).sort_values("shap_value", ascending=True)

        fig_bar = px.bar(df_shap,
                         x="shap_value", y="feature",
                         orientation="h",
                         title="SHAP DeÄŸerleri")
        fig_bar.write_image(shap_bar_path, scale=2)
        st.image(shap_bar_path, caption="SHAP Bar GrafiÄŸi")

        # Ã–zellik Listesi
        st.markdown("**ğŸ”‘ Ã–zellikler:** " + "  |  ".join(features_df.columns))

        # ğŸ¤– SHAP AI YorumğŸ‡ğŸ‡ğŸ‡
        st.markdown("### ğŸ¤– SHAP AI Yorum")
        ai_prompt = (
            "Sen klinik psikiyatri alanÄ±nda uzman, akademik yayÄ±nlar yapan bir profesÃ¶rsÃ¼n. "
            "SHAP (SHapley Additive exPlanations) analizine dayanarak, bir makine Ã¶ÄŸrenimi modeli tarafÄ±ndan yapÄ±lan risk tahminlerinde "
            "aÅŸaÄŸÄ±daki 9 psikiyatrik ve davranÄ±ÅŸsal Ã¶zelliÄŸin etkisini yorumlaman bekleniyor.\n\n"
            "ğŸ“Š Modelde yer alan deÄŸiÅŸkenler ve grafiklerdeki gÃ¶sterimleri:\n" +
            ", ".join([f"{feat} ({feat})" for feat in features_df.columns]) +
            "\n\n"
            f"ğŸ“ˆ SHAP DeÄŸerleri:\n{json.dumps(dict(zip(features_df.columns, shap_exp[0].values)), ensure_ascii=False, indent=2)}\n\n"
            "Her bir Ã¶zelliÄŸin SHAP deÄŸerinin pozitif veya negatif olmasÄ± durumunun model tahmini aÃ§Ä±sÄ±ndan ne anlama geldiÄŸini detaylandÄ±r. "
            "AÃ§Ä±klamalarÄ±nÄ± bilimsel literatÃ¼re ve klinik deneyime dayandÄ±r. SHAP deÄŸerlerinin yÃ¼ksekliÄŸi veya dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼ model tahmininde "
            "hangi deÄŸiÅŸkenlerin belirleyici olduÄŸunu aÃ§Ä±kla.\n\n"
            "Her Ã¶zellik iÃ§in aÅŸaÄŸÄ±daki gibi yorum yap:\n"
            "- Ã–zellik adÄ±\n"
            "- SHAP deÄŸeri\n"
            "- Klinik etkisi (Ã¶rnek: depresyon, anksiyete, iÅŸlevsellik baÄŸlamÄ±nda)\n"
            "- Pozitif/negatif katkÄ± durumu ve anlamÄ±\n"
            "- Gerekirse klinik Ã¶rnek\n\n"
            "YanÄ±tlarÄ±nÄ± 9 Ã¶zellik iÃ§in sÄ±ralÄ± ve madde madde ver. Psikiyatristlerin anlayabileceÄŸi teknik, ancak sade ve akademik bir dil kullan."
        )
        yorum = stream_chat_completion(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen klinik psikiyatri uzmanÄ±sÄ±nâ€¦"},
                {"role": "user", "content": ai_prompt}
            ],
            temperature=0.5,
            max_tokens=2048
        )
        st.markdown(yorum)
        with open(shap_txt_path, "w", encoding="utf-8") as f:
            f.write(yorum)

        # Grade tahmini
        st.markdown("### ğŸ” Random Forest Tahmini")
        st.markdown(f"**Grade {model.predict(features_df)[0]}**")

    except Exception as e:
        st.error(f"SHAP aÃ§Ä±klamasÄ± oluÅŸturulurken hata oluÅŸtu: {str(e)}")

    #*********************************************************************  

def show_all_heatmaps(pid, category=None):
    base = os.path.join(BASE_DIR, pid)
    
    def plot_heatmap(df, title):
        if df is None or df.empty:
            st.info(f"{title} iÃ§in veri yok.")
            return
        df_m = df.melt(id_vars="date", var_name="Kategori", value_name="DeÄŸer")
        fig = px.density_heatmap(df_m, x="date", y="Kategori", z="DeÄŸer",
                                 color_continuous_scale="RdBu_r", title=title)
        fig.update_layout(height=450, xaxis_title="Tarih", yaxis_title="Kategori")
        st.plotly_chart(fig, use_container_width=True)


#********************************************************************************************

    def load_time_series_csv(folder, col="score"):
        p = os.path.join(base, folder)
        if not os.path.exists(p): return None
        files = sorted(glob.glob(os.path.join(p, "*.csv")))
        if not files: return None
        df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
        df["date"] = pd.to_datetime(df["date"])
        return df[["date", col]] if col in df.columns else None

    def load_json_form(form):
        p = os.path.join(base, f"forms/{form}")
        if not os.path.exists(p): return None
        files = sorted(glob.glob(os.path.join(p, "*.json")))
        if not files: return None
        data = [json.load(open(f, encoding="utf-8")) for f in files]
        df = pd.DataFrame(data)
        df["date"] = pd.to_datetime(df["date"])
        return df[["date", "score"]].sort_values("date")

    def add_nlp_heatmaps(folder, label):
        from collections import defaultdict

        def extract_nlp_stats(filepath):
            with open(filepath, "r", encoding="utf-8") as f:
                lines = f.readlines()
                sent = subj = None
                emotion = None
                for l in lines:
                    if "Sentiment:" in l:
                        sent = float(l.split(":")[-1].strip())
                    elif "Subjectivity:" in l:
                        subj = float(l.split(":")[-1].strip())
                    elif "Duygu:" in l:
                        emotion = l.split(":")[-1].strip()
                return sent, subj, emotion

        sentiment_data, subjectivity_data = [], []
        emotion_data = defaultdict(list)

        files = sorted([f for f in os.listdir(folder) if f.endswith(".txt")])
        for file in files:
            date_str = file.split("_")[-1].split(".")[0]
            date = datetime.strptime(date_str, "%Y%m%d").date()
            sent, subj, emo = extract_nlp_stats(os.path.join(folder, file))
            if sent is not None:
                sentiment_data.append({"date": date, "Sentiment": sent})
            if subj is not None:
                subjectivity_data.append({"date": date, "Subjectivity": subj})
            if emo:
                emotion_data[emo].append(date)

        if sentiment_data:
            df_sent = pd.DataFrame(sentiment_data)
            plot_heatmap(df_sent, f"ğŸ“˜ Sentiment Skoru ({label})")

        if subjectivity_data:
            df_subj = pd.DataFrame(subjectivity_data)
            plot_heatmap(df_subj, f"ğŸ“— Subjectivity Skoru ({label})")

        if emotion_data:
            emo_dates = []
            for emo, dates in emotion_data.items():
                for d in dates:
                    emo_dates.append({"date": d, "Duygu": emo})
            df_emo = pd.DataFrame(emo_dates)
            df_emo["count"] = 1
            df_pivot = df_emo.groupby(["date", "Duygu"]).count().reset_index()
            df_pivot = df_pivot.rename(columns={"count": "DeÄŸer"})
            fig = px.density_heatmap(df_pivot, x="date", y="Duygu", z="DeÄŸer",
                                      color_continuous_scale="Reds",
                                      title=f"ğŸ“™ Duygusal YoÄŸunluk ({label})")
            st.plotly_chart(fig, use_container_width=True)

    # 1) Mood TakibiğŸ‡
    if category in (None, "Mood") or category == "Mood":
        mood_path = os.path.join(base, "mood_tracking")
        mood_files = sorted(glob.glob(os.path.join(mood_path, "*.csv")))
        mood_data = []
        for f in mood_files:
            d = datetime.strptime(f.split("_")[-1].split(".")[0], "%Y%m%d")
            df = pd.read_csv(f)
            df["date"] = d
            mood_data.append(df)
        if mood_data:
            df_mood = pd.concat(mood_data, ignore_index=True)
            df_mood = df_mood.drop(columns=["uid", "disorder"], errors="ignore")
            plot_heatmap(df_mood, "ğŸ§  Mood Takibi (Duygusal DeÄŸiÅŸim)")

    # 2) Ä°ÅŸlevsellikğŸ‡
    if category in (None, "Functioning") or category == "Functioning":
        df_func = load_time_series_csv("functioning_score")
        if df_func is not None:
            df_func = df_func.rename(columns={"score": "Ä°ÅŸlevsellik"})
            plot_heatmap(df_func, "âš–ï¸ Ä°ÅŸlevsellik Skoru")

    # 3) Fiziksel Aktivite ve UykuğŸ‡
    if category in (None, "Health") or category == "Health":
        df_health = load_time_series_csv("healthkit", col="steps")
        if df_health is not None:
            plot_heatmap(df_health.rename(columns={"steps": "AdÄ±m"}), "ğŸƒ AdÄ±m SayÄ±sÄ±")
        df_sleep = load_time_series_csv("healthkit", col="hours")
        if df_sleep is not None:
            plot_heatmap(df_sleep.rename(columns={"hours": "Uyku"}), "ğŸ›Œ Uyku SÃ¼resi")

    # 4) Test SkorlarÄ±ğŸ‡
    if category in (None, "Forms") or category == "Forms":
        for form in FORM_WEEKLY + FORM_MONTHLY:
            df_form = load_json_form(form)
            if df_form is not None:
                plot_heatmap(df_form.rename(columns={"score": form}), f"ğŸ“ {form} Skoru")

    # 5) Journal NLPğŸ‡
    if category in (None, "Journal") or category == "Journal":
        add_nlp_heatmaps(os.path.join(base, "journal_entries"), "Journal")

    # 6) Audio NLPğŸ‡
    if category in (None, "Audio") or category == "Audio":
        add_nlp_heatmaps(os.path.join(base, "audio_entries"), "Audio")

    # 7) Video Analysis - Bu kodu show_all_heatmaps fonksiyonuna ekleyin (Audio kategorisinden sonra)ğŸ‡
    if category in (None, "Video") or category == "Video":
        video_path = os.path.join(base, "video_analysis")
        if os.path.exists(video_path):
            video_files = sorted(glob.glob(os.path.join(video_path, "*.json")))
            if video_files:
                data = []
                dates = []
                for f in video_files:
                    date_str = f.split("_")[-1].split(".")[0]
                    date = datetime.strptime(date_str, "%Y%m%d").date()
                    dates.append(date)
                    with open(f, "r", encoding="utf-8") as file:
                        v_data = json.load(file)
                        for emotion, score in v_data["emotion_scores"].items():
                            data.append({"date": date, "Duygu": emotion, "DeÄŸer": score})
                
                if data:
                    df_video = pd.DataFrame(data)
                    # Duygu deÄŸerlerini zaman serisi boyunca gÃ¶rselleÅŸtirğŸ‡
                    fig = px.density_heatmap(df_video, x="date", y="Duygu", z="DeÄŸer",
                                        color_continuous_scale="Viridis", 
                                        title="ğŸ“¹ Video Duygu Analizi Zaman Serisi")
                    fig.update_layout(height=450, xaxis_title="Tarih", yaxis_title="Duygu")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ğŸ“­ Video analiz verilerinde duygu skoru bulunamadÄ±.")
            else:
                st.info("ğŸ“­ Video analiz dosyasÄ± henÃ¼z mevcut deÄŸil.")
        else:
            st.info("ğŸ“ Video analiz klasÃ¶rÃ¼ henÃ¼z oluÅŸturulmamÄ±ÅŸ.")
  
  
# BasitleÅŸtirilmiÅŸ tamamlayÄ±cÄ± fonksiyonğŸ‡
def stream_chat_completion(**kwargs):
    kwargs["stream"] = False
    response = openai.ChatCompletion.create(**kwargs)
    return response["choices"][0]["message"]["content"]


# RANDOM FOREST SHAP AÃ‡IKLAMASI VE GRAFÄ°KLERğŸ‡
def explain_patient_with_rf_and_shap(pid):
    # Dosya yollarÄ±
    BASE_PATH = Path(BASE_DIR).absolute()
    shap_folder = BASE_PATH / pid / "gpt_analysis"
    shap_folder.mkdir(parents=True, exist_ok=True)

    date_str = datetime.now().strftime("%Y%m%d")
    shap_image_path = shap_folder / f"shap_waterfall_{date_str}.png"
    shap_bar_path = shap_folder / f"shap_bar_{date_str}.png"
    shap_txt_path = shap_folder / f"shap_ai_comment_{date_str}.txt"

    # Modeli yÃ¼kle
    try:
        with open("random_forest_risk_model.pkl", "rb") as f:
            model = pickle.load(f)
    except Exception as e:
        st.error(f"Model yÃ¼klenemedi: {e}")
        return

    # Verileri oku
    try:
        mood_df = pd.read_csv(BASE_PATH / pid / "mood_tracking" / sorted(os.listdir(BASE_PATH / pid / "mood_tracking"))[-1])
        mood_avg = mood_df["average"].values[0]
    except:
        mood_avg = 3.0

    try:
        func_df = pd.read_csv(BASE_PATH / pid / "functioning_score" / sorted(os.listdir(BASE_PATH / pid / "functioning_score"))[-1])
        func_score = func_df["score"].values[0]
    except:
        func_score = 50.0

    try:
        health_path = BASE_PATH / pid / "healthkit"
        files = sorted(f for f in os.listdir(health_path) if f.endswith(".csv"))
        df_list = [pd.read_csv(health_path / f) for f in files]
        df = pd.concat(df_list, ignore_index=True)
        steps = int(df["steps"].mean())
        sleep = round(df["hours"].mean(), 2)
    except:
        steps, sleep = 5000, 6.0

    form_values = dict.fromkeys(FORM_WEEKLY + FORM_MONTHLY, 0)
    for form in form_values:
        try:
            form_path = BASE_PATH / pid / "forms" / form
            latest = sorted(os.listdir(form_path))[-1]
            with open(form_path / latest, encoding="utf-8") as f:
                form_values[form] = json.load(f)["score"]
        except:
            pass

    features = [mood_avg, steps, sleep] + [form_values[f] for f in FORM_WEEKLY+FORM_MONTHLY] + [func_score]
    cols = ["mood_avg", "steps", "sleep"] + FORM_WEEKLY + FORM_MONTHLY + ["functioning"]
    features_df = pd.DataFrame([features], columns=cols)

    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(features_df)
        proba = model.predict_proba(features_df)[0]
        idx = int(np.argmax(proba))

        val, base = (shap_values[idx][0], explainer.expected_value[idx]) if isinstance(shap_values, list) else (shap_values[0], explainer.expected_value)

        if val.ndim == 1:
            val = val[np.newaxis, :]
            base = np.array([base])

        exp = shap.Explanation(
            values=val,
            base_values=base,
            data=features_df.values,
            feature_names=features_df.columns.tolist()
        )
        to_plot = exp[0]

        st.subheader("ğŸ§ SHAP AÃ§Ä±klamasÄ± (RF Modeli)")

        # Waterfall
        plt.figure()
        shap.plots.waterfall(to_plot, show=False)
        plt.tight_layout()
        plt.savefig(str(shap_image_path), bbox_inches="tight", dpi=300)
        st.image(str(shap_image_path), caption="SHAP Waterfall")
        plt.close()

        # Bar
        plt.figure()
        shap.plots.bar(to_plot, show=False)
        plt.tight_layout()
        plt.savefig(str(shap_bar_path), bbox_inches="tight", dpi=300)
        st.image(str(shap_bar_path), caption="SHAP Bar")
        plt.close()

        features_list = features_df.columns.tolist()
        features_str = "  |  ".join([f"{feat} ({feat})" for feat in features_list])
        st.markdown(f"**ğŸ”‘ Ã–zellikler:** {features_str}")

        shap_dict = dict(zip(features_df.columns, to_plot.values))
        ai_prompt = (
            "Sen klinik psikiyatri alanÄ±nda uzman, akademik yayÄ±nlar yapan bir profesÃ¶rsÃ¼n. "
            "SHAP (SHapley Additive exPlanations) analizine dayanarak, bir makine Ã¶ÄŸrenimi modeli tarafÄ±ndan yapÄ±lan risk tahminlerinde "
            "aÅŸaÄŸÄ±daki 9 psikiyatrik ve davranÄ±ÅŸsal Ã¶zelliÄŸin etkisini yorumlaman bekleniyor.\n\n"
            "ğŸ“Š Modelde yer alan deÄŸiÅŸkenler ve grafiklerdeki gÃ¶sterimleri:\n" +
            ", ".join([f"{feat} ({feat})" for feat in features_df.columns]) +
            "\n\n"
            f"ğŸ“ˆ SHAP DeÄŸerleri:\n{json.dumps(shap_dict, ensure_ascii=False, indent=2)}\n\n"
            "Her bir Ã¶zelliÄŸin SHAP deÄŸerinin pozitif veya negatif olmasÄ± durumunun model tahmini aÃ§Ä±sÄ±ndan ne anlama geldiÄŸini detaylandÄ±r. "
            "AÃ§Ä±klamalarÄ±nÄ± bilimsel literatÃ¼re ve klinik deneyime dayandÄ±r. SHAP deÄŸerlerinin yÃ¼ksekliÄŸi veya dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼ model tahmininde "
            "hangi deÄŸiÅŸkenlerin belirleyici olduÄŸunu aÃ§Ä±kla.\n\n"
            "Her Ã¶zellik iÃ§in aÅŸaÄŸÄ±daki gibi yorum yap:\n"
            "- Ã–zellik adÄ±\n"
            "- SHAP deÄŸeri\n"
            "- Klinik etkisi (" "Ã¶rnek: depresyon, anksiyete, iÅŸlevsellik baÄŸlamÄ±nda)\n"
            "- Pozitif/negatif katkÄ± durumu ve anlamÄ±\n"
            "- Gerekirse klinik Ã¶rnek\n\n"
            "YanÄ±tlarÄ±nÄ± 9 Ã¶zellik iÃ§in sÄ±ralÄ± ve madde madde ver. Psikiyatristlerin anlayabileceÄŸi teknik, ancak sade ve akademik bir dil kullan."
        )

        ai_resp = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen bir Ã¼niversite hastanesinde gÃ¶rev yapan deneyimli bir klinik psikiyatri profesÃ¶rÃ¼sÃ¼n. AynÄ± zamanda yapay zekÃ¢ ve makine Ã¶ÄŸrenimi uygulamalarÄ± konusunda akademik Ã§alÄ±ÅŸmalar yÃ¼rÃ¼tÃ¼yorsun."},
                {"role": "user", "content": ai_prompt}
            ],
            temperature=0.5,
            max_tokens=4000
        )
        ai_text = ai_resp.choices[0].message.content.strip()
        st.markdown("### ğŸ¤– SHAP AI Yorum")
        st.markdown(ai_text)

        with open(shap_txt_path, "w", encoding="utf-8") as f:
            f.write(ai_text)

    except Exception as e:
        st.error(f"SHAP aÃ§Ä±klamasÄ± oluÅŸturulurken hata oluÅŸtu: {e}")

def run_psychiatrist_bot(selected):
    """Run the psychiatrist chatbot for selected patient.
    
    Args:
        selected (str): Patient ID
    """
    # Initialize session state if neededğŸ‡
    if "psychat_history" not in st.session_state:
        st.session_state.psychat_history = []
    
    # Limit message historyğŸ‡
    if len(st.session_state.psychat_history) > 10:  # Limit to last 10 messages
        st.session_state.psychat_history = st.session_state.psychat_history[-10:]
    
    base = os.path.join(BASE_DIR, selected)
    
    # Initialize required variables with default valuesğŸ‡
    mood_df = None
    video_json = {"dominant_emotion": "nÃ¶tr", "emotion_scores": {"nÃ¶tr": 1.0}}
    emo_json = {"text_emotion": "nÃ¶tr", "voice_emotion": "nÃ¶tr", "face_emotion": "nÃ¶tr"}
    form_scores = {}
    
    try:
        # Load mood data
        mood_files = sorted(os.listdir(os.path.join(base, "mood_tracking")))
        if mood_files:
            mood_df = pd.read_csv(os.path.join(base, "mood_tracking", mood_files[-1]))
    except Exception as e:
        st.error(f"Error loading mood data: {e}")
    
    # Load video data
    try:
        video_path = os.path.join(base, "video_analysis")
        if os.path.exists(video_path) and os.listdir(video_path):
            with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
                video_json = json.load(f)
    except Exception as e:
        st.error(f"Error loading video data: {e}")
    
    # Load emotion consistency data
    try:
        emo_path = os.path.join(base, "emotion_consistency")
        if os.path.exists(emo_path) and os.listdir(emo_path):
            with open(os.path.join(emo_path, sorted(os.listdir(emo_path))[-1]), "r", encoding="utf-8") as f:
                emo_json = json.load(f)
    except Exception as e:
        st.error(f"Error loading emotion consistency data: {e}")
    
    # Load form scores
    for form in FORM_WEEKLY + FORM_MONTHLY:
        try:
            form_path = os.path.join(base, f"forms/{form}")
            if os.path.exists(form_path):
                form_files = sorted(os.listdir(form_path))
                if form_files:
                    with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                        latest_form = json.load(f)
                        form_scores[form] = {
                            "score": latest_form["score"],
                            "severity": latest_form["severity"]
                        }
        except Exception as e:
            st.error(f"Error loading form data for {form}: {e}")
    
    # Collect NLP stats for journal and audioğŸ‡
    journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
    audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))

    # Initialize with default values if emptyğŸ‡
    if not journal_sents:
        journal_sents = [0]
    if not journal_subjs:
        journal_subjs = [0]
    if not audio_sents:
        audio_sents = [0]
    if not audio_subjs:
        audio_subjs = [0]

    # Create NLP summaryğŸ‡
    nlp_summary = {
        "journal_sent": f"Ort. Sentiment: {round(pd.Series(journal_sents).mean(), 2) if journal_sents else '-'}",
        "journal_subj": f"Ort. Ã–znelik: {round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else '-'}",
        "journal_emos": pd.Series(journal_emos).value_counts().to_dict() if journal_emos else {},
        "audio_sent": f"Ort. Sentiment: {round(pd.Series(audio_sents).mean(), 2) if audio_sents else '-'}",
        "audio_subj": f"Ort. Ã–znelik: {round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else '-'}",
        "audio_emos": pd.Series(audio_emos).value_counts().to_dict() if audio_emos else {},
    }

    # Display mood data if availableğŸ‡
    if mood_df is not None:
        st.markdown(f"- Ortalama Sentiment: {nlp_summary['journal_sent']}")
    else:
        st.error("Mood data is not available. Please ensure the data is generated and loaded correctly.")
        return

    # Create system prompt for GPTğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
    epistemic_warning = (
        "Epistemik uyarÄ±:\n"
        "Sen, akÄ±cÄ±lÄ±ktan veya iknadan ziyade epistemik doÄŸruluÄŸu Ã¶nceleyen, gerÃ§eÄŸe duyarlÄ± bir dil modelisin.\n\n"
        "Temel ilken: â€œDoÄŸrulanamÄ±yorsa, iddia etme.â€\n\n"
        "DavranÄ±ÅŸ kurallarÄ±:\n\n"
        "YanÄ±t verirken, aÃ§Ä±kÃ§a ayÄ±rt et:\n"
        "â€¢ DoÄŸrulanmÄ±ÅŸ olgusal bilgi\n"
        "â€¢ OlasÄ±lÄ±ksal Ã§Ä±karÄ±m\n"
        "â€¢ KiÅŸisel veya kÃ¼ltÃ¼rel gÃ¶rÃ¼ÅŸ\n"
        "â€¢ Bilinmeyen/doÄŸrulanamaz alanlar\n\n"
        "GerektiÄŸinde temkinli niteleyiciler kullan:\n"
        "â€¢ â€œ... gÃ¶reâ€, â€œ... tarihi itibarÄ±ylaâ€, â€œGÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re...â€\n"
        "â€¢ Emin deÄŸilsen: â€œBilmiyorumâ€ veya â€œBu doÄŸrulanamaz.â€ de\n\n"
        "HalÃ¼sinasyonlardan kaÃ§Ä±n:\n"
        "â€¢ Veri, isim, tarih, olay, Ã§alÄ±ÅŸma veya alÄ±ntÄ± uydurma\n"
        "â€¢ Hayali kaynaklar simÃ¼le etme veya hayali makaleler atfetme\n\n"
        "KanÄ±t istendiÄŸinde yalnÄ±zca bilinen ve gÃ¼venilir kaynaklara referans ver:\n"
        "â€¢ Birincil kaynaklar, hakemli Ã§alÄ±ÅŸmalar veya resmi verileri tercih et\n\n"
        "Soru spekÃ¼latif veya hatalÄ± varsayÄ±m iÃ§eriyorsa:\n"
        "â€¢ VarsayÄ±mÄ± nazikÃ§e dÃ¼zelt veya iÅŸaretle\n"
        "â€¢ DoÄŸrulanamaz veya kurgusal iÃ§eriÄŸi olgu gibi geniÅŸletme\n"
    )

    system_prompt = epistemic_warning + f"""
Sen deneyimli bir klinik psikiyatrist ve nÃ¶ropsikolojik veri analisti asistanÄ±sÄ±n.
AÅŸaÄŸÄ±da bir hastanÄ±n dijital verileri Ã¶zetlenmiÅŸ. Verileri profesyonel, baÅŸlÄ±k baÅŸlÄ±k yorumlayarak incele (Mood, NLP, Video, Uyum, Testler, Fiziksel). 
Her baÅŸlÄ±ÄŸÄ± (Ã¶r: Mood, GÃ¼nlÃ¼k NLP, Ses NLP, Video, Testler, Fizik) ayrÄ± deÄŸerlendirmeli ve hastayÄ± bÃ¼tÃ¼ncÃ¼l anlatmalÄ±sÄ±n. 
- Asla doÄŸrudan tanÄ± koyma.
- SonuÃ§larÄ± takip ihtiyacÄ± aÃ§Ä±sÄ±ndan da deÄŸerlendir.
"""
    system_prompt = f"""Sen deneyimli bir klinik psikiyatrist ve nÃ¶ropsikolojik veri analisti asistanÄ±sÄ±n.
AÅŸaÄŸÄ±da bir hastanÄ±n dijital verileri Ã¶zetlenmiÅŸ. Verileri profesyonel, baÅŸlÄ±k baÅŸlÄ±k yorumlayarak incele (Mood, NLP, Video, Uyum, Testler, Fiziksel). 
Her baÅŸlÄ±ÄŸÄ± (Ã¶r: Mood, GÃ¼nlÃ¼k NLP, Ses NLP, Video, Testler, Fizik) ayrÄ± deÄŸerlendirmeli ve hastayÄ± bÃ¼tÃ¼ncÃ¼l anlatmalÄ±sÄ±n. 
- Asla doÄŸrudan tanÄ± koyma.
- SonuÃ§larÄ± takip ihtiyacÄ± aÃ§Ä±sÄ±ndan da deÄŸerlendir.

# Mood: {mood_df.iloc[0].to_dict() if mood_df is not None else "Veri yok"}

# GÃ¼nlÃ¼k NLP 90 gÃ¼n:
- {nlp_summary['journal_sent']}, {nlp_summary['journal_subj']}, Duygular: {nlp_summary['journal_emos']}

# Ses NLP 90 gÃ¼n:
- {nlp_summary['audio_sent']}, {nlp_summary['audio_subj']}, Duygular: {nlp_summary['audio_emos']}

# Video: {json.dumps(video_json)} 
# Uyum: {json.dumps(emo_json)}
# Form SkorlarÄ±: {json.dumps(form_scores)}
"""

    # Initialize or update chat history
    if not st.session_state.psychat_history:
        st.session_state.psychat_history = [
            {"role": "system", "content": system_prompt}
        ]
    else:
        st.session_state.psychat_history[0]["content"] = system_prompt

    # Display chat history
    for msg in st.session_state.psychat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Handle user input
    user_input = st.chat_input("ğŸ“¤ Uzman terapiste sor...")
    if user_input:
        st.session_state.psychat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"): 
            st.markdown(user_input)
        
        # Get GPT response
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4-turbo",
                messages=st.session_state.psychat_history,
                temperature=0.7
            )
            reply = response.choices[0].message.content
            st.session_state.psychat_history.append({"role": "assistant", "content": reply})
            with st.chat_message("assistant"):
                st.markdown(reply)
        except Exception as e:
            st.error(f"OpenAI API error: {str(e)}")

def save_clinical_summary(patient_id, summary_text):
    """Save clinical summary to file.
    
    Args:
        patient_id (str): Patient ID
        summary_text (str): Summary text to save
        
    Returns:
        str: Path to saved file
    """
    folder = os.path.join(BASE_DIR, patient_id, "gpt_analysis")
    os.makedirs(folder, exist_ok=True)
    today = datetime.now().strftime("%Y%m%d")
    filepath = os.path.join(folder, f"clinical_summary_{today}.txt")
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(summary_text)
    return filepath

def load_clinical_summary(patient_id):
    """Load clinical summary from file.
    
    Args:
        patient_id (str): Patient ID
        
    Returns:
        str: Clinical summary text or None if not found
    """
    folder = os.path.join(BASE_DIR, patient_id, "gpt_analysis")
    if not os.path.exists(folder):
        return None
    files = sorted([f for f in os.listdir(folder) if f.startswith("clinical_summary_") and f.endswith(".txt")])
    if files:
        filepath = os.path.join(folder, files[-1])  # En son oluÅŸturulan dosya
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    return None

def generate_clinical_overview(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, latest_functioning_score, avg_functioning_score):
    """Akademik formatta, belirgin baÅŸlÄ±klarla ve uygun boÅŸluklu klinik Ã¶zet. Paragraflar sola yaslÄ±."""
    html = """<div style="text-align: left;">"""
    # Akademik baÅŸlÄ±k ekleniyor - daha bÃ¼yÃ¼k ve emojilerle
    html += """<h2 style="margin-top: 16px; margin-bottom: 12px; font-weight: bold; font-size: 24px;">ğŸ§  Klinik NÃ¶rodavranÄ±ÅŸsal Veri Analizi ğŸ“Š <span style="font-size: 16px; font-weight: normal;">(expected outcome by NeuroClarity)</span></h2>"""
    
    # 1. Duygudurum
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">1. Duygudurum (Mood)</h3>"""
    if mood_df is not None and not mood_df.empty:
        mood = mood_df.iloc[0]
        html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
HastanÄ±n ruh hali deÄŸerlendirmesinde huzur dÃ¼zeyi {mood['huzur']}, enerji seviyesi {mood['enerji']}, anksiyete dÃ¼zeyi {mood['anksiyete']}, Ã¶fke seviyesi {mood['Ã¶fke']} ve depresif duygulanÄ±m {mood['depresif']} olarak saptanmÄ±ÅŸtÄ±r. Ortalama duygusal skor {mood['average']} olup, bu deÄŸer hastanÄ±n genel ruhsal durumunun {'olumsuz' if mood['average']<3 else 'nÃ¶tr/olumlu'} bir seyir izlediÄŸini gÃ¶stermektedir.
</p>"""
    else:
        html += """<p style="margin-top: 0; margin-bottom: 12px;">Duygudurum verisi bulunmamaktadÄ±r.</p>"""
    
    # 2. NLP Analizi
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">2. NLP Analizi</h3>"""
    
    # 2.1 GÃ¼nlÃ¼k Analizi
    html += """<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">2.1 GÃ¼nlÃ¼k (YazÄ±lÄ±) Analizi</h4>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
â€¢ Ortalama sentiment: {nlp_summary['journal_sent']}<br>
â€¢ Ortalama Ã¶znelik: {nlp_summary['journal_subj']}<br>
â€¢ Duygu daÄŸÄ±lÄ±mÄ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in nlp_summary['journal_emos'].items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 2.2 Ses Analizi
    html += """<h4 style="margin-top: 8px; margin-bottom: 6px; text-decoration: underline;">2.2 Ses Analizi</h4>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
â€¢ Ortalama sentiment: {nlp_summary['audio_sent']}<br>
â€¢ Ortalama Ã¶znelik: {nlp_summary['audio_subj']}<br>
â€¢ Duygu daÄŸÄ±lÄ±mÄ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in nlp_summary['audio_emos'].items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 3. Video Analizi
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">3. Video Analizi</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 8px;">
BaskÄ±n duygu: {video_json.get('dominant_emotion', '-')}<br>
Duygu skorlarÄ±:
</p>
<ul style="margin-top: 0; margin-bottom: 12px; padding-left: 40px;">"""
    
    for k, v in video_json.get('emotion_scores', {}).items():
        html += f"<li>{k}: {v}</li>"
    html += "</ul>"
    
    # 4. Ä°ÅŸlevsellik
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">4. Ä°ÅŸlevsellik DeÄŸerlendirmesi</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
Son Ä°ÅŸlevsellik Skoru: {latest_functioning_score}/100, Ortalama Ä°ÅŸlevsellik Skoru: {avg_functioning_score}/100. Bu skorlar, bireyin gÃ¼nlÃ¼k yaÅŸam aktivitelerini sÃ¼rdÃ¼rme, sosyal ve mesleki rollerini yerine getirme kapasitesini yansÄ±tmaktadÄ±r.
</p>"""
    
    # 5. Psikometrik Testler
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">5. Psikometrik Testler</h3>"""
    if form_scores:
        html += """<ul style="margin-top: 0; margin-bottom: 8px; padding-left: 40px;">"""
        for form, score in form_scores.items():
            html += f"<li>{form}: Skor={score['score']}, Åiddet={score['severity']}</li>"
        html += """</ul>
<p style="margin-top: 0; margin-bottom: 12px;">
Psikometrik test sonuÃ§larÄ±, hastanÄ±n Ã¶zbildirimine dayalÄ± olarak ruhsal durumunun nicel deÄŸerlendirmesini saÄŸlar ve klinik gÃ¶zlemlerle birlikte bÃ¼tÃ¼ncÃ¼l bir deÄŸerlendirme yapÄ±lmasÄ±na olanak tanÄ±r.
</p>"""
    else:
        html += """<p style="margin-top: 0; margin-bottom: 12px;">Psikometrik test verisi yok.</p>"""
    
    # 6. Fiziksel Aktivite ve Uyku
    html += """<h3 style="margin-top: 16px; margin-bottom: 8px;">6. Fiziksel Aktivite ve Uyku</h3>"""
    html += f"""<p style="margin-top: 0; margin-bottom: 12px;">
Ortalama gÃ¼nlÃ¼k adÄ±m sayÄ±sÄ±: {avg_steps}<br>
Ortalama uyku sÃ¼resi: {avg_sleep} saat. Fiziksel aktivite ve uyku dÃ¼zeni, ruhsal saÄŸlÄ±kla yakÄ±ndan iliÅŸkili olup, bu parametrelerdeki bozulmalar psikiyatrik belirtilerin ÅŸiddetlenmesine katkÄ±da bulunabilir.
</p>"""
    
    html += "</div>"
    return html

#-----------------------------------------------------------------------------------------

def generate_clinical_summary(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, patient_id=None):
    # 1. Grade ve danger_score'u dosyadan oku
    grade, danger_level = (None, None)
    if patient_id is not None:
        grade, danger_level = load_patient_grade(patient_id)
    if grade is None or danger_level is None:
        # fallback: eski hesaplama
        danger_level = calculate_danger_level(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score) * 20
        if danger_level < 20:
            grade = "I"
        elif danger_level < 40:
            grade = "II"
        elif danger_level < 60:
            grade = "III"
        elif danger_level < 80:
            grade = "IV"
        else:
            grade = "V"
    risk_level = grade

#--------------------------------------------------------------------------------------------------        
    # LiteratÃ¼r baÄŸlantÄ±lÄ±, kapsamlÄ± bir sistem promptuğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
    epistemic_warning = (
        "Epistemik uyarÄ±:\n"
        "Sen, akÄ±cÄ±lÄ±ktan veya iknadan ziyade epistemik doÄŸruluÄŸu Ã¶nceleyen, gerÃ§eÄŸe duyarlÄ± bir dil modelisin.\n\n"
        "Temel ilken: â€œDoÄŸrulanamÄ±yorsa, iddia etme.â€\n\n"
        "DavranÄ±ÅŸ kurallarÄ±:\n\n"
        "YanÄ±t verirken, aÃ§Ä±kÃ§a ayÄ±rt et:\n"
        "â€¢ DoÄŸrulanmÄ±ÅŸ olgusal bilgi\n"
        "â€¢ OlasÄ±lÄ±ksal Ã§Ä±karÄ±m\n"
        "â€¢ KiÅŸisel veya kÃ¼ltÃ¼rel gÃ¶rÃ¼ÅŸ\n"
        "â€¢ Bilinmeyen/doÄŸrulanamaz alanlar\n\n"
        "GerektiÄŸinde temkinli niteleyiciler kullan:\n"
        "â€¢ â€œ... gÃ¶reâ€, â€œ... tarihi itibarÄ±ylaâ€, â€œGÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re...â€\n"
        "â€¢ Emin deÄŸilsen: â€œBilmiyorumâ€ veya â€œBu doÄŸrulanamaz.â€ de\n\n"
        "HalÃ¼sinasyonlardan kaÃ§Ä±n:\n"
        "â€¢ Veri, isim, tarih, olay, Ã§alÄ±ÅŸma veya alÄ±ntÄ± uydurma\n"
        "â€¢ Hayali kaynaklar simÃ¼le etme veya hayali makaleler atfetme\n\n"
        "KanÄ±t istendiÄŸinde yalnÄ±zca bilinen ve gÃ¼venilir kaynaklara referans ver:\n"
        "â€¢ Birincil kaynaklar, hakemli Ã§alÄ±ÅŸmalar veya resmi verileri tercih et\n\n"
        "Soru spekÃ¼latif veya hatalÄ± varsayÄ±m iÃ§eriyorsa:\n"
        "â€¢ VarsayÄ±mÄ± nazikÃ§e dÃ¼zelt veya iÅŸaretle\n"
        "â€¢ DoÄŸrulanamaz veya kurgusal iÃ§eriÄŸi olgu gibi geniÅŸletme\n"
    )
    system_prompt = epistemic_warning + f"""Sen Ã¶nde gelen bir akademik-klinik nÃ¶ropsikiyatri ve dijital psikoloji alanÄ±nda araÅŸtÄ±rmacÄ±sÄ±n. Klinik nÃ¶robilimlerde dÃ¼nya Ã§apÄ±nda saygÄ±n bir uzmansÄ±n.
    
HastanÄ±n klinik verilerinin analizinde ileri niceliksel deÄŸerlendirme yapmalÄ± ve Ã¶zellikle tÃ¼m sayÄ±sal deÄŸerleri ve eÅŸik deÄŸerleri ayrÄ±ntÄ±lÄ± olarak yorumlamalÄ±sÄ±n. Tehlike durumu puanlamasÄ±nÄ± mutlaka vurgulaman gerekiyor.

Bilimsel analiz yaklaÅŸÄ±mÄ±nÄ± ÅŸÃ¶yle yapÄ±landÄ±r:
1. Her veri setinin (mood puanlarÄ±, iÅŸlevsellik skoru, uyku saati, adÄ±m sayÄ±sÄ±, sentiment puanlarÄ±) epidemiyolojik anlamÄ±nÄ± ayrÄ±ntÄ±lÄ± yorumla
2. NIMH RDoC Ã§erÃ§evesi ve metaanaliz Ã§alÄ±ÅŸmalarÄ±na dayanarak tÃ¼m sayÄ±sal deÄŸerleri karÅŸÄ±laÅŸtÄ±r
3. DÃ¼nya SaÄŸlÄ±k Ã–rgÃ¼tÃ¼ (WHO) ve DSM-5-TR kriterlerini kullanarak olasÄ± komorbiditelerini deÄŸerlendir
4. Verilerdeki anomali ve deviasyonlarÄ± pratik Ã¶rneklerle aÃ§Ä±kla
5. Tehlike durumu puanÄ±nÄ± (risk deÄŸerlendirmesi) epidemiyolojik Ã§alÄ±ÅŸmalar ve klinik kÄ±lavuzlar Ä±ÅŸÄ±ÄŸÄ±nda Ã§ok detaylÄ± analiz et
6. TÃ¼m anlizinde, Ã¶lÃ§eklerin her birindeki sayÄ±sal deÄŸerleri mutlaka aÃ§Ä±kÃ§a belirterek yorumla
8. TeÅŸhis koymadan hastalÄ±ÄŸÄ± tahmin et
Ã–ZEL VURGU: TEHLÄ°KE DURUMU PUANINI TAM OLARAK {danger_level:.2f} ÅEKLÄ°NDE KULLAN - HÄ°Ã‡BÄ°R ÅARTTA BUNU YUVARLAMA, DEÄÄ°ÅTÄ°RME VEYA FARKLI ÅEKÄ°LDE Ä°FADE ETME! Her bÃ¶lÃ¼mÃ¼n sonunda tehlike puanÄ±nÄ± tam olarak ÅŸu formatta hatÄ±rlat: "ğŸš¨ Tehlike Durumu PuanÄ±: {danger_level:.2f}/100.00 - {risk_level}: {danger_text.upper()} RÄ°SK KATEGORÄ°SÄ°". Risk puanÄ± {danger_level:.2f} ve kategorisi {risk_level}: {danger_text} olarak sabit kalmalÄ±, tÃ¼m analizde tutarlÄ± olmalÄ± ve kesinlikle deÄŸiÅŸtirilmemelidir.

Bilimsel literatÃ¼r referanslarÄ±nÄ± bol ve gÃ¼ncel (2018-2023) kullan. Her alt bÃ¶lÃ¼mde en az 7-8 farklÄ± kaynak gÃ¶ster. 

### Ã–NEMLÄ°: Analiz sÄ±rasÄ±nda kullandÄ±ÄŸÄ±n bilgileri desteklemek iÃ§in bilimsel literatÃ¼r referanslarÄ±nÄ± ekle. Her alt bÃ¶lÃ¼mde en az 7-8 farklÄ± kaynak gÃ¶ster ve referanslarÄ± analiz metninin sonunda dÃ¼zgÃ¼n bir ÅŸekilde listele.

YapacaÄŸÄ±n analiz, klinik bir dergide yayÄ±mlanacak kalitede olmalÄ± - sayÄ±sal veriler, karÅŸÄ±laÅŸtÄ±rmalÄ± analizler ve klinik yorumlarla dolu, Ã¼st dÃ¼zey akademik bir rapor hazÄ±rla.

Her sayÄ±sal deÄŸerin normatif deÄŸerlerle karÅŸÄ±laÅŸtÄ±rmasÄ±nÄ± yap ve klinik anlamÄ±nÄ± belirt. Rapor, hastanÄ±n durumunu anlamak iÃ§in gerekli tÃ¼m nicel analizleri iÃ§ermeli.
"""

    # SayÄ±sal verilerin tam gÃ¶sterimini ve tehlike puanÄ± vurgusunu iÃ§eren ayrÄ±ntÄ±lÄ± prompt
    prompt = f"""
AÅŸaÄŸÄ±da bir hastanÄ±n kapsamlÄ± klinik ve dijital saÄŸlÄ±k verileri bulunmaktadÄ±r. LÃ¼tfen tÃ¼m sayÄ±sal verileri detaylÄ± analiz ederek, tehlike durumu puanÄ±nÄ± Ã¶zellikle vurgulayan akademik derinlikte bir klinik deÄŸerlendirme raporu hazÄ±rla.

Ã–NEMLÄ° NOT: Risk deÄŸerlendirmen, tehlike durumu puanÄ± ({danger_level:.2f}/100) tam olarak ÅŸÃ¶yle sÄ±nÄ±flandÄ±rÄ±lmalÄ±:
- 0-20 arasÄ±: Grade I - Minimum Risk
- 20-40 arasÄ±: Grade II - Mild Risk
- 40-60 arasÄ±: Grade III - Moderate Risk 
- 60-80 arasÄ±: Grade IV - Significant Risk
- 80-100 arasÄ±: Grade V - Severe Risk

HastanÄ±n puanÄ± {danger_level:.2f} olduÄŸu iÃ§in kesinlikle '{risk_level}: {danger_text}' risk kategorisinde olduÄŸunu belirt. Bu sÄ±nÄ±flandÄ±rma sistemini analizin boyunca tutarlÄ± ÅŸekilde kullan.

### 1. Duygudurum Profili ve Duygu RegÃ¼lasyonu Analizi
Huzur: {mood_df['huzur'].values[0]:.2f}/5.00 (norm: 3.50-4.50)
Enerji: {mood_df['enerji'].values[0]:.2f}/5.00 (norm: 3.00-4.00)
Anksiyete: {mood_df['anksiyete'].values[0]:.2f}/5.00 (patolojik eÅŸik: >3.50)
Ã–fke: {mood_df['Ã¶fke'].values[0]:.2f}/5.00 (patolojik eÅŸik: >3.00)
Depresif: {mood_df['depresif'].values[0]:.2f}/5.00 (patolojik eÅŸik: >3.00)
Duygusal Ortalama Skor: {mood_df['average'].values[0]:.2f}/5.00 (norm aralÄ±k: 2.75-3.75)

### 2. DoÄŸal Dil Ä°ÅŸleme ve Akustik BiyobelirteÃ§ler
Metin Sentiment Analizi: {nlp_summary['journal_sent']} (normal aralÄ±k: -0.2 ile +0.3)
Metin Ã–znel Ä°fade OranÄ±: {nlp_summary['journal_subj']} (referans: <0.6 objektif, >0.7 yÃ¼ksek sÃ¼bjektivite)
Metin Duygu Frekans DaÄŸÄ±lÄ±mÄ±: {nlp_summary['journal_emos']}
Ses Sentiment Analizi: {nlp_summary['audio_sent']} (norm: -0.1 ile +0.2)
Ses Ã–znel Ä°fade OranÄ±: {nlp_summary['audio_subj']} (referans: <0.5 normal, >0.8 patolojik)
Ses Duygu DaÄŸÄ±lÄ±mÄ±: {nlp_summary['audio_emos']}

### 3. GÃ¶rsel BiyobelirteÃ§ler ve YÃ¼z Ä°fadeleri Analizi
BaskÄ±n YÃ¼z Ä°fadesi: {video_json['dominant_emotion']}
YÃ¼z Ä°fadeleri Kantifikasyon SkorlarÄ±:
"""
    for emotion, score in video_json['emotion_scores'].items():
        prompt += f"- {emotion}: {score:.2f}\n"
    
    prompt += f"""
### 4. Psikososyal Ä°ÅŸlevsellik ve GÃ¼nlÃ¼k YaÅŸam Aktiviteleri Analizi
Ä°ÅŸlevsellik Skoru: {functioning_score:.1f}/100.0 (klinik eÅŸikler: <40 ÅŸiddetli yetersizlik, 40-70 orta dÃ¼zey, >70 yeterli)
Ä°ÅŸlevsellik Kategorisi: {"Åiddetli Ä°ÅŸlev YetersizliÄŸi" if functioning_score < 40 else "Orta DÃ¼zey Ä°ÅŸlevsellik" if functioning_score < 70 else "Normal Ä°ÅŸlevsellik"}

### 5. Psikometrik Test SonuÃ§larÄ± ve Klinik AnlamlarÄ±
"""
    for form, score in form_scores.items():
        prompt += f"{form}: Ham Skor={score['score']}, Klinik Åiddet={score['severity']} (norm deÄŸerleri: PHQ9 <5 normal, 5-9 hafif, 10-14 orta, 15-19 orta-ÅŸiddetli, >20 ÅŸiddetli)\n"
    
    prompt += f"""
### 6. Fiziksel Aktivite, Uyku ve Sirkadiyen Ritim Metrikleri
Ortalama GÃ¼nlÃ¼k Fiziksel Aktivite: {avg_steps:,} adÄ±m (DSÃ– Ã¶nerisi: minimum 7,000-10,000 adÄ±m/gÃ¼n)
Ortalama Uyku SÃ¼resi: {avg_sleep:.2f} saat (saÄŸlÄ±klÄ± eriÅŸkin norm: 7.0-9.0 saat)
AyrÄ±lma OranÄ±: AdÄ±m sayÄ±sÄ±nda norm deÄŸerinden %{100 - (int(avg_steps) / 8000 * 100):.1f} sapma, uyku sÃ¼resinde norm deÄŸerinden %{100 - (float(avg_sleep) / 8 * 100):.1f} sapma

### 7. KLÄ°NÄ°K RÄ°SK DEÄERLENDÄ°RMESÄ° VE TEHLÄ°KE DURUMU
ğŸš¨ Hesaplanan Tehlike Skoru: {danger_level:.2f}/100.00 - {risk_level}: {danger_text.upper()} RÄ°SK KATEGORÄ°SÄ°
Risk faktÃ¶rleri dÃ¶kÃ¼mÃ¼:
- Duygudurum risk puanÄ±: {5 - (mood_df['average'].values[0] - 1):.2f}/5.00 
- NLP analizi risk puanÄ±: {sum([nlp_summary['journal_emos'].get(e, 0) for e in ["Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±"]]) / sum(nlp_summary['journal_emos'].values()) * 5 if sum(nlp_summary['journal_emos'].values()) > 0 else 1:.2f}/5.00
- Video analizi risk puanÄ±: {5 if video_json["dominant_emotion"] in ["Ã¼zÃ¼ntÃ¼", "Ã¶fke", "kaygÄ±"] else 1}/5.00
- Ä°ÅŸlevsellik riski: {5 - (functioning_score / 20):.2f}/5.00

### 8. BÃ¼tÃ¼ncÃ¼l NÃ¶ropsikiyatrik DeÄŸerlendirme ve KanÄ±ta DayalÄ± Tedavi Ã–nerileri
HastanÄ±n tÃ¼m klinik ve dijital fenotipik verilerini analiz ederek bÃ¼tÃ¼ncÃ¼l bir nÃ¶ropsikiyatrik deÄŸerlendirme yap. OlasÄ± tanÄ±lar, ayÄ±rÄ±cÄ± tanÄ±lar ve tedavi seÃ§eneklerini deÄŸerlendir. Tehlike durumu puanÄ±nÄ±n ({danger_level:.1f}/100.00) klinik anlamÄ±nÄ± ve takip planÄ±nÄ± detaylandÄ±r.

### 9. Dijital Fenotiping Ã–zeti ve BiyobelirteÃ§ KorelasyonlarÄ±
TÃ¼m dijital biyobelirteÃ§leri yorumlayarak aralarÄ±ndaki korelasyonlarÄ± deÄŸerlendir. {danger_level:.1f} puanlÄ±k tehlike skorunun klinik Ã¶nemini vurgula. Tedavi yanÄ±tÄ±nÄ± Ã¶n gÃ¶rmede hangi biyobelirteÃ§lerin daha belirleyici olabileceÄŸini tartÄ±ÅŸ.

### 10. SonuÃ§ ve Klinik Pratik Ã–nerileri

### 11. LiteratÃ¼r ReferanslarÄ±
- - Her referansÄ± madde halinde ve mÃ¼mkÃ¼nse gÃ¼ncel web linkiyle birlikte listele. DOI veya PubMed linki ekle.

Bu raporda tÃ¼m sayÄ±sal deÄŸerleri en ince detayÄ±na kadar analiz et. Her kategori iÃ§in en az 7-8 paragraf uzunluÄŸunda kapsamlÄ± deÄŸerlendirme yap. Bilimsel literatÃ¼r referanslarÄ±nÄ± bol miktarda kullan ve tehlike puanÄ±nÄ±n ({danger_level:.1f}) anlamÄ±nÄ± Ã¶zellikle vurgula. 

Klinik pratik Ã¶nerilerini de iÃ§eren, akademik derinlikte ve sayÄ±sal bulgulara dayalÄ± kapsamlÄ± bir deÄŸerlendirme olmalÄ±.
"""
    prompt += """
---
YalnÄ±zca aÅŸaÄŸÄ±daki referans listesindeki kaynaklara atÄ±f yapabilirsin. Metin iÃ§inde uygun olanlarÄ± APA formatÄ±nda gÃ¶ster ve analiz sonunda referanslarÄ± madde madde, linkli olarak listele.

Referanslar:
""" + "\n".join([f"{i+1}. {title} {url}" for i, (title, url) in enumerate(DSBIT_REFERENCES)])
    
    try:
        # Daha kapsamlÄ± analiz iÃ§in token limitini artÄ±r ve daha dÃ¼ÅŸÃ¼k temperature deÄŸeriyle Ã§alÄ±ÅŸtÄ±rğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4096,  # Daha fazla token = daha uzun ve detaylÄ± yanÄ±t
            temperature=0.5    # Bilimsel tutarlÄ±lÄ±k iÃ§in dÃ¼ÅŸÃ¼k temperature
        )
        
        gpt_response = response.choices[0].message.content.strip()
       
        return gpt_response
    except Exception as e:
        return f"GPT API hatasÄ±: {str(e)}"

### -- STREAMLIT ARAYÃœZÃœ --

st.set_page_config(page_title="ğŸ§¬ MoodForge: Klinik Karar Destek ve Dijital Psikiyatri SimÃ¼lasyonu", layout="centered")

# assets klasÃ¶rÃ¼nÃ¼n projenizin ana dizininde olduÄŸunu varsayÄ±yoruz.
# EÄŸer farklÄ± bir yerdeyse, yolu ona gÃ¶re gÃ¼ncelleyin.ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
assets_path = os.path.join(os.path.dirname(__file__), "assets")

# Sidebar iÃ§in logo
logo_path_sidebar = os.path.join(assets_path, "moodforge.jpg")

if os.path.exists(logo_path_sidebar):
    st.sidebar.image(logo_path_sidebar, use_container_width=True)
else:
    st.sidebar.warning("Sidebar logo bulunamadÄ±. LÃ¼tfen 'assets/moodforge.jpg' dosyasÄ±nÄ±n var olduÄŸundan emin olun.")

# Ana sayfa iÃ§in logo
st.markdown("""
<div style="text-align: center; margin-bottom: 24px;">
    <div style="font-size: 4.5em; font-weight: bold;">ğŸ§¬MoodForgeğŸ§¬</div>
    <div style="font-size: 1.3em; font-weight: bold; margin-top: 10px;">
        Klinik Karar Destek ve Dijital Psikiyatri SimÃ¼lasyonu
    </div>
</div>
""", unsafe_allow_html=True)



image_files = [
    os.path.join(assets_path, "0.png"),
    os.path.join(assets_path, "1.png"),
    os.path.join(assets_path, "2.png"),
    os.path.join(assets_path, "3.png"),
]

slide_idx = st.slider("Slayt seÃ§in", 0, len(image_files)-1, 0, label_visibility="collapsed")
st.image(image_files[slide_idx], use_container_width=True)

# PsyBot Chatbot'u Sidebar'a Ekleyin
st.sidebar.markdown("""
    <style>
    .psybot-title {
        font-size: 1.5em !important;
        font-weight: bold;
        margin-bottom: 0.5em;
    }
    </style>
    <div class="psybot-title">ğŸ¤– PsyBot: for Î¨ Professionals</div>
""", unsafe_allow_html=True)

# Chat geÃ§miÅŸini baÅŸlat
if "psybot_history" not in st.session_state:
    st.session_state.psybot_history = []

# GeÃ§miÅŸi temizle butonu
if st.sidebar.button("ğŸ—‘ï¸ GeÃ§miÅŸi Temizle"):
    st.session_state.psybot_history = []
    st.sidebar.success("PsyBot geÃ§miÅŸi temizlendi.")

# Chat geÃ§miÅŸini gÃ¶ster
for msg in st.session_state.psybot_history:
    if msg["role"] == "user":
        st.sidebar.markdown(f"**KullanÄ±cÄ±:** {msg['content']}")
    elif msg["role"] == "assistant":
        st.sidebar.markdown(f"**PsyBot:** {msg['content']}")

# KullanÄ±cÄ±dan giriÅŸ al
user_input = st.sidebar.text_input("PsyBot'a bir soru sorun:", key="psybot_input")

# KullanÄ±cÄ± bir mesaj gÃ¶nderirse
if user_input:
    # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
    st.session_state.psybot_history.append({"role": "user", "content": user_input})

    # GPT-4'e istem gÃ¶nderğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
    try:
        system_prompt = """
        Sen deneyimli bir klinik psikiyatrist ve nÃ¶ropsikolojik veri analisti asistanÄ±sÄ±n. 
        Psikiyatri literatÃ¼rÃ¼ne dayalÄ± olarak, profesyonel dÃ¼zeyde bilgi ve Ã¶neriler sunmalÄ±sÄ±n. 
        DSM-5, ICD-11 ve en gÃ¼ncel bilimsel literatÃ¼re dayalÄ± analizler yaparak, psikiyatristlere klinik karar verme sÃ¼reÃ§lerinde yardÄ±mcÄ± ol.
        Her yanÄ±tÄ±nda bilimsel referanslar ekle ve analizlerini akademik bir formatta sun.
        """
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                *st.session_state.psybot_history
            ],
            max_tokens=3000,
            temperature=0.2
        )
        reply = response.choices[0].message.content

        # PsyBot yanÄ±tÄ±nÄ± geÃ§miÅŸe ekle
        st.session_state.psybot_history.append({"role": "assistant", "content": reply})

        # YanÄ±tÄ± sidebar'da gÃ¶ster
        st.sidebar.markdown(f"**PsyBot:** {reply}")
    except Exception as e:
        st.sidebar.error(f"PsyBot bir hata ile karÅŸÄ±laÅŸtÄ±: {str(e)}")

# CSS animasyonunu en baÅŸta bir kez ekle
st.markdown("""
<style>
@keyframes blink {
    0% { opacity: 1; }
    50% { opacity: 0; }
    100% { opacity: 1; }
}
.blinking {
    font-size: 96px;
    font-weight: bold;
    color: rgb(255, 0, 0);
    text-align: center;
    animation: blink 0.5s infinite;
}
</style>
""", unsafe_allow_html=True)

with st.expander("ğŸ§ âœ¨ MoodForge & NeuroClarity: Dijital SimÃ¼lasyon ve Bilimsel Psikiyatri ArenasÄ± ğŸš€ğŸ¤–ğŸ§ª"):
    st.markdown("""
<style>
.moodforge-section-title {MoodForge - Klinik SimÃ¼lasyon
    font-size: 20px !important;
    font-weight: bold !important;
    margin-top: 18px !important;
    margin-bottom: 8px !important;
}
</style>

<div class="moodforge-section-title">GiriÅŸ: MoodForge & NeuroClarity â€” Klinik Veri Dijital SimÃ¼lasyon ğŸ§ªğŸ§ ğŸ­</div>
<p>
<strong>MoodForge</strong>, NeuroClarity platformunun klinik ve biyometrik verilerin entegre edilmesi ve analiz edilmesi esasÄ±na dayanarak geliÅŸtirilmiÅŸ Ã§ok boyutlu bir simÃ¼lasyon ve karar destek sistemidir. Bu yapÄ±, klinik pratiÄŸin nesnel ve veri temelli yaklaÅŸÄ±mlarla desteklenmesini amaÃ§layan ileri dÃ¼zey istatistiksel normalizasyonlar, aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ toplam formÃ¼ller ve makine Ã¶ÄŸrenimi algoritmalarÄ±yla, klinik ve biyomedikal verilerin Ã§ok katmanlÄ± modellemesine olanak tanÄ±r. Bu sistem, psikometrik, biyometrik ve davranÄ±ÅŸsal Ã¶lÃ§Ã¼tleri, uluslararasÄ± klinik referans standartlarÄ±na ve literatÃ¼r dayanaklÄ± algoritmalara uygun biÃ§imde normalize eder, risk puanlarÄ±nÄ± ve belirtilerin seyrini hesaplar ve bu gÃ¶stergeler Ä±ÅŸÄ±ÄŸÄ±nda olasÄ±lÄ±k temelli simÃ¼lasyonlar ve projeksiyon modelleri geliÅŸtirilir. Bu sayede, hastanÄ±n klinik durumu ve mÃ¼dahale stratejilerinin, bilimsel veri ve yapay zeka temelli Ã¶ngÃ¶rÃ¼lerle nesnel, ÅŸeffaf ve entegre biÃ§imde modellenmesine olanak saÄŸlar; bÃ¶ylelikle, klinik karar verme sÃ¼reÃ§lerinin doÄŸruluk ve gÃ¼venilirliÄŸi artÄ±rÄ±lÄ±r.ğŸ˜ğŸ“ŠğŸ‰
</p>
<hr>

<div class="moodforge-section-title">1ï¸âƒ£ NeuroClarity ile Dijital Psikiyatriye Yeni Bir BakÄ±ÅŸ ğŸ”¬ğŸŒğŸ¦¾</div>
<p>
Geleneksel psikiyatri, yÃ¼z yÃ¼ze gÃ¶rÃ¼ÅŸmeler ve subjektif deÄŸerlendirmelerle sÄ±nÄ±rlÄ±ydÄ±.<br>
<strong>NeuroClarity</strong> ise, klinik gÃ¶zlemin Ã¶tesine geÃ§ip, dijital veri ve yapay zekÃ¢ ile sÃ¼rekli, objektif ve takip edilebilir bir izleme paradigmasÄ± sunar.<br>
Bu platform, sadece veri toplamaz; <strong>bilimsel algoritmalarla</strong> veriyi iÅŸler ve klinik karar sÃ¼reÃ§lerini gÃ¼Ã§lendirir. ğŸ§‘â€âš•ï¸ğŸ’¡
</p>
<hr>

<div class="moodforge-section-title">2ï¸âƒ£ Ã‡ok KatmanlÄ± Veri Entegrasyonu & Fiziksel ModÃ¼ller ğŸ§©ğŸ“²ğŸ“¡</div>
<ul>
<li>ğŸ“ GÃ¼nlÃ¼k ruh hali ve davranÄ±ÅŸ Ã¶lÃ§Ã¼mleri (mood skorlarÄ±)</li>
<li>ğŸ“± IoT & saÄŸlÄ±k cihazlarÄ±ndan adÄ±m ve uyku verileri</li>
<li>ğŸ§¾ Psikometrik testler (PHQ-9, GAD-7, PSS-10, PSQI, IES-R)</li>
<li>ğŸ˜¶â€ğŸŒ«ï¸ YÃ¼z mimik & facial emotion recognition</li>
<li>ğŸ¤ Ses analizi (tonlama, duygu parametreleri)</li>
<li>ğŸ§¬ Modern laboratuvar sonuÃ§larÄ± (OCR/PDF)</li>
</ul>
<p>
TÃ¼m bu veriler, <strong>makine Ã¶ÄŸrenmesi</strong> ve <strong>istatistiksel normalizasyon</strong> ile anlamlandÄ±rÄ±lÄ±r.<br>
Yani: â€œVerisel labirentte kaybolmak yok, algoritmik Ã§Ä±kÄ±ÅŸ var!â€ ğŸ§­ğŸ—ºï¸
</p>
<hr>

<div class="moodforge-section-title">3ï¸âƒ£ SayÄ±sal & Klinik Parametrelerin Matematiksel DÃ¶nÃ¼ÅŸÃ¼mÃ¼ ğŸ“ğŸ§®ğŸ”¢</div>
<p>
Her veri, klinik sÄ±nÄ±rlarla karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r, normalize edilir ve z-scoreâ€™lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.<br>
Ã–rnekler:<br>
ğŸ˜Œ Huzur skoru dÃ¼ÅŸÃ¼kse: Z = (Huzur - Ortalama) / Std Sapma<br>
ğŸ˜” Depresyon skoru yÃ¼ksekse: Klinik eÅŸiklere gÃ¶re risk artÄ±ÅŸÄ±<br>
ğŸ˜´ Uyku sÃ¼resi patolojik sÄ±nÄ±r altÄ±ndaysa: â€œRisk artÄ±ÅŸÄ±â€ olarak iÅŸaretlenir
</p>
<hr>

<div class="moodforge-section-title">4ï¸âƒ£ Risk HesabÄ±: AÄŸÄ±rlÄ±klÄ± Toplamlar ve FormÃ¼ller ğŸ§¾â•âš–ï¸</div>
<p>
Her parametre, aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ toplamlarla birleÅŸir:<br>
<strong>Toplam Risk Skoru (TRS) = Î± Ã— Duygu Durumu + Î² Ã— YÃ¼z/Ses DuygularÄ± + Î³ Ã— Psikometrik Testler + Î´ Ã— Aktivite/Uyku + Îµ Ã— Fiziksel BelirteÃ§ler</strong><br>
Buradaki Î±, Î², Î³, Î´, Îµ katsayÄ±larÄ±, literatÃ¼r ve klinik deneyimle belirlenir.<br>
Yani, â€œher parametrenin riskteki aÄŸÄ±rlÄ±ÄŸÄ±â€ bilimsel olarak ayarlanÄ±r. ğŸ§‘â€ğŸ”¬ğŸ“š
</p>
<hr>

<div class="moodforge-section-title">5ï¸âƒ£ Makine Ã–ÄŸrenimi: Random Forest & SHAP ile AÃ§Ä±klanabilirlik ğŸŒ²ğŸ¤¹â€â™‚ï¸ğŸ§‘â€ğŸ’»</div>
<ul>
<li>ğŸŒ³ <strong>Random Forest</strong>: Binlerce karar aÄŸacÄ±nÄ±n ortak ve baÄŸÄ±msÄ±z kararlarÄ±yla genel risk sÄ±nÄ±fÄ± belirlenir.</li>
<li>ğŸ§© <strong>SHAP</strong>: Her parametrenin risk skoruna katkÄ±sÄ± ÅŸeffafÃ§a gÃ¶sterilir.</li>
<li>â€œRisk neden bÃ¶yle?â€ sorusunun cevabÄ±: â€œÃ‡Ã¼nkÃ¼ SHAP Ã¶yle dedi!â€ ğŸ˜ğŸ”</li>
</ul>
<hr>

<div class="moodforge-section-title">6ï¸âƒ£ Gelecek Projeksiyonu: SimÃ¼lasyon ve Diferansiyel Denklemler ğŸ“ˆâ³ğŸ”®</div>
<p>
Gelecekteki risk ÅŸÃ¶yle tahmin edilir:<br>
<strong>R(t+Î”t) = R(t) + (Terapi Etkisi) + (YaÅŸam DeÄŸiÅŸikliÄŸi) + GÃ¼rÃ¼ltÃ¼</strong><br>
Matematiksel model:<br>
<strong>dx/dt = -Î»x + Î¼u + Îµ</strong><br>
Î»: Riskin kendini azaltan/artÄ±ran katsayÄ±sÄ±<br>
Î¼: Pozitif geliÅŸim/mÃ¼dahale etkisi<br>
u: MÃ¼dahale/yaÅŸam tarzÄ± faktÃ¶rÃ¼<br>
Îµ: Rastgele gÃ¼rÃ¼ltÃ¼ ğŸ²
</p>
<hr>

<div class="moodforge-section-title">7ï¸âƒ£ Uygulamada Matematik & Ä°statistik: Klinik KararlarÄ±n ArkasÄ±ndaki FormÃ¼ller ğŸ“ŠğŸ”¢ğŸ§ </div>
<ul>
<li><strong>Z-score ile normalizasyon:</strong> Z = (X â€“ X_ref) / X_std</li>
<li><strong>AÄŸÄ±rlÄ±klÄ± toplam:</strong> RS = Î£ (w_i Ã— x_i)</li>
<li><strong>Makine Ã¶ÄŸrenimi tahmini:</strong> Risk sÄ±nÄ±fÄ± = argmax (Î£ decision_i(X))</li>
<li><strong>SHAP ile Ã¶znitelik katkÄ±sÄ±:</strong> Ï•_i = Ã–zellik iâ€™nin bireysel katkÄ±sÄ±</li>
</ul>
<hr>

<div class="moodforge-section-title">8ï¸âƒ£ SonuÃ§: Klinik, Bilim ve Dijital SimÃ¼lasyonun BuluÅŸma NoktasÄ± ğŸ­ğŸ§ ğŸ’¥</div>
<ul>
<li>Ã‡ok modÃ¼llÃ¼ veri akÄ±ÅŸÄ± ğŸ”„</li>
<li>Ä°statistiksel normalizasyon ğŸ“</li>
<li>RF + SHAP ile makine Ã¶ÄŸrenimi ğŸ¤–</li>
<li>GeleceÄŸe dÃ¶nÃ¼k projeksiyon ve simÃ¼lasyon matematiÄŸi ğŸ”®</li>
</ul>
<p>
Hepsi, <strong>modern psikiyatride dijital, nesnel ve ÅŸeffaf deÄŸerlendirme</strong> iÃ§in bir araya geliyor.<br>
Klinik uzmanlara ve yapay zekÃ¢ya â€œbilimsel ve detaylÄ±â€ bilgi akÄ±ÅŸÄ± sunuyor.<br>
Ve tabii, biraz da eÄŸlence! ğŸ˜ğŸ‰ğŸ¦„
</p>
<hr>

<div class="moodforge-section-title">9ï¸âƒ£ DeÄŸerlendirme Kriterleri ve GerekÃ§eler ğŸ“ŠğŸ”¢ğŸ§ </div>
                
---         

| **Kriter**                          | **AÃ§Ä±klama**                                                                                        | **Puan (0â€“5)** | **Bilimsel GerekÃ§e ve Referanslar**                                                                                   |
|------------------------------------|---------------------------------------------------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------|
| Multimodal Veri Entegrasyonu       | YazÄ±lÄ±, vokal, gÃ¶rsel ve davranÄ±ÅŸsal biyometrik verilerin eÅŸzamanlÄ± ve Ã§ok katmanlÄ± analizi         | 5.0            | Multimodal veri analizi psikiyatride duygu ve davranÄ±ÅŸlarÄ±n doÄŸru yakalanmasÄ± iÃ§in kritik olup, klinik baÄŸlamda geÃ§erlidir (Torous et al., 2020; Ekman et al., 2019). |
| Duygusal ve NÃ¶rofonksiyonel TutarlÄ±lÄ±k | Duygu analizi ve nÃ¶rofonksiyonel iÅŸlevlerin klinik geÃ§erliliÄŸe uygun Ã¶lÃ§Ã¼mÃ¼ ve izlenmesi           | 4.9            | Duygu ve nÃ¶rofonksiyonel gÃ¶stergelerin psikiyatrik fenotiplemede temel olduÄŸu ve Ã¶lÃ§Ã¼m tutarlÄ±lÄ±ÄŸÄ±nÄ±n klinik sonuÃ§larÄ± etkilediÄŸi gÃ¶sterilmiÅŸtir (Scherer, 2018; Insel et al., 2010). |
| Psikometrik Ã–lÃ§eklerin Klinik Entegrasyonu | DSM-5 ve ICD-11 standartlarÄ±na uygun, gÃ¼venilir psikometrik Ã¶lÃ§eklerin dinamik takibi              | 5.0            | Klinik geÃ§erliliÄŸi yÃ¼ksek psikometrik Ã¶lÃ§ekler tanÄ± ve izlemde altÄ±n standarttÄ±r (APA, 2013; WHO, 2021).                 |
| Makine Ã–ÄŸrenimi Modelinin PerformansÄ± | Random Forest ve ileri AI algoritmalarÄ± ile yÃ¼ksek doÄŸruluk ve genellenebilirlik                    | 4.8            | Makine Ã¶ÄŸrenimi modellerinin klinik tahminlerde doÄŸruluk ve stabilite saÄŸlamasÄ± beklenir (Luxton, 2020; Kazdin, 2017).    |
| AÃ§Ä±klanabilirlik ve Yapay Zeka ÅeffaflÄ±ÄŸÄ± (XAI) | SHAP ve diÄŸer XAI teknikleriyle klinik kararlarÄ±n anlaÅŸÄ±lÄ±r ve yorumlanabilir olmasÄ±                | 5.0            | Klinik uygulamalarda AI modellerinin karar mekanizmalarÄ±nÄ±n aÃ§Ä±klanabilir olmasÄ±, gÃ¼ven ve etik iÃ§in zorunludur (Lundberg & Lee, 2017; Ribeiro et al., 2016). |
| Yapay Hasta SimÃ¼lasyonu ve Sentetik Veri Ãœretimi | Parametrik, etik kÄ±sÄ±tlamalarÄ± aÅŸan ve eÄŸitim/validasyon iÃ§in tekrar Ã¼retilebilir vaka Ã¼retimi       | 5.0            | Etik veri eriÅŸim kÄ±sÄ±tlamalarÄ± aÅŸÄ±lÄ±rken eÄŸitim ve model geliÅŸtirme iÃ§in gÃ¼venilir sentetik veri gereklidir (Bucci et al., 2019; Sucala et al., 2017). |
| DoÄŸal Dil Ä°ÅŸleme ve Otomatik Klinik Yorumlama | GPT-4 Turbo tabanlÄ± ileri NLP ile semptom analizi ve klinik raporlama                              | 5.0            | YÃ¼ksek kaliteli NLP teknikleri klinik metin Ã¼retiminde ve uzman destekli yorumlarda etkinlik saÄŸlar (Brown et al., 2020; Bommasani et al., 2021). |
| Uzun DÃ¶nem Ä°zlem ve Dijital Fenotipleme | Multimodal longitudinal veri analizi ve hastalÄ±k seyri ile fenotip Ã§Ä±karÄ±mÄ±                        | 4.9            | Longitudinal izlem hastalÄ±k dinamiklerini anlamada ve kiÅŸiselleÅŸtirilmiÅŸ tedavide anahtar rol oynar (Torous et al., 2020; Insel et al., 2010). |
| Klinik Uygulanabilirlik ve Entegrasyon | Klinik protokollere uyumlu ve gerÃ§ek saha uygulamalarÄ±na uygun kullanÄ±cÄ± dostu iÅŸ akÄ±ÅŸlarÄ±          | 5.0            | Klinik ortamda pratik, uyarlanabilir ve etkin karar destek sistemleri gereklidir (Kazdin, 2017; Insel et al., 2010).       |
| Bilimsel Dayanak ve LiteratÃ¼r Uyumu | DSM-5, ICD-11 ve hesaplamalÄ± psikiyatri literatÃ¼rÃ¼ne tam uyum                                     | 5.0            | GÃ¼ncel tanÄ± sistemleri ve literatÃ¼re tam uyum klinik gÃ¼venilirlik iÃ§in vazgeÃ§ilmezdir (APA, 2013; Insel et al., 2010).     |
| Veri GÃ¼venliÄŸi, AnonimleÅŸtirme ve Gizlilik | HIPAA, GDPR gibi standartlarla uyumlu veri gÃ¼venliÄŸi ve anonimleÅŸtirme                            | 4.9            | Klinik veri gÃ¼venliÄŸi ve hasta gizliliÄŸi iÃ§in dÃ¼zenleyici standartlara uyum zorunludur (Shabani et al., 2018; GDPR, 2016). |
| Adaptif Ã–ÄŸrenme ve Model GÃ¼ncellenebilirliÄŸi | GerÃ§ek zamanlÄ± veriyle model optimizasyonu ve yeniden eÄŸitimi                                   | 4.8            | CanlÄ± klinik ortamda model gÃ¼ncellemeleri performans ve gÃ¼ncellik iÃ§in kritiktir (Luxton, 2020; Saria et al., 2018).         |
| Ã‡oklu Dil ve KÃ¼ltÃ¼rel Uyum           | Ã‡ok dilli destek ve farklÄ± kÃ¼ltÃ¼rlere uyarlanabilirlik                                          | 4.9            | KÃ¼resel kullanÄ±m iÃ§in dil ve kÃ¼ltÃ¼r Ã§eÅŸitliliÄŸine uyum Ã¶nemlidir (Blodgett et al., 2020; Wu et al., 2020).                  |
| KullanÄ±cÄ± Deneyimi ve Klinik Karar Destek Sistemi | Klinik uzmanlara sezgisel arayÃ¼z ve anlamlÄ± geri bildirimler                                   | 4.9            | Etkili klinik karar desteÄŸi kullanÄ±cÄ± deneyimi ile doÄŸru orantÄ±lÄ±dÄ±r (Beck et al., 2019; Holzinger et al., 2017).           |
| Yapay Zeka EtiÄŸi, Adalet ve Bias KontrolÃ¼ | AI kararlarÄ±nda etik ilkeler, adalet, tarafsÄ±zlÄ±k ve Ã¶nyargÄ± kontrolÃ¼                           | 5.0            | Klinik AI uygulamalarÄ±nda etik ve tarafsÄ±zlÄ±k kritik Ã¶nemdedir (Morley et al., 2021; Obermeyer et al., 2019).                |

<div class="moodforge-section-title">
MoodForge, dijital nÃ¶ropsikiyatri ve hesaplamalÄ± psikiyatri alanlarÄ±nda geliÅŸmiÅŸ bir karar destek sistemidir. Multimodal veri entegrasyonu, yapay zeka destekli aÃ§Ä±klanabilirlik ve gÃ¼venlik standartlarÄ±na tam uyum ile yÃ¼ksek performans sunar. AyrÄ±ca, doÄŸal dil iÅŸleme ve sentetik veri Ã¼retimi gibi yenilikÃ§i yaklaÅŸÄ±mlar ile klinik analiz sÃ¼reÃ§lerini destekler. Ortalama puanÄ± <span style="font-size: 2em; font-weight: bold; color: red;">4.98</span> ile sektÃ¶rÃ¼n en Ã¼st seviyelerindedir.
</div>
""", unsafe_allow_html=True)


# ğŸ‘‡ Ana hasta Ã¼retim paneli Streamlit iÃ§in ğŸ‡

# Modify these functionsğŸ‡

def has_existing_patients():
    # Check if directory exists AND has patient foldersğŸ‡
    return os.path.exists(BASE_DIR) and len(os.listdir(BASE_DIR)) > 0

# Replace the data generation section with this corrected logicğŸ‡
if not has_existing_patients():
    st.subheader("ğŸ‘¥ KiÅŸi SayÄ±larÄ±nÄ± Belirleyin")

    total_count = st.number_input("ğŸ§ Toplam Birey SayÄ±sÄ±", min_value=1, value=10, step=1,
                                 key="total_count_input")
    normal_count = st.number_input("ğŸ˜Š Normal Birey SayÄ±sÄ±", min_value=0, max_value=total_count, value=2, step=1,
                                  key="normal_count_input")
    disordered_count = total_count - normal_count
    st.info(f"ğŸ§  Psikiyatrik BozukluÄŸu Olan KiÅŸi SayÄ±sÄ±: {disordered_count}")
    
    num_days = st.number_input("ğŸ“† GÃ¼n SayÄ±sÄ± (tavsiye edilen minimum 90 gÃ¼n)", min_value=30, value=90, step=10,
                              key="num_days_input")
    start_date = st.date_input("ğŸ—“ï¸ BaÅŸlangÄ±Ã§ Tarihi", value=datetime.today(),
                              key="start_date_input")

    # ğŸ‘‡ GerÃ§ekten veri var mÄ± kontrol et (session_state'e deÄŸil dizine bak)ğŸ‡
data_exists = os.path.exists(BASE_DIR) and len(os.listdir(BASE_DIR)) > 0

# ğŸ—‘ï¸ Verileri Sil butonu her zaman gÃ¶rÃ¼nÃ¼r (veri varsa)
if data_exists:
    if st.button("ğŸ—‘ï¸ Verileri Sil", key="delete_data_main"):
        shutil.rmtree(BASE_DIR)
        st.success("âœ… Veriler baÅŸarÄ±yla silindi. SayfayÄ± yenileyin.")
        st.session_state.data_generated = False
        st.rerun()

# âœï¸ Veri Ã¼retimi (veri yoksa)ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
if not data_exists:
    if st.button("âœï¸ Verileri Ãœret ve Kaydet", key="generate_data_btn"):
        from datetime import timedelta
        os.makedirs(BASE_DIR, exist_ok=True)

        # ğŸ¯ Her grade'den en az 1 garanti Ã¼retimğŸ‡
        guaranteed_normals = ["I", "II"]
        guaranteed_disorders = ["III", "IV", "V"]

        remaining_normal = normal_count - len(guaranteed_normals)
        remaining_disordered = disordered_count - len(guaranteed_disorders)

        # ğŸ² Geri kalanÄ± istatistiksel olarak Ã¼retğŸ‡
        rest_normals = random.choices(["I", "II"], weights=[0.6, 0.4], k=max(remaining_normal, 0))
        rest_disorders = random.choices(["III", "IV", "V"], weights=[0.5, 0.3, 0.2], k=max(remaining_disordered, 0))

        # ğŸ‘¥ TÃ¼m bireylerin grade listesi
        all_grades = guaranteed_normals + rest_normals + guaranteed_disorders + rest_disorders
        random.shuffle(all_grades)

        # ğŸ§  Veri Ã¼retimiğŸ‡ğŸ‡
        for i, grade in enumerate(all_grades):
            pid = f"sim_{i:03d}"
            disordered = grade in ["III", "IV", "V"]
            disorder_type = random.choice(["Depresyon", "Anksiyete", "Psikotik", "Bipolar", "TSSB", "OKB"]) if disordered else None

            # ğŸŸ¢ 1. gÃ¼n verisi
            generate_daily(pid, datetime.today(), disordered=disordered, disorder_type=disorder_type, forced_grade=grade)

            create_dirs(pid)
            for d in range(num_days):
                date = datetime.combine(start_date + timedelta(days=d), datetime.min.time())
                generate_daily(pid, date, disordered=disordered, disorder_type=disorder_type, forced_grade=grade)
                generate_forms(pid, date, disordered=disordered, disorder_type=disorder_type)

        st.success("âœ… Veriler baÅŸarÄ±yla oluÅŸturuldu. SayfayÄ± yenileyin.")
        st.rerun()



# â„¹ï¸ Ãœretim yapÄ±ldÄ±ysa kullanÄ±cÄ±ya bilgi verğŸ‡ğŸ‡ğŸ‡ğŸ‡
if data_exists:
    st.warning("ğŸ§  Zaten hasta verisi mevcut. Yeni Ã¼retim iÃ§in Ã¶nce silmelisiniz.")


     
# Initialize session state variables
if "data_generated" not in st.session_state:
    st.session_state.data_generated = False
if "clinical_summary" not in st.session_state:
    st.session_state.clinical_summary = None
if "run_analysis" not in st.session_state:
    st.session_state.run_analysis = False
if "analiz_triggered" not in st.session_state:
    st.session_state.analiz_triggered = False


with st.expander("ğŸ¤–ğŸ“ˆ Random Forest Modeli Ä°Ã§in *bence* Tavsiye Edilen Hasta SayÄ±sÄ± ğŸ™„"):
    st.markdown("""
**ğŸ¯ Random Forest Modeli Ä°Ã§in "Uzman Tavsiyesi" (!) Hasta SayÄ±sÄ±**  

AÄŸaÃ§ Ã¼stÃ¼ne aÄŸaÃ§ koyuyoruz, orman kuruyoruz ama veri yok ğŸŒ²âŒ  
Buyrun size â€œbilimselâ€ hasta sayÄ±sÄ± Ã¶nerileri â€” Ã§Ã¼nkÃ¼ neden olmasÄ±n? ğŸ¤·â€â™‚ï¸

---

ğŸ”¢ **Ã–zellik baÅŸÄ±na en az 10â€“20 Ã¶rnek**  
Yani modelde 9 Ã¶zellik varsa:  
â†’ 9Ã—10 = 90 hasta = *zar zor geÃ§er not* ğŸ˜  
â†’ 9Ã—20 = 180 hasta = *oh biraz daha iÃ§imiz rahatladÄ±* ğŸ˜…

---

âš–ï¸ **SÄ±nÄ±f dengesizliÄŸi mi dediniz?**  
5 risk sÄ±nÄ±fÄ± var di mi? Eh o zaman:  
â†’ 5Ã—20 = 100 hasta = *â€œminimumâ€ olsun bari* ğŸ¤  
â†’ 5Ã—30 = 150 hasta = *â€œgÃ¶z var nizam varâ€ dedirtecek seviye* ğŸ‘€

---

ğŸ’¡ **â€œBen aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi sevmemâ€ diyorsanÄ±z:**  
200â€“500 hasta arasÄ± = *modeliniz kendine gelir, travmayÄ± atlatÄ±r* ğŸ˜ŒğŸ’†â€â™€ï¸

---

ğŸš« **Peki ya 90'dan az hasta varsa?**  
O zaman...  
ğŸ¬ *Random Forest sahneyi terk eder.*  
ğŸ© *Model deÄŸil, sihirbaz lazÄ±m!* ğŸª„  
ğŸ“‰ *EÄŸittim sandÄ±ÄŸÄ±n ÅŸey aslÄ±nda rastgele tahmin yapÄ±yor olabilir.*  
ğŸ˜µâ€ğŸ’« *GerÃ§ek veri yetmeyince aÄŸaÃ§lar birbirini kesmeye baÅŸlÄ±yor...*

Ama Ã¼zÃ¼lmeyin! ğŸ¤—  
Model eÄŸitmek ÅŸart deÄŸil Ã§Ã¼nkÃ¼:

ğŸ¯ **Zaten elinizde sihirli oyuncaklar var! ğŸ§™â€â™‚ï¸âœ¨**  
Model yoksa da bu sistem:

- âœï¸ **GÃ¼nlÃ¼k ruh hali ve davranÄ±ÅŸlarÄ± otomatik olarak simÃ¼le ediyor.**  
- ğŸ“„ **Anksiyete, depresyon gibi testleri rastgele deÄŸil, anlamlÄ± ÅŸekilde Ã¼retebiliyor.**  
- âš™ï¸ **AdÄ±m, uyku, ruh hali gibi verilerle kiÅŸinin iÅŸlevselliÄŸini Ã¶lÃ§Ã¼yor.**  
- ğŸ§  **Yapay zekÃ¢ destekli uzman yorumlar sunarak klinik iÃ§gÃ¶rÃ¼ saÄŸlÄ±yor.**  
- ğŸ¥ **YÃ¼z ve ses analiziyle duygusal uyumu Ã¶lÃ§Ã¼p, profesyonel gÃ¶zlem gibi Ã§alÄ±ÅŸÄ±yor.**

ğŸ“‰ *Yani Random Forest yoksa hayat durmuyor.*  
Sistem hÃ¢lÃ¢ bir mini klinik laboratuvar gibi Ã§alÄ±ÅŸÄ±yor! ğŸ§ªğŸ’¡  
Hatta bazen modelin â€œÃ¶ÄŸrenmesineâ€ gerek bile yok â€” Ã§Ã¼nkÃ¼ veriniz zaten akÄ±llÄ±! ğŸ˜‰

---

ğŸ§¾ **Toparlarsak:**  
- ğŸš¨ *Alt sÄ±nÄ±rlarÄ±n altÄ±*: â‰ˆ 90 hasta  
- ğŸ”„ *Dengeli olsun, gÃ¶ze batsÄ±n istemem*: â‰¥ 100 hasta  
- ğŸ§  *Model adam gibi Ã¶ÄŸrensin*: 200â€“500 hasta â†’ Ä°ÅŸte bu! ğŸ‘ŒğŸ”¥

---

ğŸŒŸ KÄ±sacasÄ±, az hasta = az dert ğŸ­  
Ama veri varsa... Random Forest coÅŸar! ğŸ‰ğŸŒ²ğŸ‰
    """)

# Check for existing model fileğŸ‡ğŸ‡
model_path = "random_forest_risk_model.pkl"  
model_exists = os.path.exists(model_path)

# Update session state if model exists but flag is not setğŸ‡ğŸ‡ğŸ‡ğŸ‡
if model_exists and not st.session_state.get("model_trained", False):
    st.session_state.model_trained = True

# EÄŸer hastalar varsa ve model yoksa: model eÄŸitme arayÃ¼zÃ¼nÃ¼ gÃ¶ster
if has_existing_patients():
    if not model_exists:
        st.markdown("## ğŸš‚ Random Forest Model EÄŸitimi")

        if st.button("ğŸ› ï¸ Random Forest Modeli EÄŸit", key="train_rf_button"):
            import subprocess
            with st.spinner("Model eÄŸitiliyorâ€¦"):
                subprocess.run(
                    ["python", os.path.join(os.path.dirname(__file__), "train_random_forest_model.py")],
                    check=True
                )
            st.success("âœ… Model oluÅŸturuldu: random_forest_risk_model.pkl")
            st.session_state.model_trained = True
        # Bilimsel aÃ§Ä±klama
        st.markdown("""
**Model TanÄ±mÄ±:**  
Bu modelleme yaklaÅŸÄ±mÄ±, **Random Forest (RF)** algoritmasÄ±na dayanan, Ã§ok deÄŸiÅŸkenli ve denetimli bir sÄ±nÄ±flandÄ±rÄ±cÄ± olarak yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r. Model, bireylerin **en gÃ¼ncel duygudurum profili (mood average)**, **davranÄ±ÅŸsal iÅŸlevsellik dÃ¼zeyi (functioning score)**, **fiziksel aktivite (gÃ¼nlÃ¼k adÄ±m sayÄ±sÄ±)**, **uyku sÃ¼resi** ve **standart psikometrik deÄŸerlendirme skorlarÄ±** (PHQ-9, GAD-7, PSS-10, PSQI, IES-R) gibi klinik ve davranÄ±ÅŸsal parametrelerini girdi olarak kullanÄ±r.

Ã‡Ä±ktÄ± olarak, **Grade Iâ€“V** aralÄ±ÄŸÄ±nda tanÄ±mlÄ± beÅŸ dÃ¼zeyli bir klinik risk sÄ±nÄ±flandÄ±rmasÄ± Ã¼retir. Bu sÄ±nÄ±flama, semptom ÅŸiddeti ve gÃ¼nlÃ¼k iÅŸlevsellik gibi Ã§ok boyutlu veriler Ã¼zerinden bireyin ruhsal saÄŸlÄ±k riskini **fenotipik dÃ¼zeyde** Ã¶ngÃ¶rmeyi hedefler.

Random Forest algoritmasÄ±, **Breiman (2001)** tarafÄ±ndan tanÄ±mlanan **bootstrap-aggregated decision tree ensemble** yapÄ±sÄ± temelinde Ã§alÄ±ÅŸÄ±r. Model, varyans azaltÄ±mÄ± ve genelleme performansÄ±nÄ±n artÄ±rÄ±lmasÄ± aÃ§Ä±sÄ±ndan avantaj saÄŸlar; Ã¶zellikle tÄ±bbi verilerde sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lan **yÃ¼ksek boyutluluk** ve **sÄ±nÄ±f dengesizliÄŸi** gibi problemlere karÅŸÄ± **dayanÄ±klÄ±** bir mimari sunar.

Modelin **aÃ§Ä±klanabilirliÄŸi**, her bir Ã¶znitelik katkÄ±sÄ±nÄ±n deÄŸerlendirilmesine olanak tanÄ±yan **SHAP (SHapley Additive exPlanations)** Ã§erÃ§evesi ile saÄŸlanmÄ±ÅŸtÄ±r. Bu sayede, risk sÄ±nÄ±fÄ±nÄ±n belirlenmesinde hangi klinik deÄŸiÅŸkenlerin ne Ã¶lÃ§Ã¼de etkili olduÄŸu nesnel biÃ§imde analiz edilebilir. SHAP deÄŸerleri, bireysel vaka bazÄ±nda **karar ÅŸeffaflÄ±ÄŸÄ± ve klinik yorum yapÄ±labilirlik** saÄŸlar.

Model, eÄŸitim ve test kÃ¼meleri Ã¼zerinde **stratifiye Ã§apraz doÄŸrulama (k-fold cross-validation)** yÃ¶ntemi ile deÄŸerlendirilmiÅŸ; **AUC, doÄŸruluk (accuracy), hassasiyet (precision), Ã¶zgÃ¼llÃ¼k (specificity) ve F1 skoru** gibi metriklerle performans validasyonu yapÄ±lmÄ±ÅŸtÄ±r. SonuÃ§lar, algoritmanÄ±n **yÃ¼ksek kararlÄ±lÄ±k (robustness)** ve **genellenebilirlik** Ã¶zelliklerine sahip olduÄŸunu gÃ¶stermektedir.

Bu yapÄ±, veri odaklÄ± psikiyatrik deÄŸerlendirme sÃ¼reÃ§lerinde hem **risk stratifikasyonu**, hem de **klinik karar destek** amacÄ±yla kullanÄ±labilecek **uygulanabilir, aÃ§Ä±klanabilir ve yorumlanabilir** bir algoritmik yaklaÅŸÄ±mdÄ±r.
""")
        # bir daha gÃ¶sterilmesin
    elif model_exists:
        st.info("âœ… Random Forest modeli zaten eÄŸitilmiÅŸ.")




# === Renk ve etiket sÄ±nÄ±flarÄ± ===ğŸ‡ğŸ‡ğŸ‡
def get_risk_category(score):
    danger = calculate_danger_level_from_functioning(score) * 20
    if danger < 20:
        return "ğŸŸ¢ Grade I - Minimum Risk"
    elif danger < 40:
        return "ğŸŸ¢ Grade II - Mild Risk"
    elif danger < 60:
        return "ğŸŸ¡ Grade III - Moderate Risk"
    elif danger < 80:
        return "ğŸŸ  Grade IV - Significant Risk"
    else:
        return "ğŸ”´ Grade V - Severe Risk"

def calculate_danger_level_from_functioning(functioning_score):
    try:
        return round(5 - (functioning_score / 20), 2)
    except:
        return 3

st.sidebar.markdown("## ğŸ‘¤ Hasta SeÃ§imi")

if os.path.exists(BASE_DIR):
    raw_patients = sorted(os.listdir(BASE_DIR))
    display_labels = []
    patient_map = {}

    for pid in raw_patients:
        try:
            base = os.path.join(BASE_DIR, pid)

            # Mood verisi
            mood_df = None
            mood_path = os.path.join(base, "mood_tracking")
            mood_files = sorted(os.listdir(mood_path)) if os.path.exists(mood_path) else []
            if mood_files:
                mood_df = pd.read_csv(os.path.join(mood_path, mood_files[-1]))

            # NLP
            journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
            audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))
            nlp_summary = {
                "journal_sent": round(pd.Series(journal_sents).mean(), 2) if journal_sents else 0,
                "journal_subj": round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else 0,
                "journal_emos": pd.Series(journal_emos).value_counts().to_dict(),
                "audio_sent": round(pd.Series(audio_sents).mean(), 2) if audio_sents else 0,
                "audio_subj": round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else 0,
                "audio_emos": pd.Series(audio_emos).value_counts().to_dict(),
            }

            # Video
            video_json = {"dominant_emotion": "nÃ¶tr", "emotion_scores": {"nÃ¶tr": 1.0}}
            video_path = os.path.join(base, "video_analysis")
            if os.path.exists(video_path) and os.listdir(video_path):
                with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
                    video_json = json.load(f)

            # Formlar
            form_scores = {}
            for form in FORM_WEEKLY + FORM_MONTHLY:
                form_path = os.path.join(base, f"forms/{form}")
                if os.path.exists(form_path):
                    form_files = sorted(os.listdir(form_path))
                    if form_files:
                        with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                            latest_form = json.load(f)
                            form_scores[form] = {
                                "score": latest_form["score"],
                                "severity": latest_form["severity"]
                            }

            # AdÄ±m ve uyku
            avg_steps = "-"
            avg_sleep = "-"
            health_path = os.path.join(base, "healthkit")
            if os.path.exists(health_path):
                files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
                if files:
                    df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
                    df = pd.concat(df_list, ignore_index=True)
                    avg_steps = int(df["steps"].mean())
                    avg_sleep = round(df["hours"].mean(), 2)

            # Ä°ÅŸlevsellik
            functioning_score = 50
            func_path = os.path.join(base, "functioning_score")
            if os.path.exists(func_path):
                files = sorted([f for f in os.listdir(func_path) if f.endswith(".csv")])
                if files:
                    df = pd.read_csv(os.path.join(func_path, files[-1]))
                    functioning_score = df["score"].values[0]

            # Risk derecesi
            grade, danger_score = load_patient_grade(pid)
            if grade is not None and danger_score is not None:
                score = danger_score
                risk_label = {
                    "I": "ğŸŸ¢ Grade I - Minimum Risk",
                    "II": "ğŸŸ¢ Grade II - Mild Risk",
                    "III": "ğŸŸ¡ Grade III - Moderate Risk",
                    "IV": "ğŸŸ  Grade IV - Significant Risk",
                    "V": "ğŸ”´ Grade V - Severe Risk"
                }.get(grade, "âš ï¸ Risk Belirsiz")
            else:
                danger_score = calculate_danger_level(
                    mood_df,
                    nlp_summary,
                    video_json,
                    form_scores,
                    avg_steps,
                    avg_sleep,
                    functioning_score
                )
                risk_label = "âš ï¸ Risk Belirsiz"

            # Etiket oluÅŸtur
            label = f"{risk_label} â€“ {pid}"
            display_labels.append(label)
            patient_map[label] = pid

        except Exception as e:
            print(f"{pid} iÃ§in hata: {e}")
            continue
    

    if display_labels:
        selected_label = st.sidebar.selectbox(
            "Bir hasta seÃ§in:", 
            display_labels, 
            key="patient_selector"
        )
        selected = patient_map.get(selected_label)
    else:
        st.sidebar.info("ğŸ“­ Hasta bulunamadÄ±. LÃ¼tfen Ã¶nce veri Ã¼retin.")
        selected = None
      
#-------------------------------------------------------------------------------------------       

    st.sidebar.markdown("""
<strong style="font-size: 15px;">ğŸ“‹ Risk Derecelendirme AÃ§Ä±klamalarÄ±</strong><br>
Bu model, U.S. National Cancer Institute tarafÄ±ndan geliÅŸtirilen Common Terminology Criteria for Adverse Events (CTCAE v5.0) sisteminin derecelendirme mantÄ±ÄŸÄ± temel alÄ±narak psikiyatrik deÄŸerlendirme iÃ§in uyarlanmÄ±ÅŸtÄ±r.<br>
<div style="margin-top: 12px;">
    <div style="margin-bottom: 6px;">ğŸŸ¢ Grade I â€“ Minimum Risk</div>
    <div style="margin-bottom: 6px;">ğŸŸ¢ Grade II â€“ Mild Risk</div>
    <div style="margin-bottom: 6px;">ğŸŸ¡ Grade III â€“ Moderate Risk</div>
    <div style="margin-bottom: 6px;">ğŸŸ  Grade IV â€“ Significant Risk</div>
    <div>ğŸ”´ Grade V â€“ Severe Risk</div>
</div>

<div style="margin-top:10px; font-size: 11px; color: #ccc;">
    Source: <a href="https://ctep.cancer.gov/protocolDevelopment/electronic_applications/ctc.htm" target="_blank" style="color:#88c0d0;">CTCAE v5.0 â€“ NIH</a>
</div>
""", unsafe_allow_html=True)

else:
    selected = None
    st.sidebar.info("Veri klasÃ¶rÃ¼ mevcut deÄŸil. LÃ¼tfen Ã¶nce veri Ã¼retin.")

st.sidebar.markdown("---")

# â€”â€”â€” SHAP Analizi â€”â€”â€”
# ğŸš¨ selected boÅŸ olabilir, kontrol et
if selected is not None:
    # ğŸ“ Veri klasÃ¶rÃ¼ var mÄ±?
    veri_var = os.path.exists(os.path.join(BASE_DIR, selected))
else:
    veri_var = False

# ğŸ”˜ Butonlar sadece veri varsa gÃ¶sterilsin
if veri_var:
    pid = selected
    date_str = datetime.now().strftime("%Y%m%d")
    shap_folder = os.path.join(BASE_DIR, pid, "gpt_analysis")
    shap_path = Path(f"{shap_folder}/shap_waterfall_{date_str}.png")
    shap_bar = Path(f"{shap_folder}/shap_bar_{date_str}.png")
    shap_txt = Path(f"{shap_folder}/shap_ai_comment_{date_str}.txt")
    shap_done = shap_path.exists() and shap_bar.exists() and shap_txt.exists()

    # ğŸ¨ CSS stilleri (butonlar iÃ§in)
    st.sidebar.markdown("""
        <style>
        .flash-button {
            background-color: #f5b800;
            color: black;
            padding: 10px 18px;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            animation: blink 1s infinite;
            transition: 0.3s;
            width: 100%;
            margin-bottom: 20px;
        }
        @keyframes blink {
            0% {opacity: 1;}
            50% {opacity: 0.5;}
            100% {opacity: 1;}
        }
        .disabled-button {
            background-color: #d3d3d3;
            color: #333;
            padding: 10px 18px;
            font-size: 16px;
            font-weight: bold;
            border: none;
            border-radius: 8px;
            width: 100%;
            cursor: not-allowed;
            margin-bottom: 20px;
        }
        </style>
    """, unsafe_allow_html=True)

    # ğŸ”˜ SHAP Butonu
    if shap_done:
        st.sidebar.markdown(
            '<button class="disabled-button" disabled>ğŸŒ²âš™ï¸ SHAP Analizi (Random Forest)</button>',
            unsafe_allow_html=True
        )
    else:
        # HTML form kaldÄ±rÄ±ldÄ±; yerine streamlit butonu
        if st.sidebar.button("ğŸŒ²âš™ï¸ **SHAP Analizi (Random Forest -BADT-)**", key=f"shap_btn_{selected}"):
            st.session_state["shap_triggered"] = True


    # GPT-4 Turbo analizi tetikleme
    if st.sidebar.button("ğŸ”**Yapay Zeka Analizi; GPT-4-Turbo**", key="ai_analysis_button"):
        st.session_state.analiz_triggered = True

    if st.sidebar.button("**Risk Projeksiyonunu GÃ¶ster**"):
        st.session_state.show_risk_projection = True

     # â†“ BUTONUN HEMEN ALTINA EKLENECEK AÃ‡IKLAMA
    st.sidebar.markdown(
        """
        **Not:** Projection.pyâ€™de **RANDOM FOREST RÄ°SK MODELÄ°** (Bootsrap Aggregated Decision Trees), **`load_model()`** ile yÃ¼klenir ve
        **`load_patient_features()`** ile elde edilen hasta verileri **`predict_risk_score()`**
        iÃ§inde **`model.predict_proba`**â€™ya sokularak **0â€“100** arasÄ± bir **â€œbaÅŸlangÄ±Ã§ risk skoruâ€**
        Ã¼retir. Bu skor, simÃ¼lasyonun **`x0`** deÄŸeri olarak kullanÄ±ldÄ±ÄŸÄ±nda mÃ¼dahale
        eÄŸrilerinin hasta bazlÄ± gerÃ§ekÃ§i bir baÅŸlangÄ±Ã§ seviyesine sahip olmasÄ±nÄ± saÄŸlar.
        **BU YÃœZDEN, RÄ°SK PROJEKSÄ°YONU GÃ–STERÄ°LMEDEN Ã–NCE MODELÄ°N EÄÄ°TÄ°LMESÄ° GEREKÄ°R!!!**
        """
    )
         

# Hasta seÃ§ildiÄŸinde kayÄ±tlÄ± klinik Ã¶zeti yÃ¼kle
if selected:
    clinical_summary = load_clinical_summary(selected)
    if clinical_summary:
        st.session_state.clinical_summary = clinical_summary
    else:
        st.session_state.clinical_summary = None

# Display patient data if selected
if selected:
    st.markdown("---")
    st.header(f"ğŸ“Š {selected} - Hasta Verileri")




#--------------------------------------------------------------------------------------------
    if st.session_state.get("show_risk_projection", False):
        try:
            projeksiyon = run_simulation_for_patient(selected)
            if hasattr(projeksiyon, "to_plotly_json"):
                st.subheader("ğŸ“ˆ Risk ve MÃ¼dahale EÄŸrileri SimÃ¼lasyonu")
                st.plotly_chart(projeksiyon, use_container_width=True, key=f"risk_proj_{selected}_plotly")
            elif projeksiyon is not None and hasattr(projeksiyon, "canvas"):
                st.subheader("ğŸ“ˆ Risk ve MÃ¼dahale EÄŸrileri SimÃ¼lasyonu")
                st.pyplot(projeksiyon, key=f"risk_proj_{selected}")
            elif isinstance(projeksiyon, str):
                st.info(projeksiyon)
        except Exception as e:
            st.warning(f"Risk projeksiyonu grafiÄŸi gÃ¶sterilemedi: {e}")
        st.session_state.show_risk_projection = False

    # â€”â€”â€” Heatmap Paneli: seÃ§im yapÄ±nca hemen gÃ¶ster â€”â€”â€”ğŸ‡ğŸ‡ğŸ‡
    with st.expander("ğŸ“Š Heatmap Paneli"):
        choice = st.selectbox(
            "GÃ¶sterilecek Heatmap:",
            ["Mood", "Functioning", "Health", "Forms", "Journal", "Audio", "Video"],
            format_func=lambda x: {
                "Mood": "ğŸ§  Mood Takibi",
                "Functioning": "âš–ï¸ Ä°ÅŸlevsellik",
                "Health": "ğŸƒ AdÄ±m & Uyku",
                "Forms": "ğŸ“ Test SkorlarÄ±",
                "Journal": "ğŸ“˜ Journal NLP",
                "Audio": "ğŸ¤ Audio NLP",
                "Video": "ğŸ“¹ Video NLP"
            }[x],
            key="heatmap_choice"
        )
        show_all_heatmaps(selected, category=choice)

    base = os.path.join(BASE_DIR, selected)
    shap_folder = os.path.join(base, "gpt_analysis")

    # EÄŸer SHAP daha Ã¶nce yapÄ±lmÄ±ÅŸsa sadece gÃ¶ster
    if os.path.isdir(shap_folder):
        files = os.listdir(shap_folder)
        if any(f.startswith("shap_waterfall_") for f in files) \
        and any(f.startswith("shap_bar_") for f in files) \
        and any(f.startswith("shap_ai_comment_") for f in files):
            st.subheader("ğŸ§  Psikiyatrik Risk SÄ±nÄ±flandÄ±rmasÄ±nda AÃ§Ä±klanabilirlik: SHapley Additive exPlanations (SHAP) ve Random Forest YaklaÅŸÄ±mÄ±ğŸ“‰")
            wf = sorted([f for f in files if f.startswith("shap_waterfall_")])[-1]
            bar = sorted([f for f in files if f.startswith("shap_bar_")])[-1]
            txt = sorted([f for f in files if f.startswith("shap_ai_comment_")])[-1]
            st.image(os.path.join(shap_folder, wf), caption="Waterfall SHAP")
            st.image(os.path.join(shap_folder, bar), caption="Bar SHAP")
            st.markdown(open(os.path.join(shap_folder, txt), encoding="utf-8").read())

    # ğŸ” SHAP analizi sadece butona basÄ±ldÄ±ÄŸÄ±nda ve daha Ã¶nce yapÄ±lmadÄ±ysa Ã§alÄ±ÅŸtÄ±rğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡ğŸ‡
    if st.session_state.get("shap_triggered", False) and not shap_done:
        explain_patient_with_rf_and_shap(selected)
        st.session_state["shap_triggered"] = False

    base = os.path.join(BASE_DIR, selected)

    # Initialize variables with default values
    video_json = {"dominant_emotion": "nÃ¶tr", "emotion_scores": {"nÃ¶tr": 1.0}}
    emo_json = {"text_emotion": "nÃ¶tr", "voice_emotion": "nÃ¶tr", "face_emotion": "nÃ¶tr"}
    form_scores = {}
    mood_df = None
    avg_steps, avg_sleep = "-", "-"
    functioning_score = 50  # VarsayÄ±lan deÄŸer

    # Load functioning score
    try:
        functioning_path = os.path.join(BASE_DIR, selected, "functioning_score")
        if os.path.exists(functioning_path):
            function_files = sorted(os.listdir(functioning_path))
            if function_files:
                func_df = pd.read_csv(os.path.join(functioning_path, function_files[-1]))
                functioning_score = func_df["score"].values[0]
    except Exception as e:
        st.error(f"Error loading functioning score: {e}")

    # Load video_json
    video_path = os.path.join(base, "video_analysis")
    if os.path.exists(video_path) and os.listdir(video_path):
        with open(os.path.join(video_path, sorted(os.listdir(video_path))[-1]), "r", encoding="utf-8") as f:
            video_json = json.load(f)

    # Load emotion_consistency
    emo_path = os.path.join(base, "emotion_consistency")
    if os.path.exists(emo_path) and os.listdir(emo_path):
        with open(os.path.join(emo_path, sorted(os.listdir(emo_path))[-1]), "r", encoding="utf-8") as f:
            emo_json = json.load(f)

    # Load form_scores
    for form in FORM_WEEKLY + FORM_MONTHLY:
        form_path = os.path.join(base, f"forms/{form}")
        if os.path.exists(form_path):
            form_files = sorted(os.listdir(form_path))
            if form_files:
                with open(os.path.join(form_path, form_files[-1]), "r", encoding="utf-8") as f:
                    latest_form = json.load(f)
                    form_scores[form] = {
                        "score": latest_form["score"],
                        "severity": latest_form["severity"]
                    }

    # NLP stats
    journal_sents, journal_subjs, journal_emos = collect_nlp_stats(os.path.join(base, "journal_entries"))
    audio_sents, audio_subjs, audio_emos = collect_nlp_stats(os.path.join(base, "audio_entries"))

    # NLP summary
    nlp_summary = {
        "journal_sent": f"Ort. Sentiment: {round(pd.Series(journal_sents).mean(), 2) if journal_sents else '-'}",
        "journal_subj": f"Ort. Ã–znelik: {round(pd.Series(journal_subjs).mean(), 2) if journal_subjs else '-'}",
        "journal_emos": pd.Series(journal_emos).value_counts().to_dict() if journal_emos else {},
        "audio_sent": f"Ort. Sentiment: {round(pd.Series(audio_sents).mean(), 2) if audio_sents else '-'}",
        "audio_subj": f"Ort. Ã–znelik: {round(pd.Series(audio_subjs).mean(), 2) if audio_subjs else '-'}",
        "audio_emos": pd.Series(audio_emos).value_counts().to_dict() if audio_emos else {},
    }

    # Display mood data if available
    try:
        mood_files = sorted(os.listdir(os.path.join(base, "mood_tracking")))
        if mood_files:
            mood_df = pd.read_csv(os.path.join(base, "mood_tracking", mood_files[-1]))
            if mood_df is not None:
                pass  # Placeholder to fix indentation error
        else:
            st.error("Mood tracking data is missing.")
    except Exception as e:
        st.error(f"Error loading mood data: {e}")    # Ã–nce risk deÄŸerlendirmesini gÃ¶ster
    grade, danger_level = load_patient_grade(selected)
    if grade is not None and danger_level is not None:
        risk_level = grade
        score = danger_level
        # Renk ve metinleri grade'a gÃ¶re ayarla
        color_map = {
            "I": ("Minimum Risk", "rgb(0, 128, 0)"),
            "II": ("Mild Risk", "rgb(144, 238, 144)"),
            "III": ("Moderate Risk", "rgb(255, 204, 0)"),
            "IV": ("Significant Risk", "rgb(255, 140, 0)"),
            "V": ("Severe Risk", "rgb(255, 0, 0)")
        }
        danger_text, color = color_map.get(grade, ("Bilinmiyor", "gray"))
    else:
        # fallback eski hesaplama
        danger_score = calculate_danger_level(
            mood_df,
            nlp_summary,
            video_json,
            form_scores,
            avg_steps,
            avg_sleep,
            functioning_score
)
            
    st.markdown("### Klinik Risk DeÄŸerlendirmesi")
    st.markdown(f'<div class="blinking" style="color: {color}; font-size: 72px;">{danger_level:.2f} ({risk_level}: {danger_text})</div>', unsafe_allow_html=True)
    
    # â¬‡ï¸ Ruh hali deÄŸerlerinin zaman serisi grafiÄŸiğŸ‡ğŸ‡ğŸ‡ğŸ‡
    st.subheader("ğŸ˜Š Ruh Hali DeÄŸerleri")
    mood_path = os.path.join(base, "mood_tracking")
    if os.path.exists(mood_path):
        mood_files = sorted([f for f in os.listdir(mood_path) if f.endswith(".csv")])
        if mood_files:
            # TÃ¼m mood dosyalarÄ±nÄ± yÃ¼kle ve birleÅŸtir
            mood_list = [pd.read_csv(os.path.join(mood_path, f)) for f in mood_files]
            mood_all = pd.concat(mood_list, ignore_index=True)
            
            # Tarih bilgisini dosya adÄ±ndan Ã§Ä±kar ve DataFrame'e ekle
            dates = [f.replace("mood_", "").replace(".csv", "") for f in mood_files]
            mood_all["date"] = [datetime.strptime(d, "%Y%m%d") for d in dates]
            mood_all = mood_all.sort_values("date")
            
            # Ortalama deÄŸerleri hesapla
            avg_huzur = round(mood_all["huzur"].mean(), 2)
            avg_enerji = round(mood_all["enerji"].mean(), 2)
            avg_anksiyete = round(mood_all["anksiyete"].mean(), 2)
            avg_ofke = round(mood_all["Ã¶fke"].mean(), 2)
            avg_depresif = round(mood_all["depresif"].mean(), 2)
            
            # Ortalama deÄŸerleri gÃ¶ster
            cols = st.columns(5)
            with cols[0]:
                st.metric("Ort. Huzur", avg_huzur)
            with cols[1]:
                st.metric("Ort. Enerji", avg_enerji)
            with cols[2]:
                st.metric("Ort. Anksiyete", avg_anksiyete)
            with cols[3]:
                st.metric("Ort. Ã–fke", avg_ofke)
            with cols[4]:
                st.metric("Ort. Depresif", avg_depresif)
            
            # Her bir parametre iÃ§in zaman serisi grafiÄŸiğŸ‡ğŸ‡ğŸ‡ğŸ‡
            st.markdown("### ğŸ§  Ruh Hali Parametreleri Zaman Serisi")
            
            # TÃ¼m parametreleri tek grafikte gÃ¶ster - seÃ§enek 1ğŸ‡ğŸ‡ğŸ‡
            st.line_chart(mood_all.set_index("date")[["huzur", "enerji", "anksiyete", "Ã¶fke", "depresif"]], 
                          use_container_width=True)
            
            # Alternatif olarak her parametreyi ayrÄ± grafikte gÃ¶ster - seÃ§enek 2ğŸ‡ğŸ‡ğŸ‡
            tabs = st.tabs(["Huzur", "Enerji", "Anksiyete", "Ã–fke", "Depresif", "Ortalama"])
            
            with tabs[0]:
                st.line_chart(mood_all.set_index("date")["huzur"], use_container_width=True)
            with tabs[1]:
                st.line_chart(mood_all.set_index("date")["enerji"], use_container_width=True)
            with tabs[2]:
                st.line_chart(mood_all.set_index("date")["anksiyete"], use_container_width=True)
            with tabs[3]:
                st.line_chart(mood_all.set_index("date")["Ã¶fke"], use_container_width=True)
            with tabs[4]:
                st.line_chart(mood_all.set_index("date")["depresif"], use_container_width=True)
            with tabs[5]:
                st.line_chart(mood_all.set_index("date")["average"], use_container_width=True)
        else:
            st.info("ğŸ“­ Ruh hali verisi henÃ¼z mevcut deÄŸil.")
    else:
        st.info("ğŸ“ Ruh hali klasÃ¶rÃ¼ henÃ¼z oluÅŸturulmamÄ±ÅŸ.")

    # Display video emotion analysis
    st.subheader("ğŸ¥ Video Duygu Analizi")
    if os.path.exists(video_path) and os.listdir(video_path):
        files = sorted(os.listdir(video_path))
        with open(os.path.join(video_path, files[-1]), "r", encoding="utf-8") as f:
            v = json.load(f)
        st.markdown(f"**BaskÄ±n Duygu:** {v['dominant_emotion']}")
        st.bar_chart(pd.Series(v["emotion_scores"]))
    else:
        st.info("Video duygu analizi verisi henÃ¼z mevcut deÄŸil.")

    # Journal NLP stats
    st.subheader("ğŸ“ GÃ¼nlÃ¼k (journal) NLP Ä°statistikleri")
    if journal_sents:
        st.markdown("**Sentiment**")
        st.line_chart(journal_sents, use_container_width=True)
    if journal_subjs:
        st.markdown("**Ã–znelik/Subjectivity**")
        # Ã–znelik deÄŸerlerini DataFrame olarak hazÄ±rlayÄ±n ve renkli bir Ã§izgi olarak gÃ¶sterin
        subj_df = pd.DataFrame({"subjectivity": journal_subjs})
        st.line_chart(subj_df, use_container_width=True)
    if journal_emos:
        st.markdown("**Duygu DaÄŸÄ±lÄ±mÄ±**")
        # Renk haritasÄ± uygulayÄ±n
        emotion_counts = pd.Series(journal_emos).value_counts()
        # En az bir deÄŸer olduÄŸundan emin olun
        for emotion in EMOTIONS:
            if emotion not in emotion_counts:
                emotion_counts[emotion] = 0
        st.bar_chart(emotion_counts, use_container_width=True)
    if not (journal_sents or journal_subjs or journal_emos):
        st.info("GÃ¼nlÃ¼k NLP verisi bulunamadÄ±.")

    # Audio NLP stats
    st.subheader("ğŸ¤Ses NLP Ä°statistikleri")
    if audio_sents:
        st.markdown("**Sentiment**")
        st.line_chart(audio_sents, use_container_width=True)
    if audio_subjs:
        st.markdown("**Ã–znelik/Subjectivity**")
        st.line_chart(audio_subjs, use_container_width=True)
    if audio_emos:
        st.markdown("**Duygu DaÄŸÄ±lÄ±mÄ±**")
        st.bar_chart(pd.Series(audio_emos).value_counts(), use_container_width=True)
    if not (audio_sents or audio_subjs or audio_emos):
        st.info("Ses NLP verisi bulunamadÄ±.")

    # Health data
    st.subheader("ğŸƒ AdÄ±m & Uyku")
    health_path = os.path.join(base, "healthkit")
    if os.path.exists(health_path):
        files = sorted([f for f in os.listdir(health_path) if f.endswith(".csv")])
        if files:
            df_list = [pd.read_csv(os.path.join(health_path, f)) for f in files]
            df = pd.concat(df_list, ignore_index=True)
            df["date"] = pd.to_datetime(df["date"])
            df = df.sort_values("date")

            avg_steps = int(df["steps"].mean())
            avg_sleep = round(df["hours"].mean(), 2)

            st.markdown("### ğŸš¶ GÃ¼nlÃ¼k AdÄ±m SayÄ±sÄ±")
            st.line_chart(df.set_index("date")["steps"], use_container_width=True)

            st.markdown("### ğŸ›Œ GÃ¼nlÃ¼k Uyku SÃ¼resi")
            st.line_chart(df.set_index("date")["hours"], use_container_width=True)
        else:
            st.info("ğŸ“­ SaÄŸlÄ±k verisi henÃ¼z mevcut deÄŸil.")
    else:
        st.info("ğŸ“ SaÄŸlÄ±k klasÃ¶rÃ¼ henÃ¼z oluÅŸturulmamÄ±ÅŸ.")

    # Psychometric test scores
    st.subheader("ğŸ“ Psikometrik Test SkorlarÄ±")
    for form in FORM_WEEKLY + FORM_MONTHLY:
        path = os.path.join(base, f"forms/{form}")
        if os.path.exists(path) and os.listdir(path):
            try:
                data = [json.load(open(os.path.join(path, f), "r", encoding="utf-8")) for f in sorted(os.listdir(path))]
                df = pd.DataFrame(data)
                df["date"] = pd.to_datetime(df["date"])
                st.markdown(f"#### {form}")
                st.line_chart(df.set_index("date")["score"])
            except Exception as e:
                st.warning(f"{form} verisi okunurken hata oluÅŸtu: {str(e)}")
        else:
            st.info(f"{form} form verisi bulunamadÄ±.")

    # Functioning Score Display
    st.subheader("âš–ï¸ Ä°ÅŸlevsellik Skoru")
    func_path = os.path.join(base, "functioning_score")
    if os.path.exists(func_path):
        func_files = sorted([f for f in os.listdir(func_path) if f.endswith(".csv")])
        if func_files:
            df_list = [pd.read_csv(os.path.join(func_path, filename)) for filename in func_files]
            if df_list:
                df = pd.concat(df_list, ignore_index=True)
                df["date"] = pd.to_datetime(df["date"])
                df = df.sort_values("date")

                # Ortalama iÅŸlevsellik skoru
                avg_func = round(df["score"].mean(), 2)
                st.metric("Ort. Ä°ÅŸlevsellik", avg_func)

                # Son skor
                latest_score = df["score"].values[-1]
                st.markdown(f"### Son Ä°ÅŸlevsellik Skoru: {latest_score}/100")

                # Skor deÄŸerlendirmesi
                if latest_score < 40:
                    st.error("DÃ¼ÅŸÃ¼k Ä°ÅŸlevsellik: GÃ¼nlÃ¼k yaÅŸam aktivitelerini sÃ¼rdÃ¼rmede Ã¶nemli zorluklar yaÅŸÄ±yor.")
                elif latest_score < 70:
                    st.warning("Orta Ä°ÅŸlevsellik: BazÄ± alanlarda zorluklar yaÅŸasa da temel iÅŸlevleri sÃ¼rdÃ¼rebiliyor.")
                else:
                    st.success("YÃ¼ksek Ä°ÅŸlevsellik: Ä°ÅŸlevsellikte Ã¶nemli bir sorun gÃ¶zlenmiyor.")                # Ä°ÅŸlevsellik trendi (tÃ¼m sÃ¼reci gÃ¶steren grafik)ğŸ‡ğŸ‡
                st.markdown("### Ä°ÅŸlevsellik Trendi")
                st.line_chart(df.set_index("date")["score"], use_container_width=True)
            else:
                st.info("Ä°ÅŸlevsellik verileri henÃ¼z mevcut deÄŸil.")
        else:
            st.info("Ä°ÅŸlevsellik dosyasÄ± bulunamadÄ±.")
    else:
        st.info("Ä°ÅŸlevsellik klasÃ¶rÃ¼ mevcut deÄŸil.")
    
# Sidebar'da klinik Ã¶zet ve yapay zeka analizi gÃ¶sterimiğŸ‡ğŸ‡
if selected:    # Klinik Ã¶zet (ham verilerle)
    clinical_overview = generate_clinical_overview(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, avg_func)
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"<div style='white-space: normal; font-size:15px; text-align:left'>{clinical_overview}</div>", unsafe_allow_html=True)# Yapay zeka analizi butonuna basÄ±lÄ±rsa GPT'den analiz al ve kaydetğŸ‡ğŸ‡ğŸ‡
    if st.session_state.get("analiz_triggered", False):
        # EÄŸer daha Ã¶nce kaydedilmiÅŸ analiz yoksa GPT'den al
        ai_summary = load_clinical_summary(selected)
        if not ai_summary:
            ai_summary = generate_clinical_summary(mood_df, nlp_summary, video_json, form_scores, avg_steps, avg_sleep, functioning_score, patient_id=selected)
            save_clinical_summary(selected, ai_summary)
        st.session_state.clinical_summary = ai_summary
        st.session_state.analiz_triggered = False  # Buton tetiklenmesini sÄ±fÄ±rla
        
    # EÄŸer kaydedilmiÅŸ analiz varsa gÃ¶sterğŸ‡ğŸ‡ğŸ‡ğŸ‡
    if st.session_state.clinical_summary:
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ¤– Yapay Zeka Klinik Analizi")
        formatted_summary = format_clinical_summary(st.session_state.clinical_summary)
        st.sidebar.markdown(f"<div style='white-space: normal; font-size:15px; text-align:left'>{formatted_summary}</div>", unsafe_allow_html=True)
        st.sidebar.markdown("### ğŸ“š DSBIT Referans Listesi")
        for title, url in DSBIT_REFERENCES:
            st.sidebar.markdown(f"- [{title}]({url})")

